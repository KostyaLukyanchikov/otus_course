{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры задач:\n",
    "\n",
    "- ранжировать документы по степени релевантности заданной теме (тематический поиск);\n",
    "- ранжировать документы по степени тематического сходства с заданным документом или его фрагментом;\n",
    "- построить иерархический тематический каталог коллекции документов и выработать правила каталогизации новых документов;\n",
    "- определить, как темы изменялись со временем (предполагается, что для каждого документа известно время его создания);\n",
    "- определить тематику авторов (предполагается, что для каждого документа известен список авторов);\n",
    "- определить тематику различных сущностей (entities), связанных с документами (например, журналов, конференций, организаций, стран);\n",
    "- разбить документ на тематически однородные фрагменты.\n",
    "\n",
    "\n",
    "[источник](http://www.machinelearning.ru/wiki/index.php?title=%D0%A2%D0%B5%D0%BC%D0%B0%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%BE%D0%B5_%D0%BC%D0%BE%D0%B4%D0%B5%D0%BB%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D0%B5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "библиотеки:\n",
    "- pyLDAvis\n",
    "- matplotlib\n",
    "- numpy\n",
    "- pandas\n",
    "- gensim\n",
    "- nltk\n",
    "- bigARTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     D:\\Anaconda3\\lib\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     D:\\Anaconda3\\lib\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Пример анализ тем в статьях NIPS\n",
    "\n",
    "## https://www.kaggle.com/benhamner/nips-papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('nips-papers/papers.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7241, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>event_type</th>\n",
       "      <th>pdf_name</th>\n",
       "      <th>abstract</th>\n",
       "      <th>paper_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1987</td>\n",
       "      <td>Self-Organization of Associative Database and ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1-self-organization-of-associative-database-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1987</td>\n",
       "      <td>A Mean Field Theory of Layer IV of Visual Cort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10-a-mean-field-theory-of-layer-iv-of-visual-c...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1988</td>\n",
       "      <td>Storing Covariance by the Associative Long-Ter...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100-storing-covariance-by-the-associative-long...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>1994</td>\n",
       "      <td>Bayesian Query Construction for Neural Network...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000-bayesian-query-construction-for-neural-ne...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Bayesian Query Construction for Neural\\nNetwor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1001</td>\n",
       "      <td>1994</td>\n",
       "      <td>Neural Network Ensembles, Cross Validation, an...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1001-neural-network-ensembles-cross-validation...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Neural Network Ensembles, Cross\\nValidation, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1002</td>\n",
       "      <td>1994</td>\n",
       "      <td>Using a neural net to instantiate a deformable...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1002-using-a-neural-net-to-instantiate-a-defor...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>U sing a neural net to instantiate a\\ndeformab...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1003</td>\n",
       "      <td>1994</td>\n",
       "      <td>Plasticity-Mediated Competitive Learning</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1003-plasticity-mediated-competitive-learning.pdf</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Plasticity-Mediated Competitive Learning\\n\\nTe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1004</td>\n",
       "      <td>1994</td>\n",
       "      <td>ICEG Morphology Classification using an Analog...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004-iceg-morphology-classification-using-an-a...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>ICEG Morphology Classification using an\\nAnalo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1005</td>\n",
       "      <td>1994</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma Using Ne...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1005-real-time-control-of-a-tokamak-plasma-usi...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma\\nUsing N...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1006</td>\n",
       "      <td>1994</td>\n",
       "      <td>Pulsestream Synapses with Non-Volatile Analogu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1006-pulsestream-synapses-with-non-volatile-an...</td>\n",
       "      <td>Abstract Missing</td>\n",
       "      <td>Real-Time Control of a Tokamak Plasma\\nUsing N...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  year                                              title event_type  \\\n",
       "0     1  1987  Self-Organization of Associative Database and ...        NaN   \n",
       "1    10  1987  A Mean Field Theory of Layer IV of Visual Cort...        NaN   \n",
       "2   100  1988  Storing Covariance by the Associative Long-Ter...        NaN   \n",
       "3  1000  1994  Bayesian Query Construction for Neural Network...        NaN   \n",
       "4  1001  1994  Neural Network Ensembles, Cross Validation, an...        NaN   \n",
       "5  1002  1994  Using a neural net to instantiate a deformable...        NaN   \n",
       "6  1003  1994           Plasticity-Mediated Competitive Learning        NaN   \n",
       "7  1004  1994  ICEG Morphology Classification using an Analog...        NaN   \n",
       "8  1005  1994  Real-Time Control of a Tokamak Plasma Using Ne...        NaN   \n",
       "9  1006  1994  Pulsestream Synapses with Non-Volatile Analogu...        NaN   \n",
       "\n",
       "                                            pdf_name          abstract  \\\n",
       "0  1-self-organization-of-associative-database-an...  Abstract Missing   \n",
       "1  10-a-mean-field-theory-of-layer-iv-of-visual-c...  Abstract Missing   \n",
       "2  100-storing-covariance-by-the-associative-long...  Abstract Missing   \n",
       "3  1000-bayesian-query-construction-for-neural-ne...  Abstract Missing   \n",
       "4  1001-neural-network-ensembles-cross-validation...  Abstract Missing   \n",
       "5  1002-using-a-neural-net-to-instantiate-a-defor...  Abstract Missing   \n",
       "6  1003-plasticity-mediated-competitive-learning.pdf  Abstract Missing   \n",
       "7  1004-iceg-morphology-classification-using-an-a...  Abstract Missing   \n",
       "8  1005-real-time-control-of-a-tokamak-plasma-usi...  Abstract Missing   \n",
       "9  1006-pulsestream-synapses-with-non-volatile-an...  Abstract Missing   \n",
       "\n",
       "                                          paper_text  \n",
       "0  767\\n\\nSELF-ORGANIZATION OF ASSOCIATIVE DATABA...  \n",
       "1  683\\n\\nA MEAN FIELD THEORY OF LAYER IV OF VISU...  \n",
       "2  394\\n\\nSTORING COVARIANCE BY THE ASSOCIATIVE\\n...  \n",
       "3  Bayesian Query Construction for Neural\\nNetwor...  \n",
       "4  Neural Network Ensembles, Cross\\nValidation, a...  \n",
       "5  U sing a neural net to instantiate a\\ndeformab...  \n",
       "6  Plasticity-Mediated Competitive Learning\\n\\nTe...  \n",
       "7  ICEG Morphology Classification using an\\nAnalo...  \n",
       "8  Real-Time Control of a Tokamak Plasma\\nUsing N...  \n",
       "9  Real-Time Control of a Tokamak Plasma\\nUsing N...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])\n",
    "stop_words = set(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # Remove new line characters\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    # Remove distracting single quotes\n",
    "    text = re.sub(\"\\'\", \"\", text)\n",
    "    return text\n",
    "\n",
    "\n",
    "def doc_to_words(doc, stop_words, lemma):\n",
    "    stop_words = set(stop_words)\n",
    "    # remove stop words and punctuation\n",
    "    words = [w for w in gensim.utils.simple_preprocess(str(doc), deacc=True) if w not in stop_words]\n",
    "    \n",
    "    # make lemmatization\n",
    "    words = [lemma.lemmatize(w) for w in words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['self',\n",
      " 'organization',\n",
      " 'associative',\n",
      " 'database',\n",
      " 'application',\n",
      " 'hisashi',\n",
      " 'suzuki',\n",
      " 'suguru',\n",
      " 'arimoto',\n",
      " 'osaka',\n",
      " 'university',\n",
      " 'toyonaka',\n",
      " 'osaka',\n",
      " 'japan',\n",
      " 'abstract',\n",
      " 'efficient',\n",
      " 'method',\n",
      " 'self',\n",
      " 'organizing',\n",
      " 'associative',\n",
      " 'database',\n",
      " 'proposed',\n",
      " 'together',\n",
      " 'application',\n",
      " 'robot',\n",
      " 'eyesight',\n",
      " 'system',\n",
      " 'proposed',\n",
      " 'database',\n",
      " 'associate',\n",
      " 'input',\n",
      " 'output',\n",
      " 'first',\n",
      " 'half',\n",
      " 'part',\n",
      " 'discussion',\n",
      " 'algorithm',\n",
      " 'self',\n",
      " 'organization',\n",
      " 'proposed']\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare:\n",
    "    # Convert to list\n",
    "    data = df.paper_text.values.tolist()\n",
    "\n",
    "    data = [clean(t) for t in data]\n",
    "    data_words = [doc_to_words(t, stop_words, lemma) for t in data]\n",
    "    \n",
    "    with open('data.pkl', 'wb') as f:\n",
    "        pickle.dump({'data': data, 'data_words': data_words}, f)\n",
    "else:\n",
    "    with open('data.pkl', 'rb') as f:\n",
    "        d = pickle.load(f)\n",
    "        data = d['data']\n",
    "        data_words = d['data_words']\n",
    "\n",
    "pprint(data_words[0][:40])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare:\n",
    "    # Build the bigram and trigram models\n",
    "    bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "    # Faster way to get a sentence clubbed as a trigram/bigram\n",
    "    bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "    bigram_mod.save('bigram_mod.pkl')\n",
    "    \n",
    "    data_words_bigrams = [bigram_mod[w] for w in data_words]\n",
    "    with open('bigrams.pkl', 'wb') as f:\n",
    "        pickle.dump(data_words_bigrams, f)\n",
    "\n",
    "else:\n",
    "    bigram_mod = gensim.models.Phrases.load('bigram_mod.pkl')\n",
    "    \n",
    "    with open('bigrams.pkl', 'rb') as f:\n",
    "        data_words_bigrams = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['self_organization',\n",
       " 'associative',\n",
       " 'database',\n",
       " 'application',\n",
       " 'hisashi',\n",
       " 'suzuki',\n",
       " 'suguru',\n",
       " 'arimoto',\n",
       " 'osaka',\n",
       " 'university']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_bigrams[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.05 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare:\n",
    "    id2word = corpora.Dictionary(data_words_bigrams)\n",
    "    id2word.save('id2word.pkl')\n",
    "else:\n",
    "    id2word = corpora.Dictionary.load('id2word.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.74 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = [id2word.doc2bow(text) for text in data_words_bigrams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 2),\n",
       " (4, 1),\n",
       " (5, 6),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 3),\n",
       " (9, 1)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'actual'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2word[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'767 SELF-ORGANIZATION OF ASSOCIATIVE DATABASE AND ITS APPLICATIONS Hisashi Suzuki and Suguru Arimoto Osaka University, Toyonaka, Osaka 560, Japan ABSTRACT An efficient method of self-organizing associative databases is proposed together with applications to robot eyesight systems. The proposed databases can associate any input with some output. In the first half part of discussion, an algorithm of self-organization is proposed. From an aspect of hardware, it produces a new style of neural network. In the latter half part, an applicability to handwritten letter recognition and that to an autonomous mobile robot system are demonstrated. INTRODUCTION Let a mapping f : X -+ Y be given. Here, X is a finite or infinite set, and Y is another finite or infinite set. A learning machine observes any set of pairs (x, y) sampled randomly from X x Y. (X x Y means the Cartesian product of X and Y.) And, it computes some estimate j : X -+ Y of f to make small, the estimation error in some measure. Usually we say that: the faster the decrease of estimation error with increase of the number of samples, the better the learning machine. However, such expression on performance is incomplete. Since, it lacks consideration on the candidates of J of j assumed preliminarily. Then, how should we find out good learning machines? To clarify this conception, let us discuss for a while on some types of learning machines. And, let us advance the understanding of the self-organization of associative database . . Parameter Type An ordinary type of learning machine assumes an equation relating xs and ys with parameters being indefinite, namely, a structure of f. It is equivalent to define implicitly a set F of candidates of (F is some subset of mappings from X to Y.) And, it computes values of the parameters based on the observed samples. We call such type a parameter type. For a learning machine defined well, if F 3 f, j approaches f as the number of samples increases. In the alternative case, however, some estimation error remains eternally. Thus, a problem of designing a learning machine returns to find out a proper structure of f in this sense. On the other hand, the assumed structure of f is demanded to be as compact as possible to achieve a fast learning. In other words, the number of parameters should be small. Since, if the parameters are few, some j can be uniquely determined even though the observed samples are few. However, this demand of being proper contradicts to that of being compact. Consequently, in the parameter type, the better the compactness of the assumed structure that is proper, the better the learning machine. This is the most elementary conception when we design learning machines . 1. . Universality and Ordinary Neural Networks Now suppose that a sufficient knowledge on f is given though J itself is unknown. In this case, it is comparatively easy to find out proper and compact structures of J. In the alternative case, however, it is sometimes difficult. A possible solution is to give up the compactness and assume an almighty structure that can cover various 1s. A combination of some orthogonal bases of the infinite dimension is such a structure. Neural networks 1 ,2 are its approximations obtained by truncating finitely the dimension for implementation. ? American Institute of Physics 1988 768 A main topic in designing neural networks is to establish such desirable structures of 1. This work includes developing practical procedures that compute values of coefficients from the observed samples. Such discussions are :flourishing since 1980 while many efficient methods have been proposed. Recently, even hardware units computing coefficients in parallel for speed-up are sold, e.g., ANZA, Mark III, Odyssey and E-1. Nevertheless, in neural networks, there always exists a danger of some error remaining eternally in estimating /. Precisely speaking, suppose that a combination of the bases of a finite number can define a structure of 1 essentially. In other words, suppose that F 3 /, or 1 is located near F. In such case, the estimation error is none or negligible. However, if 1 is distant from F, the estimation error never becomes negligible. Indeed, many researches report that the following situation appears when 1 is too complex. Once the estimation error converges to some value (> 0) as the number of samples increases, it decreases hardly even though the dimension is heighten. This property sometimes is a considerable defect of neural networks . . Recursi ve Type The recursive type is founded on another methodology of learning that should be as follows. At the initial stage of no sample, the set Fa (instead of notation F) of candidates of I equals to the set of all mappings from X to Y. After observing the first sample (Xl, Yl) E X x Y, Fa is reduced to Fi so that I(xt) = Yl for any I E F. After observing the second sample (X2 Y2) E X x Y, Fl is further reduced to F2 so that i(xt) = Yl and I(X2) = Y2 for any I E F. Thus, the candidate set F becomes gradually small as observation of samples proceeds. The after observing i-samples, which we write is one of the most likelihood estimation of 1 selected in fi;. Hence, contrarily to the parameter type, the recursive type guarantees surely that j approaches to 1 as the number of samples increases. The recursive type, if observes a sample (x\" yd, rewrites values 1,-l(X),S to I,(x)s for some xs correlated to the sample. Hence, this type has an architecture composed of a rule for rewriting and a free memory space. Such architecture forms naturally a kind of database that builds up management systems of data in a self-organizing way. However, this database differs from ordinary ones in the following sense. It does not only record the samples already observed, but computes some estimation of l(x) for any x E X. We call such database an associative database. The first subject in constructing associative databases is how we establish the rule for rewri ting. For this purpose, we adap t a measure called the dissimilari ty. Here, a dissimilari ty means a mapping d : X x X -+ {reals > O} such that for any (x, x) E X x X, d(x, x) > 0 whenever l(x) t /(x). However, it is not necessarily defined with a single formula. It is definable with, for example, a collection of rules written in forms of \"if? .. then?? .. \" The dissimilarity d defines a structure of 1 locally in X x Y. Hence, even though the knowledge on f is imperfect, we can re:flect it on d in some heuristic way. Hence, contrarily to neural networks, it is possible to accelerate the speed of learning by establishing d well. Especially, we can easily find out simple ds for those ls which process analogically information like a human. (See the applications in this paper.) And, for such /s, the recursive type shows strongly its effectiveness. We denote a sequence of observed samples by (Xl, Yd, (X2 Y2),???. One of the simplest constructions of associative databases after observing i-samples (i = 1,2,.,,) is as follows. i i\" I, Algorithm 1. At the initial stage, let So be the empty set. For every i = 1,2\" .. , let i,-l(x) for any x E X equal some y* such that (x*,y*) E S,-l and d(x, x*) = min (%,y)ES.-t d(x, x) . Furthermore, add (x\" y,) to S;-l to produce Sa, i.e., S, = S,_l U {(x\" (1) y,n. 769 Another version improved to economize the memory is as follows. Algorithm 2, At the initial stage, let So be composed of an arbitrary element in X x Y. For every i = 1,2\"\", let ii-lex) for any x E X equal some y. such that (x?, y.) E Si-l and d(x, x?) = min d(x, x) . (i,i)ES.-l Furthermore, if ii-l(Xi) # Yi then let Si = Si-l, or add (Xi, Yi) to Si-l to produce Si, i.e., Si = Si-l U {(Xi, Yi)} In either construction, ii approaches to f as i increases. However, the computation time grows proportionally to the size of Si. The second subject in constructing associative databases is what addressing rule we should employ to economize the computation time. In the subsequent chapters, a construction of associative database for this purpose is proposed. It manages data in a form of binary tree. SELF-ORGANIZATION OF ASSOCIATIVE DATABASE Given a sample sequence (Xl, Yl), (X2 Y2), .. \" the algorithm for constructing associative database is as follows. Algorithm 3, Step I(Initialization): Let (x[root], y[root]) = (Xl, Yd. Here, x[.] and y[.] are variables assigned for respective nodes to memorize data.. Furthermore, let t = 1. Step 2: Increase t by 1, and put x, in. After reset a pointer n to the root, repeat the following until n arrives at some terminal node, i.e., leaf. Notations nand d(xt, x[n)), let n n mean the descendant nodes of n. =n. Otherwise, let n =n. If d(x\" r[n)) ~ Step 3: Display yIn] as the related information. Next, put y, in. If yIn] = y\" back to step 2. Otherwise, first establish new descendant nodes n and n. Secondly, let (x[n], yIn)) (x[n], yIn)) (x[n], yIn)), (Xt, y,). (2) (3) Finally, back to step 2. Here, the loop of step 2-3 can be stopped at any time and also can be continued. Now, suppose that gate elements, namely, artificial \"synapses\" that play the role of branching by d are prepared. Then, we obtain a new style of neural network with gate elements being randomly connected by this algorithm. LETTER RECOGNITION Recen tly, the vertical slitting method for recognizing typographic English letters3 , the elastic matching method for recognizing hand written discrete English letters4 , the global training and fuzzy logic search method for recognizing Chinese characters written in square styleS, etc. are published. The self-organization of associative database realizes the recognition of handwritten continuous English letters. 770 9 /wn\" NOV ~ ~ ~ -xk :La.t ~~ ~ ~~~ dw1lo ~~~~~of~~ ~~~ 4,-?~~4Fig. 1. Source document. 2~~--------------- lOO~--------------- H o o Fig. 2. Windowing. 1000 2000 3000 4000 Number of samples o 1000 2000 3000 4000 NUAlber of sampl es Fig. 3. An experiment result. An image scanner takes a document image (Fig. 1). The letter recognizer uses a parallelogram window that at least can cover the maximal letter (Fig. 2), and processes the sequence of letters while shifting the window. That is, the recognizer scans a word in a slant direction. And, it places the window so that its left vicinity may be on the first black point detected. Then, the window catches a letter and some part of the succeeding letter. If recognition of the head letter is performed, its end position, namely, the boundary line between two letters becomes known. Hence, by starting the scanning from this boundary and repeating the above operations, the recognizer accomplishes recursively the task. Thus the major problem comes to identifying the head letter in the window. Considering it, we define the following. ? Regard window images as xs, and define X accordingly. ? For a (x, x) E X x X, denote by B a black point in the left area from the boundary on window image X. Project each B onto window image x. Then, measure the Euclidean distance 6 between fj and a black point B on x being the closest to B. Let d(x, x) be the summation of 6s for all black points Bs on x divided by the number of Bs. ? Regard couples of the \"reading\" and the position of boundary as ys, and define Y accordingly. An operator teaches the recognizer in interaction the relation between window image and reading& boundary with algorithm 3. Precisely, if the recalled reading is incorrect, the operator teaches a correct reading via the console. Moreover, if the boundary position is incorrect, he teaches a correct position via the mouse. Fig. 1 shows partially a document image used in this experiment. Fig. 3 shows the change of the number of nodes and that of the recognition rate defined as the relative frequency of correct answers in the past 1000 trials. Speciiications of the window are height = 20dot, width = 10dot, and slant angular = 68deg. In this example, the levels of tree were distributed in 6-19 at time 4000 and the recognition rate converged to about 74%. Experimentally, the recognition rate converges to about 60-85% in most cases, and to 95% at a rare case. However, it does not attain 100% since, e.g., \"c\" and \"e\" are not distinguishable because of excessive lluctuation in writing. If the consistency of the x, y-relation is not assured like this, the number of nodes increases endlessly (d. Fig. 3). Hence, it is clever to stop the learning when the recognition rate attains some upper limit. To improve further the recognition rate, we must consider the spelling of words. It is one of future subjects. 771 OBSTACLE AVOIDING MOVEMENT Various systems of camera type autonomous mobile robot are reported flourishingly6-1O. The system made up by the authors (Fig. 4) also belongs to this category. Now, in mathematical methodologies, we solve usually the problem of obstacle avoiding movement as a cost minimization problem under some cost criterion established artificially. Contrarily, the self-organization of associative database reproduces faithfully the cost criterion of an operator. Therefore, motion of the robot after learning becomes very natural. Now, the length, width and height of the robot are all about O.7m, and the weight is about 30kg. The visual angle of camera is about 55deg. The robot has the following three factors of motion. It turns less than ?30deg, advances less than 1m, and controls speed less than 3km/h. The experiment was done on the passageway of wid th 2.5m inside a building which the authors laboratories exist in (Fig. 5). Because of an experimental intention, we arrange boxes, smoking stands, gas cylinders, stools, handcarts, etc. on the passage way at random. We let the robot take an image through the camera, recall a similar image, and trace the route preliminarily recorded on it. For this purpose, we define the following. ? Let the camera face 28deg downward to take an image, and process it through a low pass filter. Scanning vertically the filtered image from the bottom to the top, search the first point C where the luminance changes excessively. Then, su bstitu te all points from the bottom to C for white, and all points from C to the top for black (Fig. 6). (If no obstacle exists just in front of the robot, the white area shows the free area where the robot can move around.) Regard binary 32 x 32dot images processed thus as xs, and define X accordingly. ? For every (x, x) E X x X, let d(x, x) be the number of black points on the exclusive-or image between x and X. ? Regard as ys the images obtained by drawing routes on images xs, and define Y accordingly. The robot superimposes, on the current camera image x, the route recalled for x, and inquires the operator instructions. The operator judges subjectively whether the suggested route is appropriate or not. In the negative answer, he draws a desirable route on x with the mouse to teach a new y to the robot. This opera.tion defines implicitly a sample sequence of (x, y) reflecting the cost criterion of the operator. .::l\" ! - IibUBe _. - 22 11 Roan 12 {- 13 Stationary uni t Fig. 4. Configuration of autonomous mobile robot system. ~ I , 23 24 North 14 rmbi Ie unit (robot) - Roan y t Fig. 5. Experimental environment. 772 Wall Camera image Preprocessing A ::: !fa ? Preprocessing 0 O Course suggest ion ?? .. Search A Fig. 6. Processing for obstacle avoiding movement. x Fig. 1. Processing for position identification. We define the satisfaction rate by the relative frequency of acceptable suggestions of route in the past 100 trials. In a typical experiment, the change of satisfaction rate showed a similar tendency to Fig. 3, and it attains about 95% around time 800. Here, notice that the rest 5% does not mean directly the percentage of collision. (In practice, we prevent the collision by adopting some supplementary measure.) At time 800, the number of nodes was 145, and the levels of tree were distributed in 6-17. The proposed method reflects delicately various characters of operator. For example, a robot trained by an operator 0 moves slowly with enough space against obstacles while one trained by another operator 0 brushes quickly against obstacles. This fact gives us a hint on a method of printing \"characters\" into machines. POSITION IDENTIFICATION The robot can identify its position by recalling a similar landscape with the position data to a camera image. For this purpose, in principle, it suffices to regard camera images and position data as xs and ys, respectively. However, the memory capacity is finite in actual compu ters. Hence, we cannot but compress the camera images at a slight loss of information. Such compression is admittable as long as the precision of position identification is in an acceptable area. Thus, the major problem comes to find out some suitable compression method. In the experimental environment (Fig. 5), juts are on the passageway at intervals of 3.6m, and each section between adjacent juts has at most one door. The robot identifies roughly from a surrounding landscape which section itself places in. And, it uses temporarily a triangular surveying technique if an exact measure is necessary. To realize the former task, we define the following . ? Turn the camera to take a panorama image of 360deg. Scanning horizontally the center line, substitute the points where the luminance excessively changes for black and the other points for white (Fig. 1). Regard binary 360dot line images processed thus as xs, and define X accordingly. ? For every (x, x) E X x X, project each black point A on x onto x. And, measure the Euclidean distance 6 between A and a black point A on x being the closest to A. Let the summation of 6 be S. Similarly, calculate S by exchanging the roles of x and X. Denoting the numbers of As and As respectively by nand n, define 773 d(x, x) = ~(~ + ~). 2 n n (4) ? Regard positive integers labeled on sections as ys (cf. Fig. 5), and define Y accordingly. In the learning mode, the robot checks exactly its position with a counter that is reset periodically by the operator. The robot runs arbitrarily on the passageways within 18m area and learns the relation between landscapes and position data. (Position identification beyond 18m area is achieved by crossing plural databases one another.) This task is automatic excepting the periodic reset of counter, namely, it is a kind of learning without teacher. We define the identification rate by the relative frequency of correct recalls of position data in the past 100 trials. In a typical example, it converged to about 83% around time 400. At time 400, the number of levels was 202, and the levels oftree were distributed in 522. Since the identification failures of 17% can be rejected by considering the trajectory, no pro blem arises in practical use. In order to improve the identification rate, the compression ratio of camera images must be loosened. Such possibility depends on improvement of the hardware in the future. Fig. 8 shows an example of actual motion of the robot based on the database for obstacle avoiding movement and that for position identification. This example corresponds to a case of moving from 14 to 23 in Fig. 5. Here, the time interval per frame is about 40sec. ,~. .~ ( ;~\"i.. ~ \" \" . ..I I ? ? \" I . .1 t ; i -: , . . , II Fig. 8. Actual motion of the robot. 774 CONCLUSION A method of self-organizing associative databases was proposed with the application to robot eyesight systems. The machine decomposes a global structure unknown into a set of local structures known and learns universally any input-output response. This framework of problem implies a wide application area other than the examples shown in this paper. A defect of the algorithm 3 of self-organization is that the tree is balanced well only for a subclass of structures of f. A subject imposed us is to widen the class. A probable solution is to abolish the addressing rule depending directly on values of d and, instead, to establish another rule depending on the distribution function of values of d. It is now under investigation. REFERENCES 1. Hopfield, J. J. and D. W. Tank, \"Computing with Neural Circuit: A Model/ Science 233 (1986), pp. 625-633. 2. Rumelhart, D. E. et al., \"Learning Representations by Back-Propagating Errors,\" Nature 323 (1986), pp. 533-536. 3. Hull, J. J., \"Hypothesis Generation in a Computational Model for Visual Word Recognition,\" IEEE Expert, Fall (1986), pp. 63-70. 4. Kurtzberg, J. M., \"Feature Analysis for Symbol Recognition by Elastic Matching,\" IBM J. Res. Develop. 31-1 (1987), pp. 91-95. 5. Wang, Q. R. and C. Y. Suen, \"Large Tree Classifier with Heuristic Search and Global Training,\" IEEE Trans. Pattern. Anal. & Mach. Intell. PAMI 9-1 (1987) pp. 91-102. 6. Brooks, R. A. et al, \"Self Calibration of Motion and Stereo Vision for Mobile Robots,\" 4th Int. Symp. of Robotics Research (1987), pp. 267-276. 7. Goto, Y. and A. Stentz, \"The CMU System for Mobile Robot Navigation,\" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 99-105. 8. Madarasz, R. et al., \"The Design of an Autonomous Vehicle for the Disabled,\" IEEE Jour. of Robotics & Automation RA 2-3 (1986), pp. 117-125. 9. Triendl, E. and D. J. Kriegman, \"Stereo Vision and Navigation within Buildings,\" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 1725-1730. 10. Turk, M. A. et al., \"Video Road-Following for the Autonomous Land Vehicle,\" 1987 IEEE Int. Conf. on Robotics & Automation (1987), pp. 273-279. '"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].count('accordingly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 2),\n",
       " (4, 1),\n",
       " (5, 6),\n",
       " (6, 1),\n",
       " (7, 1),\n",
       " (8, 3),\n",
       " (9, 1),\n",
       " (10, 2),\n",
       " (11, 2),\n",
       " (12, 1),\n",
       " (13, 1),\n",
       " (14, 1),\n",
       " (15, 2),\n",
       " (16, 8),\n",
       " (17, 1),\n",
       " (18, 1),\n",
       " (19, 2),\n",
       " (20, 2),\n",
       " (21, 1),\n",
       " (22, 1),\n",
       " (23, 1),\n",
       " (24, 1),\n",
       " (25, 1),\n",
       " (26, 1),\n",
       " (27, 6),\n",
       " (28, 2),\n",
       " (29, 1),\n",
       " (30, 1),\n",
       " (31, 1),\n",
       " (32, 5),\n",
       " (33, 3),\n",
       " (34, 1),\n",
       " (35, 1),\n",
       " (36, 1),\n",
       " (37, 1),\n",
       " (38, 2),\n",
       " (39, 7),\n",
       " (40, 1),\n",
       " (41, 1),\n",
       " (42, 3),\n",
       " (43, 1),\n",
       " (44, 1),\n",
       " (45, 1),\n",
       " (46, 1),\n",
       " (47, 1),\n",
       " (48, 1),\n",
       " (49, 1),\n",
       " (50, 13),\n",
       " (51, 1),\n",
       " (52, 3),\n",
       " (53, 1),\n",
       " (54, 1),\n",
       " (55, 1),\n",
       " (56, 2),\n",
       " (57, 2),\n",
       " (58, 1),\n",
       " (59, 1),\n",
       " (60, 3),\n",
       " (61, 1),\n",
       " (62, 4),\n",
       " (63, 2),\n",
       " (64, 2),\n",
       " (65, 1),\n",
       " (66, 1),\n",
       " (67, 2),\n",
       " (68, 2),\n",
       " (69, 4),\n",
       " (70, 1),\n",
       " (71, 3),\n",
       " (72, 1),\n",
       " (73, 3),\n",
       " (74, 9),\n",
       " (75, 1),\n",
       " (76, 2),\n",
       " (77, 6),\n",
       " (78, 1),\n",
       " (79, 1),\n",
       " (80, 1),\n",
       " (81, 1),\n",
       " (82, 1),\n",
       " (83, 1),\n",
       " (84, 2),\n",
       " (85, 1),\n",
       " (86, 1),\n",
       " (87, 2),\n",
       " (88, 1),\n",
       " (89, 11),\n",
       " (90, 4),\n",
       " (91, 1),\n",
       " (92, 1),\n",
       " (93, 1),\n",
       " (94, 7),\n",
       " (95, 1),\n",
       " (96, 1),\n",
       " (97, 1),\n",
       " (98, 1),\n",
       " (99, 4),\n",
       " (100, 1),\n",
       " (101, 3),\n",
       " (102, 1),\n",
       " (103, 1),\n",
       " (104, 1),\n",
       " (105, 1),\n",
       " (106, 1),\n",
       " (107, 1),\n",
       " (108, 1),\n",
       " (109, 2),\n",
       " (110, 1),\n",
       " (111, 2),\n",
       " (112, 1),\n",
       " (113, 2),\n",
       " (114, 2),\n",
       " (115, 2),\n",
       " (116, 3),\n",
       " (117, 2),\n",
       " (118, 1),\n",
       " (119, 1),\n",
       " (120, 2),\n",
       " (121, 1),\n",
       " (122, 3),\n",
       " (123, 1),\n",
       " (124, 2),\n",
       " (125, 1),\n",
       " (126, 1),\n",
       " (127, 3),\n",
       " (128, 2),\n",
       " (129, 2),\n",
       " (130, 1),\n",
       " (131, 1),\n",
       " (132, 1),\n",
       " (133, 1),\n",
       " (134, 1),\n",
       " (135, 1),\n",
       " (136, 1),\n",
       " (137, 2),\n",
       " (138, 1),\n",
       " (139, 1),\n",
       " (140, 3),\n",
       " (141, 3),\n",
       " (142, 1),\n",
       " (143, 1),\n",
       " (144, 1),\n",
       " (145, 3),\n",
       " (146, 1),\n",
       " (147, 2),\n",
       " (148, 2),\n",
       " (149, 4),\n",
       " (150, 1),\n",
       " (151, 1),\n",
       " (152, 4),\n",
       " (153, 2),\n",
       " (154, 1),\n",
       " (155, 1),\n",
       " (156, 2),\n",
       " (157, 3),\n",
       " (158, 1),\n",
       " (159, 1),\n",
       " (160, 1),\n",
       " (161, 1),\n",
       " (162, 1),\n",
       " (163, 7),\n",
       " (164, 19),\n",
       " (165, 1),\n",
       " (166, 2),\n",
       " (167, 2),\n",
       " (168, 1),\n",
       " (169, 14),\n",
       " (170, 3),\n",
       " (171, 2),\n",
       " (172, 5),\n",
       " (173, 1),\n",
       " (174, 1),\n",
       " (175, 1),\n",
       " (176, 1),\n",
       " (177, 2),\n",
       " (178, 1),\n",
       " (179, 2),\n",
       " (180, 1),\n",
       " (181, 2),\n",
       " (182, 2),\n",
       " (183, 2),\n",
       " (184, 2),\n",
       " (185, 1),\n",
       " (186, 1),\n",
       " (187, 1),\n",
       " (188, 1),\n",
       " (189, 1),\n",
       " (190, 3),\n",
       " (191, 1),\n",
       " (192, 2),\n",
       " (193, 1),\n",
       " (194, 1),\n",
       " (195, 1),\n",
       " (196, 2),\n",
       " (197, 1),\n",
       " (198, 2),\n",
       " (199, 1),\n",
       " (200, 2),\n",
       " (201, 1),\n",
       " (202, 1),\n",
       " (203, 3),\n",
       " (204, 1),\n",
       " (205, 1),\n",
       " (206, 3),\n",
       " (207, 1),\n",
       " (208, 1),\n",
       " (209, 4),\n",
       " (210, 1),\n",
       " (211, 1),\n",
       " (212, 1),\n",
       " (213, 1),\n",
       " (214, 3),\n",
       " (215, 1),\n",
       " (216, 1),\n",
       " (217, 2),\n",
       " (218, 1),\n",
       " (219, 2),\n",
       " (220, 1),\n",
       " (221, 2),\n",
       " (222, 3),\n",
       " (223, 1),\n",
       " (224, 1),\n",
       " (225, 1),\n",
       " (226, 1),\n",
       " (227, 1),\n",
       " (228, 3),\n",
       " (229, 1),\n",
       " (230, 2),\n",
       " (231, 3),\n",
       " (232, 1),\n",
       " (233, 1),\n",
       " (234, 8),\n",
       " (235, 1),\n",
       " (236, 1),\n",
       " (237, 4),\n",
       " (238, 1),\n",
       " (239, 1),\n",
       " (240, 1),\n",
       " (241, 1),\n",
       " (242, 8),\n",
       " (243, 4),\n",
       " (244, 2),\n",
       " (245, 2),\n",
       " (246, 2),\n",
       " (247, 1),\n",
       " (248, 3),\n",
       " (249, 4),\n",
       " (250, 1),\n",
       " (251, 1),\n",
       " (252, 7),\n",
       " (253, 1),\n",
       " (254, 1),\n",
       " (255, 2),\n",
       " (256, 1),\n",
       " (257, 1),\n",
       " (258, 1),\n",
       " (259, 2),\n",
       " (260, 4),\n",
       " (261, 3),\n",
       " (262, 1),\n",
       " (263, 1),\n",
       " (264, 1),\n",
       " (265, 2),\n",
       " (266, 3),\n",
       " (267, 1),\n",
       " (268, 1),\n",
       " (269, 1),\n",
       " (270, 1),\n",
       " (271, 1),\n",
       " (272, 1),\n",
       " (273, 1),\n",
       " (274, 1),\n",
       " (275, 1),\n",
       " (276, 2),\n",
       " (277, 22),\n",
       " (278, 1),\n",
       " (279, 1),\n",
       " (280, 1),\n",
       " (281, 5),\n",
       " (282, 4),\n",
       " (283, 1),\n",
       " (284, 6),\n",
       " (285, 1),\n",
       " (286, 1),\n",
       " (287, 1),\n",
       " (288, 1),\n",
       " (289, 1),\n",
       " (290, 8),\n",
       " (291, 4),\n",
       " (292, 3),\n",
       " (293, 1),\n",
       " (294, 1),\n",
       " (295, 1),\n",
       " (296, 1),\n",
       " (297, 1),\n",
       " (298, 2),\n",
       " (299, 3),\n",
       " (300, 1),\n",
       " (301, 1),\n",
       " (302, 3),\n",
       " (303, 2),\n",
       " (304, 1),\n",
       " (305, 1),\n",
       " (306, 2),\n",
       " (307, 1),\n",
       " (308, 2),\n",
       " (309, 3),\n",
       " (310, 3),\n",
       " (311, 1),\n",
       " (312, 1),\n",
       " (313, 1),\n",
       " (314, 1),\n",
       " (315, 1),\n",
       " (316, 2),\n",
       " (317, 2),\n",
       " (318, 1),\n",
       " (319, 2),\n",
       " (320, 1),\n",
       " (321, 3),\n",
       " (322, 2),\n",
       " (323, 1),\n",
       " (324, 1),\n",
       " (325, 7),\n",
       " (326, 2),\n",
       " (327, 1),\n",
       " (328, 1),\n",
       " (329, 1),\n",
       " (330, 1),\n",
       " (331, 10),\n",
       " (332, 1),\n",
       " (333, 1),\n",
       " (334, 1),\n",
       " (335, 1),\n",
       " (336, 8),\n",
       " (337, 1),\n",
       " (338, 1),\n",
       " (339, 1),\n",
       " (340, 1),\n",
       " (341, 5),\n",
       " (342, 1),\n",
       " (343, 4),\n",
       " (344, 1),\n",
       " (345, 1),\n",
       " (346, 23),\n",
       " (347, 1),\n",
       " (348, 1),\n",
       " (349, 2),\n",
       " (350, 1),\n",
       " (351, 1),\n",
       " (352, 2),\n",
       " (353, 1),\n",
       " (354, 1),\n",
       " (355, 1),\n",
       " (356, 1),\n",
       " (357, 2),\n",
       " (358, 7),\n",
       " (359, 1),\n",
       " (360, 1),\n",
       " (361, 3),\n",
       " (362, 3),\n",
       " (363, 3),\n",
       " (364, 1),\n",
       " (365, 2),\n",
       " (366, 1),\n",
       " (367, 1),\n",
       " (368, 2),\n",
       " (369, 1),\n",
       " (370, 1),\n",
       " (371, 3),\n",
       " (372, 1),\n",
       " (373, 1),\n",
       " (374, 1),\n",
       " (375, 1),\n",
       " (376, 2),\n",
       " (377, 1),\n",
       " (378, 1),\n",
       " (379, 1),\n",
       " (380, 1),\n",
       " (381, 1),\n",
       " (382, 2),\n",
       " (383, 1),\n",
       " (384, 2),\n",
       " (385, 1),\n",
       " (386, 2),\n",
       " (387, 2),\n",
       " (388, 1),\n",
       " (389, 1),\n",
       " (390, 1),\n",
       " (391, 1),\n",
       " (392, 1),\n",
       " (393, 1),\n",
       " (394, 1),\n",
       " (395, 3),\n",
       " (396, 1),\n",
       " (397, 1),\n",
       " (398, 3),\n",
       " (399, 1),\n",
       " (400, 17),\n",
       " (401, 2),\n",
       " (402, 1),\n",
       " (403, 2),\n",
       " (404, 1),\n",
       " (405, 18),\n",
       " (406, 13),\n",
       " (407, 4),\n",
       " (408, 1),\n",
       " (409, 2),\n",
       " (410, 1),\n",
       " (411, 1),\n",
       " (412, 3),\n",
       " (413, 1),\n",
       " (414, 1),\n",
       " (415, 1),\n",
       " (416, 1),\n",
       " (417, 1),\n",
       " (418, 1),\n",
       " (419, 1),\n",
       " (420, 1),\n",
       " (421, 1),\n",
       " (422, 1),\n",
       " (423, 1),\n",
       " (424, 2),\n",
       " (425, 1),\n",
       " (426, 11),\n",
       " (427, 1),\n",
       " (428, 1),\n",
       " (429, 1),\n",
       " (430, 2),\n",
       " (431, 1),\n",
       " (432, 1),\n",
       " (433, 1),\n",
       " (434, 2),\n",
       " (435, 4),\n",
       " (436, 1),\n",
       " (437, 2),\n",
       " (438, 1),\n",
       " (439, 1),\n",
       " (440, 1),\n",
       " (441, 4),\n",
       " (442, 6),\n",
       " (443, 1),\n",
       " (444, 3),\n",
       " (445, 9),\n",
       " (446, 2),\n",
       " (447, 2),\n",
       " (448, 1),\n",
       " (449, 2),\n",
       " (450, 1),\n",
       " (451, 2),\n",
       " (452, 1),\n",
       " (453, 5),\n",
       " (454, 2),\n",
       " (455, 2),\n",
       " (456, 4),\n",
       " (457, 1),\n",
       " (458, 2),\n",
       " (459, 4),\n",
       " (460, 2),\n",
       " (461, 1),\n",
       " (462, 1),\n",
       " (463, 1),\n",
       " (464, 2),\n",
       " (465, 1),\n",
       " (466, 1),\n",
       " (467, 1),\n",
       " (468, 1),\n",
       " (469, 2),\n",
       " (470, 8),\n",
       " (471, 9),\n",
       " (472, 1),\n",
       " (473, 1),\n",
       " (474, 4),\n",
       " (475, 1),\n",
       " (476, 7),\n",
       " (477, 1),\n",
       " (478, 1),\n",
       " (479, 2),\n",
       " (480, 1),\n",
       " (481, 1),\n",
       " (482, 1),\n",
       " (483, 14),\n",
       " (484, 1),\n",
       " (485, 5),\n",
       " (486, 2),\n",
       " (487, 4),\n",
       " (488, 7),\n",
       " (489, 1),\n",
       " (490, 2),\n",
       " (491, 1),\n",
       " (492, 1),\n",
       " (493, 7),\n",
       " (494, 2),\n",
       " (495, 1),\n",
       " (496, 1),\n",
       " (497, 10),\n",
       " (498, 1),\n",
       " (499, 3),\n",
       " (500, 1),\n",
       " (501, 1),\n",
       " (502, 1),\n",
       " (503, 2),\n",
       " (504, 2),\n",
       " (505, 1),\n",
       " (506, 1),\n",
       " (507, 1),\n",
       " (508, 2),\n",
       " (509, 1),\n",
       " (510, 1),\n",
       " (511, 8),\n",
       " (512, 3),\n",
       " (513, 1),\n",
       " (514, 1),\n",
       " (515, 1),\n",
       " (516, 3),\n",
       " (517, 3),\n",
       " (518, 1),\n",
       " (519, 1),\n",
       " (520, 1),\n",
       " (521, 1),\n",
       " (522, 1),\n",
       " (523, 1),\n",
       " (524, 1),\n",
       " (525, 2),\n",
       " (526, 1),\n",
       " (527, 1),\n",
       " (528, 12),\n",
       " (529, 1),\n",
       " (530, 15),\n",
       " (531, 1),\n",
       " (532, 1),\n",
       " (533, 3),\n",
       " (534, 10),\n",
       " (535, 2),\n",
       " (536, 1),\n",
       " (537, 2),\n",
       " (538, 1),\n",
       " (539, 2),\n",
       " (540, 1),\n",
       " (541, 2),\n",
       " (542, 1),\n",
       " (543, 1),\n",
       " (544, 1),\n",
       " (545, 1),\n",
       " (546, 1),\n",
       " (547, 6),\n",
       " (548, 1),\n",
       " (549, 1),\n",
       " (550, 3),\n",
       " (551, 2),\n",
       " (552, 2),\n",
       " (553, 3),\n",
       " (554, 2),\n",
       " (555, 4),\n",
       " (556, 1),\n",
       " (557, 1),\n",
       " (558, 7),\n",
       " (559, 1),\n",
       " (560, 4),\n",
       " (561, 2),\n",
       " (562, 1),\n",
       " (563, 1),\n",
       " (564, 1),\n",
       " (565, 2),\n",
       " (566, 1),\n",
       " (567, 9),\n",
       " (568, 1),\n",
       " (569, 1),\n",
       " (570, 4),\n",
       " (571, 1),\n",
       " (572, 1),\n",
       " (573, 1),\n",
       " (574, 2),\n",
       " (575, 2),\n",
       " (576, 1),\n",
       " (577, 1),\n",
       " (578, 1),\n",
       " (579, 11),\n",
       " (580, 4),\n",
       " (581, 3),\n",
       " (582, 1),\n",
       " (583, 1),\n",
       " (584, 1),\n",
       " (585, 4),\n",
       " (586, 1),\n",
       " (587, 2),\n",
       " (588, 1),\n",
       " (589, 1),\n",
       " (590, 1),\n",
       " (591, 7),\n",
       " (592, 1),\n",
       " (593, 1),\n",
       " (594, 1),\n",
       " (595, 3),\n",
       " (596, 3),\n",
       " (597, 1),\n",
       " (598, 1),\n",
       " (599, 1),\n",
       " (600, 1),\n",
       " (601, 1),\n",
       " (602, 1),\n",
       " (603, 1),\n",
       " (604, 1),\n",
       " (605, 2),\n",
       " (606, 3),\n",
       " (607, 1),\n",
       " (608, 2),\n",
       " (609, 1),\n",
       " (610, 1),\n",
       " (611, 1),\n",
       " (612, 1),\n",
       " (613, 1),\n",
       " (614, 1),\n",
       " (615, 1),\n",
       " (616, 1),\n",
       " (617, 1),\n",
       " (618, 2),\n",
       " (619, 21),\n",
       " (620, 1),\n",
       " (621, 4),\n",
       " (622, 1),\n",
       " (623, 3),\n",
       " (624, 1),\n",
       " (625, 6),\n",
       " (626, 6),\n",
       " (627, 1),\n",
       " (628, 1),\n",
       " (629, 1),\n",
       " (630, 1),\n",
       " (631, 20),\n",
       " (632, 1),\n",
       " (633, 2),\n",
       " (634, 1),\n",
       " (635, 1),\n",
       " (636, 1),\n",
       " (637, 3),\n",
       " (638, 1),\n",
       " (639, 4),\n",
       " (640, 1),\n",
       " (641, 2),\n",
       " (642, 1),\n",
       " (643, 3),\n",
       " (644, 1),\n",
       " (645, 1),\n",
       " (646, 1),\n",
       " (647, 7),\n",
       " (648, 3),\n",
       " (649, 2),\n",
       " (650, 4),\n",
       " (651, 9),\n",
       " (652, 1),\n",
       " (653, 5),\n",
       " (654, 1),\n",
       " (655, 1),\n",
       " (656, 8),\n",
       " (657, 3),\n",
       " (658, 1),\n",
       " (659, 1),\n",
       " (660, 1),\n",
       " (661, 5),\n",
       " (662, 1),\n",
       " (663, 1),\n",
       " (664, 1),\n",
       " (665, 2),\n",
       " (666, 1),\n",
       " (667, 1),\n",
       " (668, 1),\n",
       " (669, 3),\n",
       " (670, 1),\n",
       " (671, 1),\n",
       " (672, 2),\n",
       " (673, 1),\n",
       " (674, 2),\n",
       " (675, 1),\n",
       " (676, 2),\n",
       " (677, 1),\n",
       " (678, 1),\n",
       " (679, 3),\n",
       " (680, 1),\n",
       " (681, 1),\n",
       " (682, 3),\n",
       " (683, 1),\n",
       " (684, 1),\n",
       " (685, 1),\n",
       " (686, 1),\n",
       " (687, 6),\n",
       " (688, 2),\n",
       " (689, 1),\n",
       " (690, 1),\n",
       " (691, 1),\n",
       " (692, 1),\n",
       " (693, 13),\n",
       " (694, 3),\n",
       " (695, 1),\n",
       " (696, 1),\n",
       " (697, 1),\n",
       " (698, 1),\n",
       " (699, 1),\n",
       " (700, 1),\n",
       " (701, 1),\n",
       " (702, 1),\n",
       " (703, 1),\n",
       " (704, 1),\n",
       " (705, 1),\n",
       " (706, 1),\n",
       " (707, 1),\n",
       " (708, 1),\n",
       " (709, 1),\n",
       " (710, 1),\n",
       " (711, 2),\n",
       " (712, 1),\n",
       " (713, 1),\n",
       " (714, 4),\n",
       " (715, 1),\n",
       " (716, 1),\n",
       " (717, 1),\n",
       " (718, 1),\n",
       " (719, 1),\n",
       " (720, 1),\n",
       " (721, 8),\n",
       " (722, 4),\n",
       " (723, 3),\n",
       " (724, 1),\n",
       " (725, 4),\n",
       " (726, 1),\n",
       " (727, 1),\n",
       " (728, 1),\n",
       " (729, 1),\n",
       " (730, 1),\n",
       " (731, 1),\n",
       " (732, 2),\n",
       " (733, 1),\n",
       " (734, 1),\n",
       " (735, 1),\n",
       " (736, 6),\n",
       " (737, 9),\n",
       " (738, 1),\n",
       " (739, 1),\n",
       " (740, 1),\n",
       " (741, 1),\n",
       " (742, 2),\n",
       " (743, 1),\n",
       " (744, 1),\n",
       " (745, 1),\n",
       " (746, 2),\n",
       " (747, 2),\n",
       " (748, 1),\n",
       " (749, 5),\n",
       " (750, 3),\n",
       " (751, 1),\n",
       " (752, 1),\n",
       " (753, 1),\n",
       " (754, 1),\n",
       " (755, 2),\n",
       " (756, 1),\n",
       " (757, 2),\n",
       " (758, 14),\n",
       " (759, 2),\n",
       " (760, 1),\n",
       " (761, 4),\n",
       " (762, 1),\n",
       " (763, 1),\n",
       " (764, 1),\n",
       " (765, 2),\n",
       " (766, 1),\n",
       " (767, 1),\n",
       " (768, 1),\n",
       " (769, 2),\n",
       " (770, 1),\n",
       " (771, 2),\n",
       " (772, 1),\n",
       " (773, 2),\n",
       " (774, 6),\n",
       " (775, 1),\n",
       " (776, 3),\n",
       " (777, 1),\n",
       " (778, 1),\n",
       " (779, 1),\n",
       " (780, 1),\n",
       " (781, 2),\n",
       " (782, 1),\n",
       " (783, 1),\n",
       " (784, 2),\n",
       " (785, 2),\n",
       " (786, 1),\n",
       " (787, 1),\n",
       " (788, 3),\n",
       " (789, 1),\n",
       " (790, 3),\n",
       " (791, 1),\n",
       " (792, 1),\n",
       " (793, 3),\n",
       " (794, 1),\n",
       " (795, 1),\n",
       " (796, 1),\n",
       " (797, 1),\n",
       " (798, 1),\n",
       " (799, 10),\n",
       " (800, 1),\n",
       " (801, 2),\n",
       " (802, 1),\n",
       " (803, 1),\n",
       " (804, 5),\n",
       " (805, 1),\n",
       " (806, 1),\n",
       " (807, 1),\n",
       " (808, 3),\n",
       " (809, 5),\n",
       " (810, 2),\n",
       " (811, 3),\n",
       " (812, 1),\n",
       " (813, 2),\n",
       " (814, 2),\n",
       " (815, 4),\n",
       " (816, 3),\n",
       " (817, 3),\n",
       " (818, 3),\n",
       " (819, 3),\n",
       " (820, 1),\n",
       " (821, 2)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 15min 49s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "if prepare:\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=20, \n",
    "        random_state=100,\n",
    "        update_every=1,\n",
    "        chunksize=100,\n",
    "        passes=10,\n",
    "        alpha='auto',\n",
    "        per_word_topics=True)\n",
    "    lda_model.save('lda_default.pkl')\n",
    "else:\n",
    "    lda_model = gensim.models.ldamodel.LdaModel.load('lda_default.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.024*\"signal\" + 0.021*\"system\" + 0.018*\"time\" + 0.016*\"control\" + '\n",
      "  '0.014*\"source\" + 0.012*\"trajectory\" + 0.012*\"target\" + 0.009*\"noise\" + '\n",
      "  '0.009*\"dynamic\" + 0.008*\"figure\"'),\n",
      " (1,\n",
      "  '0.012*\"arxiv_preprint\" + 0.006*\"st\" + 0.006*\"kx\" + 0.005*\"long_beach\" + '\n",
      "  '0.005*\"eq\" + 0.005*\"respectively\" + 0.005*\"th\" + 0.004*\"al\" + 0.004*\"ii\" + '\n",
      "  '0.004*\"following\"'),\n",
      " (2,\n",
      "  '0.023*\"point\" + 0.012*\"solution\" + 0.011*\"function\" + 0.009*\"one\" + '\n",
      "  '0.009*\"case\" + 0.009*\"equation\" + 0.008*\"value\" + 0.008*\"problem\" + '\n",
      "  '0.008*\"local\" + 0.008*\"constraint\"'),\n",
      " (3,\n",
      "  '0.069*\"image\" + 0.020*\"object\" + 0.014*\"convolutional\" + 0.011*\"pixel\" + '\n",
      "  '0.010*\"model\" + 0.009*\"map\" + 0.008*\"visual\" + 0.008*\"recognition\" + '\n",
      "  '0.008*\"using\" + 0.008*\"frame\"'),\n",
      " (4,\n",
      "  '0.032*\"algorithm\" + 0.022*\"problem\" + 0.019*\"optimization\" + 0.017*\"method\" '\n",
      "  '+ 0.017*\"function\" + 0.013*\"gradient\" + 0.012*\"loss\" + 0.011*\"convex\" + '\n",
      "  '0.011*\"learning\" + 0.010*\"objective\"'),\n",
      " (5,\n",
      "  '0.012*\"set\" + 0.010*\"number\" + 0.009*\"algorithm\" + 0.008*\"query\" + '\n",
      "  '0.008*\"data\" + 0.007*\"page\" + 0.007*\"one\" + 0.006*\"search\" + 0.006*\"item\" + '\n",
      "  '0.006*\"user\"'),\n",
      " (6,\n",
      "  '0.033*\"training\" + 0.024*\"classification\" + 0.024*\"data\" + 0.020*\"class\" + '\n",
      "  '0.019*\"label\" + 0.016*\"classifier\" + 0.015*\"learning\" + 0.015*\"set\" + '\n",
      "  '0.014*\"test\" + 0.011*\"example\"'),\n",
      " (7,\n",
      "  '0.044*\"model\" + 0.027*\"sequence\" + 0.023*\"state\" + 0.020*\"word\" + '\n",
      "  '0.012*\"context\" + 0.012*\"language\" + 0.011*\"representation\" + '\n",
      "  '0.009*\"memory\" + 0.009*\"attention\" + 0.008*\"sentence\"'),\n",
      " (8,\n",
      "  '0.019*\"data\" + 0.015*\"kernel\" + 0.015*\"function\" + 0.012*\"method\" + '\n",
      "  '0.012*\"point\" + 0.009*\"space\" + 0.009*\"gaussian\" + 0.009*\"mean\" + '\n",
      "  '0.008*\"sample\" + 0.008*\"linear\"'),\n",
      " (9,\n",
      "  '0.022*\"bound\" + 0.016*\"theorem\" + 0.015*\"algorithm\" + 0.014*\"log\" + '\n",
      "  '0.011*\"function\" + 0.011*\"let\" + 0.010*\"probability\" + 0.010*\"distribution\" '\n",
      "  '+ 0.010*\"result\" + 0.009*\"learning\"'),\n",
      " (10,\n",
      "  '0.020*\"model\" + 0.014*\"cell\" + 0.014*\"response\" + 0.010*\"figure\" + '\n",
      "  '0.007*\"visual\" + 0.007*\"direction\" + 0.007*\"unit\" + 0.007*\"brain\" + '\n",
      "  '0.007*\"pattern\" + 0.007*\"two\"'),\n",
      " (11,\n",
      "  '0.043*\"neuron\" + 0.018*\"neural\" + 0.015*\"time\" + 0.014*\"activity\" + '\n",
      "  '0.012*\"dynamic\" + 0.010*\"input\" + 0.009*\"spike\" + 0.009*\"model\" + '\n",
      "  '0.009*\"rate\" + 0.009*\"network\"'),\n",
      " (12,\n",
      "  '0.060*\"matrix\" + 0.017*\"rank\" + 0.016*\"sparse\" + 0.013*\"algorithm\" + '\n",
      "  '0.011*\"vector\" + 0.010*\"tensor\" + 0.009*\"column\" + 0.009*\"method\" + '\n",
      "  '0.009*\"low\" + 0.008*\"analysis\"'),\n",
      " (13,\n",
      "  '0.052*\"feature\" + 0.036*\"task\" + 0.024*\"model\" + 0.023*\"learning\" + '\n",
      "  '0.011*\"representation\" + 0.009*\"different\" + 0.008*\"group\" + 0.008*\"human\" '\n",
      "  '+ 0.008*\"object\" + 0.008*\"domain\"'),\n",
      " (14,\n",
      "  '0.025*\"policy\" + 0.024*\"state\" + 0.020*\"action\" + 0.019*\"learning\" + '\n",
      "  '0.015*\"reward\" + 0.014*\"agent\" + 0.013*\"algorithm\" + 0.011*\"value\" + '\n",
      "  '0.010*\"function\" + 0.010*\"game\"'),\n",
      " (15,\n",
      "  '0.016*\"memory\" + 0.014*\"system\" + 0.013*\"distributed\" + 0.012*\"parallel\" + '\n",
      "  '0.012*\"bit\" + 0.010*\"communication\" + 0.010*\"input\" + 0.009*\"block\" + '\n",
      "  '0.009*\"computation\" + 0.009*\"implementation\"'),\n",
      " (16,\n",
      "  '0.035*\"graph\" + 0.033*\"node\" + 0.021*\"algorithm\" + 0.021*\"cluster\" + '\n",
      "  '0.020*\"clustering\" + 0.017*\"tree\" + 0.016*\"edge\" + 0.015*\"set\" + '\n",
      "  '0.013*\"structure\" + 0.011*\"network\"'),\n",
      " (17,\n",
      "  '0.068*\"network\" + 0.029*\"neural\" + 0.023*\"layer\" + 0.022*\"learning\" + '\n",
      "  '0.022*\"input\" + 0.017*\"weight\" + 0.017*\"output\" + 0.016*\"unit\" + '\n",
      "  '0.016*\"training\" + 0.013*\"deep\"'),\n",
      " (18,\n",
      "  '0.053*\"model\" + 0.024*\"distribution\" + 0.014*\"inference\" + 0.013*\"log\" + '\n",
      "  '0.013*\"variable\" + 0.012*\"parameter\" + 0.010*\"latent\" + 0.010*\"likelihood\" '\n",
      "  '+ 0.009*\"posterior\" + 0.009*\"data\"'),\n",
      " (19,\n",
      "  '0.039*\"time\" + 0.022*\"xt\" + 0.013*\"prediction\" + 0.010*\"online\" + '\n",
      "  '0.009*\"adversarial\" + 0.009*\"process\" + 0.008*\"event\" + 0.008*\"model\" + '\n",
      "  '0.008*\"data\" + 0.006*\"round\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
       "\n",
       "\n",
       "<div id=\"ldavis_el1123221260817831524039933797\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "\n",
       "var ldavis_el1123221260817831524039933797_data = {\"mdsDat\": {\"x\": [-0.12066194339734104, -0.14307291739155006, -0.09129339123025812, -0.1510499597339456, -0.11353658128076852, -0.03211201127913745, -0.08161931625559767, -0.02994900886943815, -0.0647169376959638, -0.08794327847715679, -0.060511479843398004, 0.07956268746587106, 0.018616203748163744, -0.019873202205141396, 0.1100541999975719, 0.08030524533099241, 0.07439714295361233, 0.3514565261004785, 0.16409682546165366, 0.11785119660135243], \"y\": [-0.030538759382673798, -0.13989403015258392, -0.03689099739924701, -0.13011570585633891, 0.010938449288438764, 0.07276253190013435, 0.05835537672477674, -0.13087464617996922, 0.001130878003222125, -0.10121183333020002, -0.04796047424249973, 0.13719190993982722, 0.09712781880568487, 0.10934909074767157, 0.1114219227453277, 0.11249937941699852, 0.03349855963973664, -0.3423935885417558, 0.14180997315896315, 0.07379414471448578], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [9.90141956935927, 9.693207436130201, 9.282038353359672, 7.850170674002236, 7.405190734888604, 5.800398493172438, 4.93270971549362, 4.771500450156235, 4.701760145234893, 4.5283986686199285, 4.353325045673227, 4.249203063739771, 3.9287481864093294, 3.803670799893015, 3.077863186812573, 2.6798659335899737, 2.6353971817644166, 2.3190970588611868, 2.2849953382437507, 1.801039964595658]}, \"tinfo\": {\"Term\": [\"model\", \"network\", \"image\", \"matrix\", \"feature\", \"algorithm\", \"learning\", \"training\", \"time\", \"graph\", \"neuron\", \"distribution\", \"bound\", \"data\", \"node\", \"neural\", \"state\", \"task\", \"point\", \"log\", \"function\", \"layer\", \"input\", \"policy\", \"kernel\", \"optimization\", \"classification\", \"theorem\", \"class\", \"system\", \"gp\", \"tangent\", \"manifold\", \"gps\", \"wasserstein\", \"covariates\", \"extrapolation\", \"cca\", \"riemannian\", \"kernel\", \"reproducing_kernel\", \"nystr\", \"geodesic\", \"spline\", \"spherical\", \"ridge\", \"fake\", \"regularizers\", \"regressor\", \"resampling\", \"nystr_om\", \"ylx\", \"control_variate\", \"covariate\", \"kvk\", \"riemannian_manifold\", \"bundle\", \"sect\", \"sollich\", \"glms\", \"rkhs\", \"isotropic\", \"mse\", \"regression\", \"outlier\", \"estimator\", \"ridge_regression\", \"variance\", \"covariance\", \"density\", \"dimensional\", \"squared\", \"gaussian\", \"multivariate\", \"distance\", \"dimension\", \"point\", \"space\", \"mean\", \"regularizer\", \"data\", \"metric\", \"estimation\", \"estimate\", \"nonlinear\", \"linear\", \"function\", \"method\", \"sample\", \"statistic\", \"error\", \"xi\", \"approximation\", \"test\", \"using\", \"noise\", \"approach\", \"based\", \"set\", \"parameter\", \"two\", \"corollary\", \"minimax\", \"sup\", \"pac\", \"vc_dimension\", \"hardness\", \"rademacher_complexity\", \"radon\", \"almost_surely\", \"annual_acm\", \"proof_sketch\", \"sobolev\", \"polynomially\", \"provable\", \"excess_risk\", \"concentration_inequality\", \"martingale\", \"hindsight\", \"rademacher\", \"matroid\", \"balcan\", \"adversarially\", \"supremum\", \"acm_symposium\", \"stoc\", \"lugosi\", \"chernoff\", \"computing_stoc\", \"ctm\", \"oco\", \"theorem\", \"bound\", \"lemma\", \"colt\", \"bounded\", \"proof\", \"thm\", \"oracle\", \"ln_ln\", \"prove\", \"adversary\", \"risk\", \"hold\", \"inf\", \"optimistic\", \"guarantee\", \"upper\", \"let\", \"hypothesis\", \"satisfies\", \"concave\", \"assumption\", \"inequality\", \"exists\", \"definition\", \"log\", \"remark\", \"ln\", \"complexity\", \"probability\", \"polynomial\", \"empirical\", \"least\", \"lower\", \"constant\", \"condition\", \"theory\", \"case\", \"setting\", \"distribution\", \"sample\", \"algorithm\", \"result\", \"function\", \"error\", \"optimal\", \"rate\", \"learning\", \"random\", \"following\", \"set\", \"consider\", \"given\", \"show\", \"section\", \"variational\", \"mcmc\", \"particle\", \"dirichlet\", \"sampler\", \"message_passing\", \"elbo\", \"marginals\", \"gibbs_sampling\", \"ising\", \"belief_propagation\", \"free_energy\", \"hmc\", \"welling\", \"copula\", \"expectation_maximization\", \"nats\", \"gibbs_sampler\", \"rip\", \"latents\", \"exchangeable\", \"seminal\", \"maximum_posteriori\", \"aaron_courville\", \"nonsmooth\", \"imm\", \"ancestral\", \"evy\", \"spin_glass\", \"marginalization\", \"posterior\", \"likelihood\", \"bayesian\", \"inference\", \"latent\", \"private\", \"exponential_family\", \"lifted\", \"mixture\", \"em\", \"markov_chain\", \"gamma\", \"inducing\", \"prior\", \"marginal\", \"mle\", \"generative\", \"kl_divergence\", \"conditional\", \"probabilistic\", \"monte_carlo\", \"distribution\", \"model\", \"variable\", \"log\", \"graphical\", \"parameter\", \"sampling\", \"process\", \"probability\", \"gaussian\", \"sample\", \"approximate\", \"data\", \"observation\", \"stochastic\", \"using\", \"estimate\", \"factor\", \"mean\", \"method\", \"given\", \"approach\", \"algorithm\", \"strongly_convex\", \"coordinate_descent\", \"svrg\", \"screening\", \"primal\", \"erm\", \"hinge_loss\", \"multiclass\", \"primal_dual\", \"subgradient\", \"frank_wolfe\", \"mathematical_programming\", \"polytope\", \"nesterov\", \"mirror_descent\", \"kwk\", \"thread\", \"bregman_divergence\", \"submodular_maximization\", \"duality\", \"prognostic\", \"transductive\", \"hedge\", \"shalev_shwartz\", \"lagrangian\", \"conic\", \"saga\", \"pseudocode\", \"sdca\", \"bnn\", \"dual\", \"descent\", \"bfgs\", \"accelerated\", \"optimization\", \"convex\", \"submodular\", \"sgd\", \"objective\", \"kxk\", \"xk_xk\", \"gradient\", \"iterates\", \"gradient_descent\", \"regularized\", \"loss\", \"minimization\", \"xk\", \"batch\", \"convergence\", \"iteration\", \"problem\", \"algorithm\", \"update\", \"regularization\", \"solution\", \"stochastic\", \"method\", \"smooth\", \"min\", \"constraint\", \"max\", \"yi\", \"function\", \"xi\", \"linear\", \"step\", \"cost\", \"learning\", \"machine\", \"set\", \"optimal\", \"parameter\", \"rate\", \"vector\", \"non\", \"query\", \"ranking\", \"document\", \"hash\", \"runtime\", \"relu\", \"ucb\", \"hashing\", \"annotation\", \"web\", \"bounding_box\", \"tau\", \"vanilla\", \"clump\", \"leveraging\", \"collaborative_filtering\", \"pointer\", \"counterfactual\", \"cold_start\", \"predicate\", \"mips\", \"querying\", \"bach\", \"prox\", \"ranked\", \"alice\", \"lsh\", \"wikipedia\", \"peer\", \"amortized\", \"item\", \"topic\", \"hop\", \"retrieval\", \"coverage\", \"speedup\", \"triplet\", \"bag\", \"user\", \"scoring\", \"preference\", \"search\", \"google\", \"active\", \"list\", \"recommendation\", \"candidate\", \"instance\", \"score\", \"page\", \"number\", \"set\", \"evaluation\", \"comparison\", \"top\", \"program\", \"datasets\", \"size\", \"algorithm\", \"one\", \"large\", \"data\", \"approach\", \"based\", \"machine\", \"work\", \"using\", \"experiment\", \"two\", \"information\", \"result\", \"learning\", \"value\", \"example\", \"problem\", \"method\", \"backpropagation\", \"generative_adversarial\", \"feed_forward\", \"mini_batch\", \"iclr\", \"resnet\", \"back_propagation\", \"momentum\", \"batch_normalization\", \"rnns\", \"minibatch\", \"vae\", \"tensorflow\", \"shallow\", \"multilayer\", \"encoder_decoder\", \"lstms\", \"deep\", \"rbm\", \"ilya_sutskever\", \"backprop\", \"vqa\", \"dnns\", \"mtse_query\", \"le_cun\", \"thermodynamic_limit\", \"wgan\", \"ian_goodfellow\", \"kingma_ba\", \"vaes\", \"layer\", \"encoder\", \"net\", \"rumelhart\", \"yoshua_bengio\", \"architecture\", \"fine_tuning\", \"network\", \"fully_connected\", \"layered\", \"recurrent\", \"geoffrey_hinton\", \"unit\", \"rnn\", \"feedforward\", \"hidden\", \"activation\", \"weight\", \"teacher\", \"neural\", \"output\", \"input\", \"module\", \"sigmoid\", \"trained\", \"training\", \"learning\", \"softmax\", \"error\", \"pattern\", \"one\", \"parameter\", \"function\", \"used\", \"representation\", \"number\", \"gradient\", \"system\", \"result\", \"figure\", \"performance\", \"using\", \"et_al\", \"classifier\", \"discriminator\", \"unlabeled\", \"speaker\", \"phoneme\", \"vowel\", \"utterance\", \"phone\", \"knn\", \"hme\", \"snn\", \"fom\", \"timit\", \"recognizer\", \"triple_gan\", \"phonetic\", \"genome\", \"handwritten_character\", \"lenet\", \"absolute_discounting\", \"mnist_cifar\", \"correctly_classified\", \"cae\", \"maf\", \"talker\", \"transcription\", \"rcs\", \"nmse\", \"diabolo\", \"dcnn\", \"semi_supervised\", \"classification\", \"label\", \"labeled\", \"mnist\", \"supervision\", \"voice\", \"discriminative\", \"audio\", \"validation\", \"training\", \"class\", \"supervised\", \"ensemble\", \"accuracy\", \"test\", \"train\", \"pruning\", \"recognition\", \"classify\", \"data\", \"prediction\", \"speech\", \"svm\", \"datasets\", \"example\", \"performance\", \"set\", \"testing\", \"table\", \"learning\", \"dataset\", \"trained\", \"using\", \"error\", \"used\", \"feature\", \"method\", \"sample\", \"based\", \"vector\", \"result\", \"approach\", \"machine\", \"cnn\", \"saddle\", \"sublinear\", \"supp\", \"lyapunov\", \"clause\", \"ttur\", \"es\", \"bij\", \"barycenter\", \"reg\", \"ols\", \"reversible\", \"hypergraph\", \"vincent\", \"bai\", \"fascicle\", \"attraction\", \"sst\", \"continuously_differentiable\", \"tsp\", \"chu\", \"poincar\", \"dx_dx\", \"smd\", \"xiong\", \"underdetermined\", \"impossibility\", \"tract\", \"hilbert\", \"contraction\", \"embeddings\", \"nonconvex\", \"bipartite\", \"perturbation\", \"lattice\", \"completion\", \"statistical_mechanic\", \"vi\", \"perturbed\", \"stable\", \"formula\", \"symmetry\", \"ij\", \"stability\", \"point\", \"equation\", \"minimum\", \"diffusion\", \"solution\", \"supplementary\", \"monotonic\", \"constraint\", \"critical\", \"local\", \"energy\", \"equilibrium\", \"symmetric\", \"limit\", \"theory\", \"operator\", \"map\", \"ai\", \"continuous\", \"xj\", \"global\", \"case\", \"property\", \"order\", \"xi\", \"value\", \"ii\", \"one\", \"function\", \"system\", \"problem\", \"condition\", \"two\", \"result\", \"given\", \"set\", \"policy\", \"reward\", \"agent\", \"reinforcement\", \"player\", \"bandit\", \"mdp\", \"skill\", \"payoff\", \"mdps\", \"critic\", \"multi_armed\", \"bellman\", \"imitation\", \"nash_equilibrium\", \"iearning\", \"actor_critic\", \"contextual_bandit\", \"sutton\", \"discounted\", \"thompson_sampling\", \"rollout\", \"pomdp\", \"atari_game\", \"discount_factor\", \"torque\", \"dueling_bandit\", \"partially_observable\", \"trpo\", \"mcts\", \"arm\", \"episode\", \"planning\", \"game\", \"action\", \"robot\", \"exploration\", \"opponent\", \"rl\", \"environment\", \"regret\", \"horizon\", \"state\", \"expert\", \"st\", \"option\", \"trajectory\", \"learning\", \"control\", \"optimal\", \"value\", \"strategy\", \"decision\", \"transition\", \"algorithm\", \"function\", \"step\", \"problem\", \"dynamic\", \"time\", \"based\", \"system\", \"space\", \"using\", \"tensor\", \"svd\", \"denoising\", \"nuclear_norm\", \"vec\", \"mab\", \"ica\", \"frobenius_norm\", \"kak\", \"tang\", \"lanczos\", \"compressed_sensing\", \"deconvolution\", \"nnz\", \"incoherence\", \"subgaussian\", \"hard_thresholding\", \"nmf\", \"iht\", \"sbl\", \"pvi\", \"schatten_norm\", \"siam_review\", \"terrence_sejnowski\", \"gtf\", \"preconditioning\", \"mpgm\", \"denoiser\", \"whitening\", \"matching_pursuit\", \"singular\", \"recovery\", \"eigenvectors\", \"matrix\", \"subspace\", \"sparsity\", \"pca\", \"rank\", \"sparse\", \"entry\", \"corruption\", \"lasso\", \"column\", \"decomposition\", \"factorization\", \"spectral\", \"orthogonal\", \"eigenvalue\", \"row\", \"principal_component\", \"norm\", \"low\", \"diagonal\", \"projection\", \"vector\", \"recover\", \"rn\", \"analysis\", \"block\", \"algorithm\", \"method\", \"component\", \"noise\", \"error\", \"problem\", \"data\", \"linear\", \"result\", \"signal\", \"graph\", \"cluster\", \"clustering\", \"vertex\", \"dag\", \"transport\", \"clique\", \"fdr\", \"adjacency\", \"subgraph\", \"auto_encoder\", \"axiom\", \"dpp\", \"graphon\", \"soda\", \"amino_acid\", \"downstream\", \"interventional\", \"eoo\", \"fritzke\", \"directed_acyclic\", \"pointnet\", \"rna\", \"mjk\", \"pew\", \"clarans\", \"martinetz\", \"hpc\", \"treewidth\", \"nyi\", \"node\", \"protein\", \"tree\", \"edge\", \"gene\", \"parent\", \"leaf\", \"causal\", \"partitioning\", \"molecule\", \"community\", \"cut\", \"child\", \"partition\", \"neighbor\", \"directed\", \"structure\", \"path\", \"topology\", \"assignment\", \"connected\", \"degree\", \"algorithm\", \"set\", \"link\", \"network\", \"variable\", \"number\", \"hierarchical\", \"two\", \"data\", \"distance\", \"problem\", \"random\", \"time\", \"figure\", \"one\", \"size\", \"based\", \"center\", \"weight\", \"different\", \"retina\", \"pathway\", \"retinal\", \"crf\", \"lgn\", \"shapley\", \"owl\", \"lesion\", \"barn_owl\", \"psychophysical\", \"fixation\", \"shunting\", \"attentional\", \"flanker\", \"anatomical\", \"hasselmo\", \"ocular_dominance\", \"saccade\", \"lateral\", \"aifnn\", \"compartmental\", \"triggering\", \"eye_movement\", \"eccentricity\", \"center_surround\", \"glomerulus\", \"shap\", \"orange\", \"crfs\", \"parietal_cortex\", \"roi\", \"eye\", \"observer\", \"gaze\", \"response\", \"receptive_field\", \"cell\", \"cue\", \"orientation\", \"behavioral\", \"brain\", \"cognitive\", \"stimulus\", \"head\", \"spatial\", \"receptor\", \"subject\", \"sensory\", \"animal\", \"perceptual\", \"motion\", \"visual\", \"direction\", \"area\", \"auditory\", \"location\", \"perception\", \"region\", \"field\", \"trial\", \"pattern\", \"model\", \"map\", \"unit\", \"position\", \"figure\", \"effect\", \"human\", \"two\", \"study\", \"center\", \"activity\", \"information\", \"one\", \"different\", \"input\", \"processing\", \"convolutional\", \"pixel\", \"camera\", \"texture\", \"pyramid\", \"vgg\", \"optical_flow\", \"dnn\", \"eccv\", \"lighting\", \"rgb\", \"mst\", \"capsule\", \"occlusion\", \"translation_rotation\", \"video\", \"csc\", \"trevor_darrell\", \"inpainting\", \"convnet\", \"acnn\", \"super_resolution\", \"fcn\", \"celeba\", \"pixelcnn\", \"spark\", \"stereo\", \"illumination\", \"rladder\", \"pascal_voc\", \"image\", \"scene\", \"patch\", \"segmentation\", \"cvpr\", \"deformation\", \"iccv\", \"convolution\", \"pose\", \"computer_vision\", \"appearance\", \"elastic\", \"object\", \"frame\", \"mask\", \"descriptor\", \"pooling\", \"shape\", \"detection\", \"road\", \"resolution\", \"visual\", \"reconstruction\", \"filter\", \"rotation\", \"color\", \"recognition\", \"map\", \"motion\", \"scale\", \"vision\", \"transformation\", \"using\", \"model\", \"region\", \"figure\", \"spatial\", \"location\", \"approach\", \"method\", \"result\", \"based\", \"gan\", \"dropout\", \"gans\", \"imagenet\", \"rating\", \"autoencoder\", \"participant\", \"facial\", \"captioning\", \"irl\", \"handwriting\", \"writer\", \"facial_expression\", \"dcgan\", \"crop\", \"eigen\", \"sift\", \"generator_discriminator\", \"sgan\", \"siamese\", \"blur\", \"chair\", \"kxi\", \"omniglot\", \"inception_score\", \"krr\", \"glove\", \"ag_cvae\", \"mmd_gan\", \"cursive_handwriting\", \"dictionary\", \"shot\", \"feature\", \"category\", \"movie\", \"task\", \"categorization\", \"exemplar\", \"transfer\", \"semantic\", \"attribute\", \"face\", \"view\", \"caption\", \"ground_truth\", \"people\", \"human\", \"similarity\", \"shared\", \"group\", \"generator\", \"learned\", \"representation\", \"domain\", \"learn\", \"learning\", \"object\", \"model\", \"multi\", \"different\", \"multiple\", \"across\", \"information\", \"experiment\", \"two\", \"performance\", \"example\", \"dataset\", \"one\", \"spike\", \"synaptic\", \"firing\", \"spiking\", \"oscillator\", \"hippocampal\", \"spike_train\", \"dendritic\", \"correlogram\", \"membrane\", \"odor\", \"membrane_potential\", \"pmd\", \"calcium\", \"somatic\", \"excitatory_inhibitory\", \"synchrony\", \"soma\", \"pyramidal_cell\", \"presynaptic\", \"calcium_imaging\", \"synaptic_transmission\", \"interneurons\", \"postsynaptic\", \"olfactory\", \"biophysical\", \"dendrite\", \"ganglion\", \"pinter\", \"de_vries\", \"neuron\", \"excitatory\", \"conductance\", \"hippocampus\", \"neuronal\", \"attractor\", \"inhibitory\", \"oscillatory\", \"synapsis\", \"fire\", \"activity\", \"hebbian\", \"axon\", \"oscillation\", \"population\", \"connectivity\", \"recording\", \"dynamic\", \"neural\", \"intensity\", \"fig\", \"time\", \"coding\", \"rate\", \"input\", \"correlation\", \"current\", \"biological\", \"information\", \"cell\", \"pattern\", \"simulation\", \"noise\", \"network\", \"connection\", \"state\", \"model\", \"temporal\", \"threshold\", \"stimulus\", \"system\", \"function\", \"parameter\", \"sentence\", \"phrase\", \"grammar\", \"parsing\", \"tbe\", \"motif\", \"gru\", \"question_answering\", \"sbm\", \"schema\", \"consciousness\", \"turing\", \"transducer\", \"cleanup\", \"nadel\", \"isotonic_regression\", \"bee\", \"efe\", \"catastrophic_interference\", \"suffix\", \"grammatical\", \"bleu_score\", \"ming\", \"fsm\", \"musical\", \"attentivechrome\", \"dude\", \"syllable\", \"infant\", \"sardnet\", \"token\", \"symbolic\", \"string\", \"symbol\", \"language\", \"hmm\", \"music\", \"cyclic\", \"automaton\", \"hmms\", \"word\", \"sequence\", \"english\", \"lstm\", \"attention\", \"context\", \"character\", \"memory\", \"translation\", \"alignment\", \"length\", \"state\", \"question\", \"model\", \"representation\", \"embedding\", \"rule\", \"text\", \"long\", \"structure\", \"vector\", \"system\", \"modeling\", \"speech\", \"transition\", \"time\", \"level\", \"figure\", \"budget\", \"privacy\", \"streaming\", \"auction\", \"fairness\", \"market\", \"revenue\", \"server\", \"fmri\", \"bid\", \"differential_privacy\", \"centralized\", \"influence_maximization\", \"click\", \"hawkes_process\", \"service\", \"security\", \"voxels\", \"differentially_private\", \"buyer\", \"unfairness\", \"nll\", \"bidder\", \"bucket\", \"consolidation\", \"seller\", \"trader\", \"party\", \"glimpse\", \"probing\", \"price\", \"allocation\", \"adversarial\", \"routing\", \"forecasting\", \"attack\", \"xt\", \"event\", \"yt\", \"vt\", \"fair\", \"outcome\", \"offline\", \"pt\", \"round\", \"utility\", \"online\", \"time\", \"day\", \"ct\", \"ut\", \"prediction\", \"bt\", \"zt\", \"patient\", \"individual\", \"process\", \"user\", \"influence\", \"mechanism\", \"cost\", \"data\", \"series\", \"model\", \"rate\", \"system\", \"setting\", \"change\", \"information\", \"value\", \"sequence\", \"kx\", \"pg\", \"tk\", \"pu\", \"sr\", \"conv\", \"gc\", \"fc\", \"xr\", \"dqn\", \"fm\", \"lds\", \"cr\", \"hx\", \"vb\", \"gb\", \"sg\", \"lg\", \"stein\", \"clipping\", \"dialog\", \"vpn\", \"kz\", \"hp\", \"psd\", \"gu\", \"ph\", \"hw\", \"kv\", \"pv\", \"pe\", \"sp\", \"survival\", \"tp\", \"ip\", \"f\", \"long_beach\", \"quadrature\", \"hm\", \"ga\", \"da\", \"al\", \"arxiv_preprint\", \"l\", \"mc\", \"dc\", \"pd\", \"px\", \"mk\", \"t\", \"xu\", \"st\", \"ht\", \"aggregation\", \"respectively\", \"th\", \"eq\", \"ii\", \"bp\", \"following\", \"denotes\", \"proposed\", \"nd\", \"index\", \"eeg\", \"muscle\", \"spectrogram\", \"amp\", \"cochlear\", \"ladder\", \"calibration\", \"principe\", \"pitch\", \"quantum\", \"motor_command\", \"cursor\", \"mae\", \"rpfb\", \"visuomotor\", \"nlp\", \"spectrogram_inversion\", \"ramp\", \"interconnect\", \"peptide\", \"pc_bo\", \"dmd\", \"meg\", \"frequency_band\", \"hra\", \"automatic_differentiation\", \"articulator\", \"compressive\", \"physic_engine\", \"felix\", \"plant\", \"supplement\", \"sound\", \"waveform\", \"movement\", \"source\", \"clinical\", \"sensor\", \"motor\", \"adaptation\", \"signal\", \"sensing\", \"force\", \"finger\", \"trajectory\", \"channel\", \"control\", \"frequency\", \"filtering\", \"physical\", \"target\", \"filter\", \"controller\", \"measurement\", \"system\", \"amplitude\", \"feedback\", \"time\", \"dynamic\", \"noise\", \"domain\", \"figure\", \"change\", \"using\", \"hand\", \"real\", \"used\", \"error\", \"output\", \"state\", \"chip\", \"processor\", \"cnns\", \"hardware\", \"wta\", \"transistor\", \"analog_vlsi\", \"vlsi\", \"tunneling\", \"lloyd\", \"silicon\", \"floating_gate\", \"kohonen\", \"cmos\", \"ccd\", \"coreset\", \"iou\", \"graf\", \"reedy\", \"readout\", \"steganographic\", \"federated\", \"mapreduce\", \"slate\", \"inception\", \"oxide\", \"drain\", \"arti\", \"comparator\", \"batching\", \"proximal\", \"quantization\", \"asynchronous\", \"communication\", \"quantized\", \"floating\", \"analog\", \"stored\", \"bit\", \"parallel\", \"storage\", \"digital\", \"distributed\", \"circuit\", \"memory\", \"charge\", \"implementation\", \"worker\", \"device\", \"block\", \"decoder\", \"voltage\", \"operation\", \"computation\", \"core\", \"delay\", \"system\", \"current\", \"input\", \"output\", \"code\", \"figure\", \"time\", \"vector\", \"processing\", \"neural\", \"number\", \"using\", \"scheme\"], \"Freq\": [155714.0, 78634.0, 45252.0, 51044.0, 40977.0, 118185.0, 106527.0, 46448.0, 64073.0, 25340.0, 22107.0, 59960.0, 37705.0, 91194.0, 24332.0, 51518.0, 45986.0, 32570.0, 44397.0, 46700.0, 94123.0, 22732.0, 42050.0, 19280.0, 25169.0, 27308.0, 20053.0, 26733.0, 27084.0, 44755.0, 4667.7805743889885, 3760.038499996674, 3726.0802135692734, 1100.6847399033556, 1070.0691915176196, 845.3680996797482, 789.9267289911215, 718.3003012286749, 685.9644696311407, 25135.970283287683, 665.5940056459297, 645.9549342973669, 644.2458734120537, 639.9903387980291, 574.2089911254357, 572.6237546441646, 571.9319479355389, 569.7256006673381, 528.6081328648153, 523.0775620260704, 463.5249370137123, 429.7767969362692, 426.0007918594282, 355.42126036809765, 348.14526262403785, 340.9165217653448, 330.62536426916665, 330.4641321101749, 326.94927104415325, 322.6945887587225, 1389.7035891635185, 839.2066162752451, 2798.2481860022817, 11008.692785142286, 2023.7226085366367, 11919.642645548916, 775.0326656273611, 11425.828459946124, 6438.252303103833, 8819.3159474629, 10267.572238143495, 3495.392744501334, 14464.070785635107, 2134.398044659245, 9547.48185746151, 6961.876775977584, 19107.35089048609, 15153.052309081908, 13910.073867431203, 1644.3596747269391, 31216.19457372249, 5330.344078368112, 7804.278961557299, 9585.9214982287, 4239.22255999025, 12416.503242952265, 24856.174671147266, 19266.899226989288, 13063.753243196306, 4512.843903797254, 10766.123855476924, 7728.364137178379, 7501.313648923316, 6999.833809354336, 10626.749568569658, 6384.157848351336, 8084.552635335653, 7399.457730276531, 7988.154650190787, 7153.335537406838, 6678.82640504702, 3627.5511055427596, 2786.2162563008583, 1913.1311694058002, 1685.6461152238116, 834.8257455014782, 682.2174497213524, 576.8677892517891, 528.5882125899627, 525.9973374962697, 507.12855755161, 446.7518178926034, 440.0500128628048, 423.48595331871456, 414.83418924692, 361.9100804016942, 360.9618713869782, 360.9313460564385, 358.5427679141129, 333.8895421328456, 320.1762749616227, 310.09531352328173, 296.03801637392564, 285.89375601553604, 271.9620832333215, 253.28635224694997, 251.63742812754342, 250.0426940026713, 249.57781431046507, 242.01786969228112, 235.33208061039667, 25217.994553287732, 34628.63363973248, 10786.379251813083, 1104.941869053572, 7287.126319130215, 10508.79890848345, 492.273360247485, 3843.135128350216, 737.323250527888, 3917.107205885239, 1234.4033884513908, 4940.150517039851, 6393.452928203875, 1451.1817235079372, 546.5818403474397, 7271.5819029734475, 6198.594793605441, 16986.019462661247, 4366.088137778852, 3552.778740526433, 1944.2020156475817, 10256.762495511632, 2731.185551979477, 3830.507422592174, 6079.799941874316, 22386.193247110597, 2113.3443323777356, 2689.167677859759, 9100.44276351334, 16599.47393394869, 4002.0329865413246, 6276.325403866604, 4722.340300650253, 8022.992512422681, 7696.7948900273, 8289.790113024617, 7347.5046348882925, 13607.484593423145, 8720.042908637743, 16283.194981143177, 13562.374783772673, 23593.869332936873, 15264.048528586125, 17255.321021128686, 10719.195154842366, 8659.198067554606, 8429.762544416215, 14375.13161923309, 8865.194587000555, 8220.406894291098, 10679.15704657943, 7528.850223167799, 7641.890273631612, 7529.430227625982, 7349.21646390298, 13311.195416733017, 2412.6794269196794, 1999.141687957533, 1531.2800545486607, 1333.7472236929686, 1218.2875078555676, 1217.8682044506454, 1191.6413668533771, 840.2120236627918, 786.5310670222161, 692.0937839115879, 683.2256900166113, 668.6548301112855, 583.8031530952067, 575.0072365595782, 667.7357007123528, 500.78760418003833, 477.14716634893534, 470.8793661398508, 449.249196496204, 414.2046027195194, 412.3735350238768, 400.18661428447797, 397.79459622593026, 396.4679710343672, 368.31862333047405, 367.5615156791558, 351.42055406564634, 337.81640912458005, 335.1084264634242, 14399.130702384702, 15402.566808197791, 13109.733758250513, 22082.804606383423, 15426.565558233482, 1211.5043453205094, 2073.5282249318757, 769.7465017597582, 9797.97514586013, 6875.231370945287, 2640.9013962495405, 1955.683105074391, 1441.0270163623154, 12990.238591159516, 4131.86173964583, 1631.6660659993727, 6804.304730709591, 1950.5990845818494, 7374.000539266209, 5645.260275116403, 3555.7656725527627, 36756.80657967114, 80821.17643685683, 19692.590182808046, 20464.260437580986, 3344.154794241612, 18728.231059148366, 7886.65403917777, 10896.20808989499, 11180.724315680647, 8625.704744035374, 12062.267510096124, 5788.051062247965, 14297.195319131597, 5515.320076436181, 6371.7128791118275, 9986.726486774158, 6357.945735853709, 5139.281893648477, 6439.584099914155, 7585.750623111749, 6490.836594700349, 6357.488346240718, 6446.1111349194225, 2246.670516786756, 1851.0857148384707, 1185.492097174403, 1099.4601149820978, 1043.9725938106928, 1009.5609422073725, 852.1958309740695, 809.2631453424582, 758.9443171620876, 752.4477673522958, 736.4073170487376, 710.714320007888, 704.4115614590072, 667.139067305034, 629.3991014771233, 617.5640566861574, 594.5996045587171, 559.7596750196211, 459.04659699224493, 455.0957630682303, 439.1249529795095, 396.88416446889613, 389.4131772379093, 386.3518609690725, 385.0857981091411, 353.121239833982, 349.23572880690375, 328.3946087069473, 318.29099610374203, 316.6905100450124, 4015.323090551376, 1085.7610024890746, 507.1222969588536, 1405.757601956961, 24946.82575271989, 14152.471417870702, 3805.050637491863, 3568.3123499453336, 12848.064167605193, 1140.726315903937, 878.5491899442927, 16513.562271769028, 1208.1913533570396, 4708.57892780566, 2536.895042177172, 15337.406543493984, 3990.1745260687853, 3792.350064316491, 3963.534797525096, 11421.773702046405, 11095.46676056689, 28311.28591428529, 41259.625984553015, 8010.779010379358, 4863.7548960699105, 9609.96822189533, 9211.40965137686, 22346.50473046639, 3494.611303432289, 5858.012035033314, 7086.654335577747, 7191.854533496227, 5373.265683459157, 22240.570513420957, 8324.752388246978, 9164.03838752411, 8378.437297798098, 5913.600468817917, 13751.59606194089, 6565.839533499354, 8586.079415540975, 6113.001990486591, 6855.007629970351, 5564.141891323534, 5725.396643192342, 5424.163482740994, 9775.170978130922, 3616.708765506077, 3141.265716850456, 2175.3557827287646, 2000.752958201666, 1977.73309543925, 1779.6260881198004, 1474.4275503437127, 1040.2196988551225, 1023.4563329520695, 984.5484642237128, 915.3395002501338, 853.714769795931, 759.5740900959044, 689.6192392789135, 627.2720659605191, 614.8837998774641, 590.6746686706716, 553.5570416908744, 546.8459016211933, 526.2892503008778, 509.00558388014326, 464.5040242064536, 453.6437601950297, 446.43392206586105, 377.2788225823034, 365.24876775274345, 359.78610811120996, 351.4205030547983, 351.1856382962042, 7547.326604898439, 4790.714116994253, 460.7525979786751, 2477.215217917651, 1220.600366430191, 1566.8799802289482, 1387.3544866874336, 670.8207801585254, 6865.8810983505355, 1191.4129664395323, 1820.8060396560397, 7649.247710934882, 991.1218443550749, 4441.311850156626, 1994.2254744404995, 1348.4013590384673, 2428.714936990661, 5501.738417578651, 4725.592550594168, 9025.691752162922, 11697.671333426233, 14570.68891520566, 3623.2603306960496, 4096.128932956804, 3285.066127446769, 2349.9999706512244, 3786.132382974239, 5607.8032292353555, 11233.57857044438, 7944.972756274, 5473.4996842275, 9280.710683491434, 6138.797601172476, 5848.123423042302, 4769.660715377075, 5168.856010902205, 6513.974362917043, 4673.290520335967, 5643.2550587913365, 4980.27915820515, 5388.416313212483, 6081.3455448808345, 4935.986327857027, 4441.626608596672, 4531.656021777594, 4290.695828586251, 2316.9079727165904, 1387.8417146646584, 1353.9222546609014, 1343.9674098213138, 1045.443895477375, 970.7447228255531, 909.7758751614967, 815.8124500051124, 698.8327596125994, 684.7304511062009, 642.6892122493074, 628.226681671845, 520.4532643639731, 510.69237245222166, 491.49807836928414, 489.9426824068091, 453.26821426706454, 11982.480231258456, 394.9473566618231, 372.867263817219, 372.72851202302047, 352.8580456619176, 292.46287369874483, 287.89651941934056, 279.212132831311, 276.63141048559714, 266.0408372134942, 257.1262147414487, 255.34527083042738, 250.21866665349654, 22056.94298707668, 1883.3401831276146, 7370.030175861957, 354.5353002073423, 730.8777111707825, 9928.356284349271, 439.6635758805613, 65241.284034453456, 1513.1412977276143, 492.38296086327324, 4899.230097213941, 677.6720291660605, 15399.613926388443, 1970.1545344319352, 1517.6866533848258, 8641.275778664725, 4824.6074849283705, 15932.09770917383, 1517.2049888197591, 27319.04480976923, 15803.408831984052, 21029.533939961748, 2892.3791806243858, 1215.7319031482075, 6076.704563432374, 15275.89237452668, 21427.90704014215, 1504.6874798947583, 7949.241967924907, 3688.5958939304787, 6136.217488131555, 5379.173940309832, 6943.491293637147, 4613.421151520311, 3464.3749917325913, 4534.709549934616, 3540.974636780281, 4199.3822470062, 4583.574148215849, 4366.219046514896, 3828.730213003635, 4417.6973491257095, 3601.3050930425607, 12854.3415665804, 3484.1480708089684, 2401.613711450552, 2363.4370643500943, 1238.0764312011831, 672.1640409394591, 663.6021076128784, 624.3797757372975, 586.0243186161886, 521.3456203045139, 504.63933874179725, 487.85591881924813, 451.2201517384415, 447.9417006764235, 401.0940414188455, 392.1750306143491, 364.596816719475, 361.7610737917005, 319.71913435168614, 315.5887644129128, 313.2650361946686, 303.1885017881477, 298.5292740851283, 296.2099099636942, 293.1740319151801, 289.84325887086595, 282.21804943743143, 278.83073185228596, 269.9283282053804, 261.2873693419682, 2446.8682158856077, 19119.201540285667, 15584.750011698623, 3947.37831132764, 3813.7899582314726, 1201.7939436545819, 534.5457629002881, 2039.3665008639193, 897.1934796255249, 3228.5454211512542, 26988.85946372558, 16483.289331600958, 3723.495332668442, 2755.1885888561646, 8423.499080386642, 11487.435865239027, 3876.2211702756613, 1861.882410771947, 5711.331333269564, 874.5237659255203, 19113.847996575016, 6714.62180941776, 2597.7234836514576, 1636.49214384368, 4355.148194200881, 8644.154608942219, 7319.3359741608465, 11811.190137860176, 2438.5376504590995, 4481.470160980253, 12399.303183978815, 4542.521091767403, 3720.1282314668983, 7666.421038584736, 6173.351138461104, 6003.524835195511, 5521.235239293544, 6379.079474390308, 5246.524167650562, 4966.091175346734, 4584.896896408245, 4709.852169604971, 4263.426107955837, 4060.8297309741065, 5350.3459095243215, 1526.8948429098607, 794.7548070928145, 736.0963525876458, 595.5491691094301, 443.10542461868584, 355.3431922189528, 338.2446610952418, 325.7679559047475, 317.59379654449253, 316.32041840937575, 312.5924489794346, 290.79528397320564, 284.79376729768427, 261.89724002721516, 260.2705590165695, 239.21126146387678, 238.3129096646973, 236.37986396976237, 235.11397038823168, 224.89835339984813, 202.1215105304737, 200.8400773727475, 185.03789146703252, 182.46859026099693, 180.2244221701182, 175.93243001681049, 174.92493608408748, 170.5611218807425, 170.14336741495777, 795.929243080525, 3773.830575664674, 1279.3843980945758, 610.8412073863417, 3599.5456259590997, 1132.9449998057087, 2122.4461569828186, 433.519902075951, 3782.496228316669, 734.9655917083616, 2806.159944522278, 1563.539308542413, 1014.8828300632927, 3652.4822305227444, 2127.7525229252706, 17938.173354360875, 6723.623484706165, 4218.012178686492, 1502.8656836217108, 9187.633451293286, 693.7546812753773, 774.2040484462793, 6185.538116692007, 1529.9161381324611, 6303.747330529876, 2466.3438694553706, 1489.5744855784665, 1962.926771101905, 2533.5743284176647, 5072.636477564723, 3026.5168853024375, 5455.655038881342, 3365.090341923966, 3393.5075489395717, 2428.0446785549857, 2956.019509974858, 6867.811036391099, 4211.951880882806, 5141.9726517859335, 5166.925058141441, 6650.8020642150595, 3383.2949668463925, 7128.834295055812, 8287.993761246722, 6031.10220309675, 6549.640837945434, 3948.3926364030212, 4957.8544590689335, 4691.51826265862, 4271.03859789317, 4333.947183534714, 19279.34699361272, 11801.33411662025, 10482.928340935116, 7059.186576393565, 4813.501306712063, 4472.820035108659, 1803.8921834836037, 1587.0213081111262, 1275.9676702151883, 1076.5700761394398, 998.3585807695846, 984.8963967627293, 886.323435774948, 881.53129113065, 798.7107709246043, 736.6094565313515, 735.0529381624352, 604.4908534467168, 601.3708912544521, 594.793598304003, 564.3793409021795, 494.8406730648476, 403.893806639669, 394.4408761328711, 394.4001778454601, 390.88541978006714, 340.6778763319133, 340.6328833633446, 339.82944070822333, 325.49853938969767, 6781.430883172315, 2125.508308621468, 2835.0988242126723, 7442.620027322472, 15607.563872649238, 2220.721075095051, 3334.7779165491615, 474.6104313172699, 2841.799606110337, 4491.8918372057315, 7086.602022085207, 1058.0058109171964, 18476.780003742817, 3038.5134516820935, 4931.12286502752, 1637.3742186466347, 3622.5807352734096, 15026.951041705173, 4545.314612815078, 6507.608128540916, 8230.418710467766, 3419.496191151609, 3297.08473671602, 2984.598339221282, 9683.437332124786, 7683.370409223551, 4786.476924343433, 6115.841107405706, 3663.4668194227725, 4789.410438911824, 3755.7825873604265, 3768.092987348309, 3584.938641909328, 3456.3057909283402, 7636.204845648179, 2396.701485014221, 1081.0274639931931, 964.2368407485876, 824.7367732451592, 792.1231807408508, 701.6825346345169, 655.2222873073035, 609.2846900967584, 545.9684892430695, 540.5398926554569, 515.3910102702577, 503.614469172898, 483.0206166061822, 464.5411862981477, 432.04618300569285, 412.60067075083776, 310.5384767884218, 283.8100796560067, 282.09066602117673, 273.94564883465176, 272.75445095335016, 253.87615722239383, 251.796038344205, 250.87281396682533, 245.3521786373615, 240.98583906776048, 237.1978059834295, 235.85765693355066, 231.87638580368102, 3469.5287952004765, 4487.017302928526, 1465.379257596232, 44912.48053189249, 5191.515183567315, 4266.671790578072, 3849.8105273579777, 12446.536014201407, 11896.136541707694, 5173.322610947413, 622.1775636799889, 2415.952091698097, 6890.951083996551, 4030.6967571784435, 2372.706443609219, 4987.986643629141, 1974.5277023021188, 3158.6462667669275, 4940.059623599436, 1727.231687093032, 5811.329105731864, 6466.810920635014, 2368.740418426235, 2802.9761706163085, 8454.840121650008, 1936.2849770338346, 3087.875274322075, 5971.082720675078, 2918.3479679288835, 9721.79701876893, 6514.3041241760675, 3495.5220951438564, 3897.3366482843526, 4532.072540963074, 5020.569311116187, 5240.8482956984135, 3814.2656416908394, 4020.3267413059684, 3086.838896432654, 25339.2191629142, 14846.617006023036, 14399.212098296734, 5699.498642316989, 1684.9329436341843, 947.5896901909435, 899.3216083980561, 881.5922166025879, 728.0911590925591, 691.417091898207, 513.2715552248942, 486.9910837341424, 443.27863953104827, 438.836923068433, 423.08853473339923, 422.5472428279481, 414.9037431067506, 390.09862516106415, 381.8794406794999, 379.78072704854924, 342.9073187005551, 316.6481657833103, 311.10350460658003, 305.3453870488271, 305.23227785950724, 303.6086727891066, 301.48474744671364, 297.90662058140674, 296.44658976104955, 284.6323109948345, 23945.453464173686, 1702.5872207683115, 12308.909977005447, 11725.523215753914, 1524.925224317922, 1367.0549418227695, 2220.8374123881895, 3146.139116907311, 1564.2768127415075, 858.1412860908234, 2692.1066310906654, 1504.2203925560277, 1191.4719226677012, 3971.415740045153, 1785.260149174383, 1479.631749734683, 9305.146953264622, 3069.4655348785486, 1264.9391412756047, 1680.505508950305, 1893.0790012373811, 2441.9684798734147, 15036.974546099553, 10571.53817253336, 1823.675385877216, 8153.294433600189, 4770.324618781949, 5372.343147073177, 2018.2844824061801, 4146.57613513558, 4696.2222565797565, 2669.2646123346944, 3683.666295518181, 2817.629892245803, 3216.9977249093286, 2913.8446117154176, 2971.701554699855, 2620.5578342713584, 2704.958899542341, 2135.578607636261, 2318.6613510548714, 2252.654717141962, 950.5006738011065, 837.0160667447543, 721.1637407819627, 637.9712477261694, 581.1972028325855, 578.9575060785592, 568.8453817160471, 552.4439963879389, 543.4136388923413, 536.8203761172053, 528.0839818687202, 518.6473267675118, 498.5703238387395, 489.693674209944, 488.2313360937608, 484.05452192688756, 432.7538914314265, 423.96401237259994, 408.31169888294454, 402.0716959645625, 355.98514356419304, 350.1237204393756, 347.59054814167445, 328.16375550032484, 322.2916638628063, 312.64127272999764, 308.12044475071144, 300.576871506115, 286.92719025777944, 285.2548145277324, 770.1048620455199, 2085.768932973919, 781.6490462691206, 513.7523286465774, 9495.176262383862, 2203.343827478894, 9927.989653634695, 1463.3081583209218, 2105.754857285689, 1130.3273356448221, 4640.6910157533675, 1427.8787795167193, 4012.2558739877577, 1762.0442338431485, 3824.526790774134, 1182.8448675014115, 1879.0971231019034, 1894.0896144822168, 1196.8018019155386, 1304.1173669037034, 3425.231956258342, 4955.406694413943, 4811.135238861373, 2830.522807756636, 1607.5662833128595, 3621.0364329944678, 1281.901906326194, 4515.811299157558, 3763.3135066222067, 2158.8678750397885, 4633.651179197052, 14276.780732952979, 4338.582470959001, 4721.643933980994, 2694.5694594707625, 6764.418069856298, 2975.4721710876984, 2767.871123598929, 4571.923530486096, 2745.7921387000874, 2262.1106286191834, 2259.0189139593826, 2769.881437169394, 2777.8271015774503, 2528.1318826718034, 2236.8815672158216, 2173.019565693396, 9322.053760112836, 6960.974494902168, 1257.4408919394439, 1178.1221584870575, 1091.9517230453923, 1037.25985637951, 844.5831033292264, 806.4974583687157, 797.2469204176978, 576.3631211409112, 518.9748468164789, 488.4958619157895, 471.6619240236933, 465.1616414697694, 430.2774380868813, 4683.445576216404, 417.4704317377496, 385.7994315111056, 376.54904386780174, 372.48630151197443, 359.1525793560239, 346.8824345844066, 324.61528617707046, 316.85895721102384, 316.61508294504296, 309.6365963989969, 287.74219233394075, 278.3127882032513, 255.20547603999313, 251.69924799528704, 44362.23235967513, 3760.207197684431, 2463.651654174365, 4566.631230734853, 2750.684375309715, 799.8508512552032, 949.5576350243712, 3351.4928666724636, 3089.073634937071, 3837.23268634417, 995.3176912467933, 557.6676222108038, 12910.558443775335, 4965.171232585498, 1322.4084703197477, 950.2449922005378, 1949.6260270340144, 3495.812321356093, 3471.9924566861073, 1265.5297767227373, 2518.4239354672422, 5285.896029046996, 3043.2643529383104, 3524.4772048794703, 1654.3797408665998, 1734.646765686674, 5191.779350842633, 5751.813267395092, 2876.3241885270654, 4795.008170170455, 1731.1645868762093, 2827.280284522815, 5156.156422622315, 6528.159223795017, 2739.5540890872912, 4199.371166015927, 2154.3065044328328, 2285.5906729266785, 3195.6463134014243, 3329.1721711420114, 2973.3751739243276, 2829.9539581396207, 3900.6684524510406, 3491.0576801875113, 1914.1457032798714, 1848.1563653453827, 1480.5560326974662, 1304.8584836461164, 665.2661409719365, 656.6597249763192, 570.6013859181598, 481.6860045928624, 430.87029255327, 406.2665208327186, 397.88191743200207, 388.57521102483105, 385.92590205552506, 375.2293471059576, 366.6782296414621, 332.72085690412393, 330.7447347899996, 324.93296831094574, 318.9869573714714, 299.73975790537196, 278.3191442631265, 268.9460614283031, 266.3280579761223, 256.6076676233033, 241.09228225382984, 237.04352026040627, 232.25434003975306, 222.16008432175494, 1924.2392859565368, 1892.2646566048124, 32292.237338356503, 4058.702049915163, 1143.9550379392274, 22807.97811641501, 372.4553981579523, 933.4563042223571, 3495.954510640789, 1825.7425609797012, 2395.1914090913247, 2839.7853418444997, 4612.590182414038, 1024.8837668463086, 2644.5629001112266, 1030.7101947122321, 5014.198966179355, 3550.2442801368775, 1745.9026872686286, 5236.842494271381, 2066.116980986101, 3958.107909861861, 6698.9700004276365, 4800.808628613396, 4398.380844497676, 14623.844405945416, 4816.191224746952, 15013.508124898643, 3239.8061846319215, 5425.00302253551, 3177.34125492174, 2688.8794339970646, 4341.877969577116, 3680.683328481466, 4218.189416657985, 3701.172598441662, 2938.3412944586153, 2606.740160048481, 2867.009972895319, 4784.06608945639, 3540.7051977377105, 2727.8275011320998, 1297.7464909113376, 1188.632392310481, 941.7353466794015, 929.7562124325045, 918.7148725937692, 805.1712144434628, 786.7454501656237, 719.2519250137836, 611.8470874289579, 496.1979253967912, 492.72064402147555, 477.66635897483695, 459.52838594932666, 447.0331645047438, 439.60087298541424, 409.08001601725306, 378.91130296893215, 372.52081225040723, 355.3561365228202, 345.9676828793088, 340.37309276409445, 322.738195097734, 310.5881111983949, 308.50150686481567, 302.812978340622, 293.16734953545506, 280.71519668765586, 21753.5632969677, 1111.3710389377193, 1019.8378771434114, 568.384543986261, 1868.0951748684847, 1522.448342731722, 1149.4104718115211, 815.3342846195569, 2136.570735591582, 785.6087689222805, 6928.011063749217, 1002.4504104790789, 1001.5043732772743, 985.8150987346523, 3344.737489047762, 2088.328254992519, 1084.0213318766898, 6101.489188580863, 8954.55369267915, 1528.9214085794188, 3394.4690891954965, 7738.31959933056, 1634.3768843448179, 4419.6969291019395, 5279.876721306164, 2522.075831896529, 2727.679837371699, 1445.3151059230088, 3979.1657685382884, 2460.6401713011783, 2814.36152633624, 2169.9330895982603, 2945.392506708152, 4397.586930451253, 1984.7394187246307, 3231.6364689160746, 4435.251787231086, 1813.9904194306566, 1913.02935136191, 1748.3525826362024, 2187.510493778962, 2111.836937970195, 1825.315900141679, 3333.1191212868634, 1320.9311288074143, 1099.4909129130883, 887.9028670046656, 775.6127049944687, 703.9442764196914, 611.8230062446636, 598.2377093779603, 430.81428410743695, 395.0499935390537, 394.5812124184929, 394.5517614092784, 389.1710440834827, 373.1429026274064, 350.0461601137805, 341.9987807813261, 311.33482060244825, 304.72913096910594, 304.4492823019135, 295.59954879936157, 292.91115097389184, 250.16512572761783, 229.0386275353952, 226.20428188880496, 223.34822605526546, 218.1371147590367, 201.31928127259482, 201.22364879619852, 198.08209246993846, 199.28705910934585, 1202.233872829144, 894.7992732146059, 1707.9363574639178, 2727.9553752667157, 5146.648599172161, 1844.5803253862678, 731.4096878275847, 481.07282862587, 854.317130898579, 1041.6746601501331, 8892.102149896828, 11956.432649832881, 431.4197086832828, 2018.4715921373436, 3890.245272350301, 5271.757511589906, 1742.6149336299436, 4143.883822934906, 1917.8441835672666, 1118.8278970414983, 2987.042644506486, 9954.389850783495, 2319.840565446781, 19527.7270114413, 4860.8147897206945, 2387.8548132751193, 3324.7635444480597, 1602.2745436528992, 1903.3144038567543, 2621.492719565446, 2925.9793474900102, 3065.0990456804298, 1755.189309867038, 1555.9530531077908, 1505.4398304104582, 1839.9514161990892, 1605.1680732683983, 1604.2126199877366, 1760.9894840177396, 1344.7577911546791, 1231.3229358269107, 1210.3451493698692, 1078.2274114226668, 996.258378758246, 979.0131761098343, 948.4245408893574, 798.4078435834472, 740.4155701692574, 658.8771155479147, 641.1797076487817, 616.8130537041161, 498.24745844469624, 488.4748341350439, 447.6317264681929, 445.08309364208174, 441.904347836175, 440.355759108008, 423.318812857671, 416.72637112646106, 394.8655997233345, 393.9595255905347, 392.4295140791894, 368.6969305404266, 351.14002387136713, 329.7896344033914, 294.25310746133744, 293.32472554443007, 280.8928621299506, 1663.3644703686462, 948.8474057325069, 4089.0731887168918, 693.2153741951644, 604.1067919418466, 786.2267347862573, 9733.962323520896, 3523.323988781214, 2633.828496999347, 1591.8308426639596, 1041.464284039665, 1846.2678323430691, 853.7714786271674, 2319.286018777872, 2765.913163971692, 1876.2557454043938, 4391.194289442745, 16974.931316301212, 1291.4964820157059, 1504.7480088598877, 1445.091398305529, 5436.454072804183, 1246.2272579165715, 1347.878461102299, 1259.187248667345, 2169.496079467251, 4044.345905135623, 2273.380884195728, 1604.668732955731, 1842.4931032067245, 2516.9627296823824, 3350.873777167669, 1686.676785337438, 3416.1381361355434, 2242.729938418964, 2139.07905034192, 1907.5239488277384, 1681.8552791859345, 1962.261453524306, 1777.4858509031396, 1586.2804643257302, 2190.7541910951127, 1302.689886687768, 1277.22341650399, 1224.300196967009, 1212.810664543514, 1105.0161793994785, 1090.2786022258806, 1057.1244658102023, 876.7518670811291, 795.9702401221158, 766.621962522971, 731.4880608502064, 718.9849340422824, 705.7102102837118, 642.0938539110014, 581.9595101097995, 575.4763300968957, 519.3831438086125, 517.3619439771627, 489.0348911123296, 485.55580646577613, 463.3904829437851, 461.9506093034048, 456.90410883093034, 436.4694551323524, 435.5313213592642, 488.86702341490843, 403.46073898944013, 398.98784563315377, 392.565264794319, 773.1556714225986, 985.3688329625295, 897.3513274646754, 788.5213328615476, 1085.0223558566283, 927.115370407433, 1890.7235102042555, 564.781507486192, 754.0197298915695, 674.4758610260413, 1013.3744351573008, 1607.5074587050879, 4710.937204129462, 1037.1648013918275, 1026.9980699730113, 1044.3234004568553, 1183.6366428416923, 958.4789476256183, 999.2092229499101, 970.7798701616487, 1297.0012834001577, 2244.9145920130877, 1213.4763682082873, 912.0267971392273, 1814.0266047324915, 1753.2773079657368, 1844.6232430624586, 1380.2510623712546, 1017.9030478127312, 1345.0277702623632, 1109.533523980082, 1224.572493987826, 1029.5667474085506, 1018.7833772492073, 965.4573442028999, 777.3226075374802, 754.3922574573296, 479.716648667075, 472.1562770849871, 438.541109456147, 925.7251581944055, 352.8128310659004, 340.6076430123731, 327.26089855802945, 315.16846086293094, 295.85420863215285, 291.2381753012544, 280.256237938097, 274.29484958410103, 271.82367381788606, 254.40757900720067, 254.18085440585537, 223.35244990041414, 222.8531487395953, 220.51579162906162, 215.50794042146, 213.49014829269527, 213.39890333312167, 212.80875060417168, 207.89334638555124, 205.810732089099, 200.29477212338318, 194.277675170117, 190.2685137044736, 1643.744879982281, 988.6202323357122, 2129.838578772485, 1046.7014191056367, 2128.212385969622, 5236.12017632973, 690.7809486297602, 1715.6851598502099, 1962.4548910162357, 2637.175765137515, 8865.979382881782, 522.8332249653253, 1971.2467526539053, 418.93718999322795, 4493.917109007268, 2574.572674866844, 5969.078369913436, 2927.9145955677905, 1286.609529311727, 1197.8074431755572, 4320.895859619418, 2842.938022658869, 1683.5150064098939, 1811.1357362048152, 7761.687991787388, 906.807575668121, 2085.930498891979, 6634.030897416507, 3222.6077967778047, 3375.9912950386824, 2682.8923966095504, 2932.729531983019, 1749.3180300939614, 2797.940860424957, 1563.3298993996361, 1640.3431804690563, 2164.2615538733635, 1959.7424133102238, 1839.5742658421527, 1919.1624250330397, 1671.6058518492378, 1405.0569725550654, 1033.578049590303, 1002.259578133656, 811.1392946021867, 770.0795235566562, 503.5034612594507, 471.7370042661232, 439.3582234288042, 429.98628882790433, 388.48345894966513, 383.1631354472519, 348.0504473352882, 346.58253071901936, 308.562122594385, 287.83856248156746, 283.4449416605071, 251.5745415491172, 246.030673160543, 231.7560135106717, 225.18666719398138, 224.2722468200827, 209.0429607576058, 195.15187774179063, 177.64343985275138, 175.7054019844043, 174.83163553139178, 173.67062156533822, 170.31448536004547, 169.22194568870484, 1144.720356897054, 1798.8243731931982, 1324.4293604555764, 3078.7671815972926, 541.889272337406, 381.30256396967815, 1738.1576984389199, 1385.4750124384545, 3491.3926269404596, 3615.520761247564, 980.8213186464119, 799.3971330561969, 3833.846097396457, 2278.9938964154726, 4760.941261348219, 437.208733493136, 2516.3680061728114, 1238.861125584256, 663.2793995253021, 2746.0585248826624, 1141.2248776553001, 1074.7515827093641, 1704.9493709006708, 2644.1282582388176, 1009.6526659091836, 1130.6530666961776, 3995.5594017073863, 1791.0213009612762, 2887.598940220168, 2191.9253251486, 1437.152622950145, 2154.070323358012, 2191.8947313505096, 1708.3360492253414, 1539.3688451392063, 1608.1099398210843, 1400.5325356851874, 1231.9641534534408, 1158.5061014695561], \"Total\": [155714.0, 78634.0, 45252.0, 51044.0, 40977.0, 118185.0, 106527.0, 46448.0, 64073.0, 25340.0, 22107.0, 59960.0, 37705.0, 91194.0, 24332.0, 51518.0, 45986.0, 32570.0, 44397.0, 46700.0, 94123.0, 22732.0, 42050.0, 19280.0, 25169.0, 27308.0, 20053.0, 26733.0, 27084.0, 44755.0, 4668.681463769541, 3760.9393893863703, 3727.271473019736, 1101.5856292866522, 1070.9700851126654, 846.268989193279, 790.8276183851856, 719.2011906145141, 686.8653590116927, 25169.019015093174, 666.4948950264817, 646.8558236860354, 645.1467627926057, 640.8912281785812, 575.1098805059877, 573.5246440247166, 572.8328374716172, 570.6264900553023, 529.5090222632273, 523.9785038379185, 464.42582639426433, 430.67768633104134, 426.90168124814363, 356.3222785683567, 349.0461520172891, 341.8174111458968, 331.52625381029526, 331.36502150546477, 327.8501604906741, 323.5954781428681, 1394.6478490711281, 844.2495243301081, 2974.4432673544165, 12217.849654743428, 2258.966798230602, 16057.739662331122, 825.9938578955868, 15800.926215319343, 8716.094840087017, 12915.673547109323, 16323.850697014122, 4722.411073908272, 24697.030092907327, 2760.365745998401, 17181.87411762947, 12365.715281650779, 44397.595088113696, 33321.81953803754, 30299.82575965142, 2090.981403082261, 91194.2259246978, 10175.929405105908, 17341.337903674514, 23084.746791327314, 7679.254518047033, 34745.511140765586, 94123.5517035321, 74545.22187341496, 45423.62740157653, 9778.833451954491, 42904.785562195, 26817.73362022093, 25581.13540865162, 24032.242704030014, 64673.97141390066, 21506.96295443864, 42184.45658158996, 43098.56236755097, 79933.36017469109, 47733.35290482429, 54704.73971329415, 3628.460426429737, 2787.1255771878355, 1914.0404902985372, 1686.5554361135344, 835.7350663884565, 683.1267706083307, 577.7771101387674, 529.4975335836582, 526.9066583863249, 508.037878443671, 447.6611387907236, 440.95933375894947, 424.39527420569283, 415.74351014452117, 362.81940128867245, 361.87119227395647, 361.84066694341675, 359.4520888093255, 334.79886301982384, 321.085595848601, 311.00463441026, 296.94733731480846, 286.8030769025143, 272.8714041277516, 254.19567313825112, 252.54674901452157, 250.95201488964946, 250.48713519744322, 242.92719075142077, 236.2414015004518, 26733.96704859684, 37705.72899097151, 11652.469124338748, 1156.3479642825373, 8166.5813356801145, 12261.620039924072, 508.2142723914823, 4427.3709477240145, 780.1026876215418, 4710.401267049131, 1363.7459541190658, 6266.790925122302, 8576.183328996145, 1693.4683393655496, 572.7439114485702, 10244.301938012846, 8657.931048924956, 27248.79121663136, 5944.337472338137, 4782.564060118929, 2448.9829794564475, 16948.17690053243, 3677.934543619357, 5517.062747236971, 9602.346923512234, 46700.86609464949, 2736.2883200233214, 3686.038083630136, 16624.03515131586, 36588.45838657087, 6118.726464249252, 10993.60043236142, 7667.81585774821, 15284.919662744322, 15591.407444239932, 17614.257949811767, 15127.974508302717, 41251.90273306142, 21497.059924939156, 59960.34499621212, 45423.62740157653, 118185.517906125, 63112.78940436005, 94123.5517035321, 42904.785562195, 27283.065236423165, 26244.165780296975, 106527.0394798763, 30225.282303083135, 25810.683299129243, 79933.36017469109, 20850.494559859453, 42043.238236775906, 43124.19440549374, 31479.00609949176, 13312.091700310806, 2413.5757104974655, 2000.037971545616, 1532.176338129192, 1334.643507270755, 1219.183791433354, 1218.7644880284317, 1192.5376504311635, 841.1083072405786, 787.4273506000029, 692.9900674893747, 684.1219736064605, 669.5511136890723, 584.6994366943702, 575.903520137365, 668.8472715417198, 501.6838877720461, 478.0434499267221, 471.77564976245753, 450.14548008605317, 415.10088629730615, 413.2698187604649, 401.0828978622647, 398.6908799233894, 397.36425469235263, 369.2149071852995, 368.45779926634816, 352.31683765454903, 338.71269273558994, 336.00471004121096, 14477.627283149057, 15556.599192866655, 13240.685834108137, 22729.932089183752, 15821.407507035814, 1215.3668673133218, 2116.1518962435384, 781.6714066913921, 10970.193473502362, 7596.3547822454675, 2865.6319375248145, 2096.0643708792945, 1540.987220058923, 16165.750437919323, 4765.321766100341, 1776.348778742438, 8506.136083665842, 2178.642854925364, 9723.210484706715, 7239.071206255217, 4328.6212878438455, 59960.34499621212, 155714.3803611621, 33197.63659104172, 46700.86609464949, 4633.903626140547, 47733.35290482429, 16161.843551104874, 25971.4816153824, 36588.45838657087, 24697.030092907327, 45423.62740157653, 13629.90035273712, 91194.2259246978, 14353.618513835543, 21443.626812719078, 64673.97141390066, 23084.746791327314, 13974.710380410677, 30299.82575965142, 74545.22187341496, 42043.238236775906, 42184.45658158996, 118185.517906125, 2247.578510003803, 1851.9937080555185, 1186.4000903914507, 1100.3681082075584, 1044.8805870277406, 1010.46893542725, 853.1038241911176, 810.1711385652654, 759.8523103791357, 753.3557605693439, 737.3153102657857, 711.6223132249361, 705.3195546760553, 668.0470605220821, 630.3070946969161, 618.4720499032055, 595.5075977828329, 560.6676716573376, 459.9559935094451, 456.0037562852784, 440.03294647105974, 397.7921577026079, 390.32117046360844, 387.2598541861206, 385.99379133491107, 354.02923305631725, 350.14372203243977, 329.30260198689035, 319.1989893283819, 317.59850344888093, 4058.7312447850272, 1089.2948020805443, 508.6970015078964, 1437.7677231476337, 27308.970869344015, 15570.909614320293, 4072.752727363887, 4043.1491868356516, 16482.3724318635, 1224.907385207017, 939.2277071526287, 24100.25378196607, 1341.228241543876, 6288.810166362692, 3121.5636133166063, 24866.430414176924, 5320.208619332886, 5072.578930812888, 5400.235099473262, 19029.506645863363, 18414.36335653003, 69226.41380606533, 118185.517906125, 14966.604790845307, 8149.852206205716, 22359.86970057819, 21443.626812719078, 74545.22187341496, 5721.3852671809145, 11898.758838136182, 15783.27835519923, 16197.763720943642, 11245.901460844569, 94123.5517035321, 26817.73362022093, 34745.511140765586, 29805.937453418548, 17044.887922018177, 106527.0394798763, 26513.173490209352, 79933.36017469109, 27283.065236423165, 47733.35290482429, 26244.165780296975, 37323.50248298863, 27009.737222211334, 9776.074922154354, 3617.612709529505, 3142.1696608738844, 2176.259726752193, 2001.6569022407446, 1978.637039531249, 1780.5300321518803, 1475.3314943671412, 1041.1236428829918, 1024.3602769754984, 985.4524082515828, 916.2434448788922, 854.6187138356106, 760.478034502454, 690.5231833418931, 628.1810943443676, 615.7877439348186, 591.5786127326546, 554.4609857278897, 547.7498456446223, 527.1931943295939, 509.90952790357215, 465.40796825106963, 454.54770423844826, 447.33786608928995, 378.1827666411787, 366.15271177617234, 360.690052138025, 352.3244470943336, 352.0895823696715, 7716.242657221413, 5009.935051920264, 464.56353821007514, 2680.759318584562, 1283.707519702473, 1671.9322520425922, 1487.199894390934, 689.4515742156005, 9140.12183529865, 1321.4028304537671, 2150.015777649545, 10989.870295237373, 1107.6705123184565, 6663.192191800419, 2556.4612755970747, 1602.1900440250834, 3885.7564735314922, 11765.015608297314, 10086.108485257513, 27864.506807885722, 51301.54546712539, 79933.36017469109, 8477.703042277544, 11309.20699177901, 8191.066672880756, 4668.787693353945, 12473.627718192392, 27723.92020699733, 118185.517906125, 62107.461855567206, 27668.79843938541, 91194.2259246978, 42184.45658158996, 43098.56236755097, 26513.173490209352, 33378.17314977487, 64673.97141390066, 26975.326780820706, 54704.73971329415, 45289.443791743106, 63112.78940436005, 106527.0394798763, 47239.012805368686, 37655.56224837618, 69226.41380606533, 74545.22187341496, 2317.8342513028797, 1388.767993266567, 1354.848533252527, 1344.8936884177233, 1046.3701740769936, 971.671001457377, 910.7021537580837, 816.7387286017654, 699.7590381988895, 685.6567296956199, 643.6154908455989, 629.1529602768827, 521.3795431378254, 511.61865103851164, 492.4243569555741, 490.868960996228, 454.1944928596123, 12007.349203763728, 395.8736352481131, 373.79354240663787, 373.65479060931045, 353.78432430539664, 293.3891522850348, 288.8235663407156, 280.1384114233602, 277.5576892420204, 266.9671177783828, 258.0524933379388, 256.2715494910333, 251.14494525853422, 22732.283718920182, 1902.3316144181013, 7634.523950510605, 356.2493289834321, 746.7466475394604, 11010.182660582193, 446.7440095392138, 78634.2255304039, 1601.851476201268, 504.22172144961195, 6004.842982303168, 712.41415226765, 21980.852290712, 2308.221810118239, 1748.1506816818094, 12524.404187320515, 6516.176934791425, 26265.91670492126, 1793.752121190653, 51518.644099876496, 29627.59679945139, 42050.43209218572, 4331.356772145848, 1454.3181284752873, 12088.278447823446, 46448.24051290062, 106527.0394798763, 2037.7895732764046, 42904.785562195, 18242.355580839652, 62107.461855567206, 47733.35290482429, 94123.5517035321, 42310.69267844935, 21579.18984089186, 51301.54546712539, 24100.25378196607, 44755.52016201262, 63112.78940436005, 52404.53341954283, 33107.20156658565, 64673.97141390066, 28995.071684693485, 12855.24790979508, 3485.054414049049, 2402.520054665229, 2364.343407578198, 1238.9827744326726, 673.0703841709488, 664.5084508360209, 625.2861189680782, 586.9306618366467, 522.2519636368008, 505.5456820012714, 488.76240717426043, 452.1264949672599, 448.8480439025776, 402.0004359998377, 393.08137383215586, 365.5031599579485, 362.66741711789825, 320.6254776190169, 316.49510777574505, 314.17137941731534, 304.0948450223363, 299.43561733715023, 297.1163870276032, 294.080375191219, 290.74960211323173, 283.1243928650113, 279.73707513158257, 270.8350367437697, 262.19371262080887, 2464.809329822516, 20053.06337590208, 16710.251632399537, 4303.407150784756, 4228.608673903408, 1290.2630381699262, 558.9765652971114, 2373.5833697659004, 989.6452947536665, 4126.89734143799, 46448.24051290062, 27084.911139112908, 5267.538932034295, 3773.5025464147516, 16149.091666918344, 24032.242704030014, 7499.387503942623, 2886.5758840303, 14642.827404394864, 1103.5120699472154, 91194.2259246978, 21352.646859243712, 5490.4610908420855, 2778.4693929021514, 12473.627718192392, 37655.56224837618, 33107.20156658565, 79933.36017469109, 5475.149393807162, 15966.291211092173, 106527.0394798763, 18283.574329039944, 12088.278447823446, 64673.97141390066, 42904.785562195, 42310.69267844935, 40977.799340767975, 74545.22187341496, 45423.62740157653, 43098.56236755097, 37323.50248298863, 63112.78940436005, 42184.45658158996, 26513.173490209352, 5351.251040690356, 1527.7999740292264, 795.6599382331492, 737.001483707716, 596.4543002242132, 444.01055573659784, 356.24902756693314, 339.14979221544354, 326.68943283818425, 318.4989277553683, 317.2257881107516, 313.4975801052851, 291.7004151562144, 285.6988984175501, 262.8023712135953, 261.1756901851979, 240.1163928578905, 239.21804078222516, 237.2849952067744, 236.01910152425046, 225.803484519714, 203.02664168100864, 201.74520854422212, 185.94302259640062, 183.37372144605234, 181.12955334341302, 176.83756114221643, 175.83006722208606, 171.46625307537235, 171.04849855805537, 814.5689770798173, 3994.590946647477, 1346.694235203436, 641.7119796841824, 4120.562388976265, 1295.6366529150603, 2740.4665810190586, 477.8040969667978, 5566.054836534128, 876.9241114029737, 4143.479067470396, 2118.3995943830632, 1295.3264317481044, 5931.922305391389, 3184.0611209888007, 44397.595088113696, 14280.212857532159, 8048.517439291159, 2248.819002408272, 22359.86970057819, 876.9406215712821, 1019.0805867777788, 15783.27835519923, 2502.3971470381302, 17065.407943990704, 4843.98350581284, 2466.79378773178, 3676.0730064258605, 5301.584950638597, 15127.974508302717, 7062.794832849416, 18117.524327907533, 9015.101953670333, 10236.286863793443, 5756.63050391688, 8426.97160612295, 41251.90273306142, 17138.064332860366, 26360.19651367812, 26817.73362022093, 47239.012805368686, 11479.688464527862, 62107.461855567206, 94123.5517035321, 44755.52016201262, 69226.41380606533, 17614.257949811767, 54704.73971329415, 63112.78940436005, 42043.238236775906, 79933.36017469109, 19280.257907149924, 11802.245030157457, 10483.839254472323, 7060.097489935733, 4814.41222024927, 4473.730948645866, 1804.8030970208106, 1587.9322216622234, 1276.8785837523951, 1077.4809896766467, 999.2694943461378, 985.8073102999365, 887.2343493121552, 882.4422046678571, 799.6216844618115, 737.5203700750737, 735.9638517027713, 605.4017669870009, 602.2818048095595, 595.7045118530842, 565.2902544393867, 495.7515866020548, 404.8047201768762, 395.3517896700783, 395.3110913826673, 391.79633338405614, 341.5887898734435, 341.5437969005518, 340.74035443175006, 326.40945292690486, 6823.360222347794, 2134.172992937045, 2857.704166323578, 7702.608382260599, 16413.72511179258, 2390.5851504025118, 3801.772552208199, 481.97599479046556, 3486.3681485613506, 6609.574914543235, 11540.471756231245, 1226.1998684782563, 45986.532152795044, 5071.949067241887, 11184.616997196463, 2333.5255221362186, 8386.923508332562, 106527.0394798763, 14331.73805260324, 27283.065236423165, 47239.012805368686, 9690.160928295987, 9235.621546191429, 7774.773738948924, 118185.517906125, 94123.5517035321, 29805.937453418548, 69226.41380606533, 18266.020837697517, 64073.92594157123, 43098.56236755097, 44755.52016201262, 33321.81953803754, 64673.97141390066, 7637.106457709344, 2397.6030970753854, 1081.929076057744, 965.1384528097524, 825.6383853382815, 793.0247928673721, 702.5841467256473, 656.1238993684683, 610.186302164346, 546.870101432897, 541.4415047224019, 516.2926223314224, 504.5160812956447, 483.92222866734704, 465.4427983593125, 432.94779510504196, 413.5022828120026, 311.44008884958663, 284.71169172055767, 282.99227819701287, 274.8472613536567, 273.656063014515, 254.77776931563466, 252.69765119904238, 251.7744272042182, 246.25379071020993, 241.8878929491557, 238.09941806816244, 236.7592689981016, 232.7779978648458, 3526.4399361528235, 4598.930062492022, 1490.9785953541657, 51044.47996329947, 5605.232914800096, 4596.62633890081, 4171.917092883379, 14233.946818786551, 13926.943220909554, 6097.600837779282, 652.500887094789, 2823.2435064187025, 9197.41410511191, 5508.3953485003085, 3035.2355245658214, 7441.766739586381, 2528.8899161306767, 4619.562773349099, 8212.562737901872, 2271.053896511162, 11505.032448712243, 15558.72950993236, 4195.072842083428, 6434.366128152586, 37323.50248298863, 3588.589385760282, 7979.112368244035, 27915.480618418198, 8613.552133117599, 118185.517906125, 74545.22187341496, 14488.948170345946, 21506.96295443864, 42904.785562195, 69226.41380606533, 91194.2259246978, 34745.511140765586, 63112.78940436005, 14520.892373420247, 25340.120032854524, 14847.51787374054, 14400.112966014238, 5700.399510084633, 1685.8338113516888, 948.4905579363541, 900.2224761155607, 882.4930843869179, 728.9920268100636, 692.317959619305, 514.1724230745559, 487.8919514757473, 444.1795072485528, 439.7377907967617, 423.98940249318144, 423.4481105716026, 415.8046109445866, 390.9994928785687, 382.7803101159619, 380.6816206932532, 343.8081864214458, 317.54903654618374, 312.00437241040277, 306.246254827166, 306.13314581099013, 304.5100574559855, 302.38561530482576, 298.80748856984854, 297.3474574785541, 285.53317873781054, 24332.727661902445, 1713.4845083567636, 12652.046437439423, 12507.825279603783, 1560.7511923317659, 1401.941199179183, 2368.685878991066, 3644.0906959146605, 1735.9454178290669, 921.8986737090189, 3415.1721600529027, 1858.5917998737982, 1422.6750611075397, 5847.329646262842, 2511.3900159345035, 2074.014891247902, 22074.0939341202, 6655.190977096294, 1935.9463902920613, 2936.0156285543626, 3562.665875480606, 5484.475370235595, 118185.517906125, 79933.36017469109, 3541.6512831315886, 78634.2255304039, 33197.63659104172, 51301.54546712539, 5369.411408950273, 54704.73971329415, 91194.2259246978, 17181.87411762947, 69226.41380606533, 30225.282303083135, 64073.92594157123, 52404.53341954283, 62107.461855567206, 27723.92020699733, 43098.56236755097, 8058.652363798501, 26265.91670492126, 36327.90224624013, 951.4048889214496, 837.9202818650974, 722.0679559023058, 638.8754628522717, 582.1014179565221, 579.861721235983, 569.7495968735965, 553.3482115152616, 544.3178541115909, 537.7245912428841, 528.9881969890633, 519.5515420091907, 499.4745389789267, 490.5978893450743, 489.1355512141039, 484.9587371574035, 433.6581065517696, 424.86822749294305, 409.21591400688123, 402.9789892278722, 356.88935894617464, 351.02793562063084, 348.49476326201756, 329.06797062066795, 323.19587898674297, 313.5454879593869, 309.0249426987564, 301.48108666144, 287.83140541213385, 286.1590296947919, 786.2131590876168, 2198.131265154601, 807.0303078454077, 525.2927554787145, 11466.943162399783, 2449.6403649946888, 12543.968285928078, 1624.5615597211975, 2447.501613304079, 1248.8507675846276, 5830.1511875052565, 1695.1236738919067, 5761.4572038514425, 2343.8232480427696, 6171.673562546857, 1461.0353009339558, 2615.4224684294336, 2687.149078445991, 1518.3823871688182, 1697.342477332308, 6430.372235163276, 10975.189080114988, 10785.608455155867, 5261.621438162416, 2498.523445272391, 8156.28773127837, 1815.6068608925664, 12522.635246960155, 10766.20914137037, 4693.4425032205645, 18242.355580839652, 155714.3803611621, 18117.524327907533, 21980.852290712, 7839.882755355498, 52404.53341954283, 10017.96320315735, 9389.161355531098, 54704.73971329415, 12292.699183051836, 8058.652363798501, 9605.860762062966, 45289.443791743106, 62107.461855567206, 36327.90224624013, 42050.43209218572, 22084.170362251032, 9322.972464345106, 6961.883987557285, 1258.3503845945597, 1179.031651150728, 1092.8612157151938, 1038.1693490380121, 845.4925959843424, 807.4069510437183, 798.1564130728137, 577.2726581659857, 519.8843394715949, 489.4053547963457, 472.5714167071562, 466.07113413259134, 431.1869307723025, 4693.375295233667, 418.37992449156644, 386.7089241842453, 377.4585365229177, 373.3957941733059, 360.0620721847614, 347.7919272395226, 325.52477885626047, 317.76845000776524, 317.5245757934161, 310.54608919356514, 288.6516849890567, 279.22228085836724, 256.11629529584945, 252.608740650403, 45252.02439373623, 3886.320888474489, 2561.0410638816907, 4816.637618653505, 2896.695485327048, 818.8647427041847, 985.2019675283416, 3746.3328324941963, 3478.201627969085, 4391.9743241076285, 1060.1870583782588, 577.228864104255, 17727.613603333248, 6262.802055818236, 1484.5891466840058, 1045.453241629672, 2347.338269161906, 5182.840504049818, 5728.652643952154, 1641.1632850180338, 4030.3187660416966, 10975.189080114988, 5601.047813440786, 7521.261694908411, 2406.6110938352385, 2615.1880595466805, 14642.827404394864, 18117.524327907533, 6430.372235163276, 16717.425045473818, 2768.998314173846, 7726.011797172213, 64673.97141390066, 155714.3803611621, 12522.635246960155, 52404.53341954283, 6171.673562546857, 8156.28773127837, 42184.45658158996, 74545.22187341496, 63112.78940436005, 43098.56236755097, 3901.5787608870105, 3491.9679885978394, 1915.056011695618, 1849.0666737499516, 1481.466341108259, 1305.7687920654564, 666.1764493731192, 657.5700333877988, 571.5116943224715, 482.59631300227954, 431.7806010616686, 407.17682929931516, 398.7922258385206, 389.48551952705816, 386.83621046779996, 376.1396555563383, 367.5885380426449, 333.63116554603675, 331.65504504253164, 325.84327671212856, 319.8972657776154, 300.6500663065548, 279.2294527344496, 269.85636986760034, 267.2383668752786, 257.51797607159324, 242.00259073500723, 237.95491106805483, 233.16485811036637, 223.07039339590872, 1957.0844321281616, 1930.731907841401, 40977.799340767975, 4834.256931167251, 1275.1923493731958, 32570.345578306213, 383.5398369210919, 1045.1841155379766, 4465.980370393331, 2333.3220990332825, 3243.7537013139404, 3962.397328072422, 7081.549669256799, 1246.7704237386508, 4126.7558430455265, 1302.387342805858, 9389.161355531098, 6292.9986252207555, 2598.623866469985, 10727.772378412194, 3542.0793157147723, 9434.272327034218, 21579.18984089186, 13939.851158066558, 12310.190191472035, 106527.0394798763, 17727.613603333248, 155714.3803611621, 10780.440793934395, 36327.90224624013, 11439.772396666654, 8451.632993397598, 45289.443791743106, 26975.326780820706, 54704.73971329415, 33107.20156658565, 37655.56224837618, 18283.574329039944, 62107.461855567206, 4784.966487808865, 3541.6055960901854, 2728.7278994845747, 1298.6468892638122, 1189.5327906732525, 942.6357450368375, 930.6566107849794, 919.6152709512053, 806.0716144392867, 787.6458485180985, 720.1523233712197, 612.7474857814328, 497.0983238332584, 493.6210423739504, 478.5667573273118, 460.4287843018015, 447.93356286568326, 440.50127134247185, 409.9804143697279, 379.811701321407, 373.42121060288207, 356.2565348802562, 346.86808123178366, 341.2734911165693, 323.6385934502088, 311.48850955086976, 309.4019052222517, 303.71337670339375, 294.0677574259881, 281.61559520502396, 22107.31326310954, 1119.5617975482564, 1031.2773829390683, 571.6349341213239, 1906.3027420641154, 1558.3697581742788, 1198.6903345930064, 842.8493010575062, 2316.9421693735194, 835.4258034010238, 9605.860762062966, 1146.857316519027, 1158.714510593609, 1163.4939876035764, 5524.623566909851, 3344.4901558689335, 1461.1466185006545, 18266.020837697517, 51518.644099876496, 2894.1043955441696, 13200.235873176132, 64073.92594157123, 3433.4970561195437, 26244.165780296975, 42050.43209218572, 8822.22441995725, 11511.482551467452, 2755.5213737167583, 45289.443791743106, 12543.968285928078, 18242.355580839652, 9179.804086469567, 21506.96295443864, 78634.2255304039, 7551.881843155962, 45986.532152795044, 155714.3803611621, 6607.64221365317, 8975.952666383137, 5761.4572038514425, 44755.52016201262, 94123.5517035321, 47733.35290482429, 3334.0337126346203, 1321.8457201551707, 1100.4055042608447, 888.8174583568633, 776.5272967444055, 704.858867795302, 612.7375975958065, 599.152300725717, 431.72887546839286, 395.96458490810073, 395.4958040885161, 395.46635279008785, 390.0856354433877, 374.05749418738714, 350.96075178383313, 342.91337216076994, 312.24941226237075, 305.64373347048183, 305.3638743385885, 296.5141401471182, 293.82574232524206, 251.07971707537453, 229.95321898271445, 227.11887327750622, 224.26281740302215, 219.05346565590975, 202.23390429516905, 202.13824020691888, 198.9966838813237, 200.20946337438264, 1209.6683834140008, 906.6100991483215, 1754.1134008866711, 2879.9974794153777, 5513.887245745049, 1973.8810925601028, 785.2252406025085, 503.7456079159792, 936.6979903373494, 1177.0254085740016, 12855.717383599196, 19670.68021770104, 461.3287143705622, 3032.0775921542404, 6806.240767028519, 10336.033649443463, 2762.6886600139283, 10000.337381640791, 3687.1608124184795, 1730.6195584887812, 7646.338058845206, 45986.532152795044, 5686.722511691453, 155714.3803611621, 21579.18984089186, 6823.423834122047, 13207.777034636243, 4274.820610063696, 7725.282563025134, 22074.0939341202, 37323.50248298863, 44755.52016201262, 8264.922280330215, 5490.4610908420855, 7774.773738948924, 64073.92594157123, 17431.985104937656, 52404.53341954283, 1761.9012589920342, 1345.6695661289737, 1232.2347108012052, 1211.2569243441637, 1079.139186399706, 997.1701537325405, 979.9249510841288, 949.3363158754274, 799.3196185760731, 741.327345143552, 659.7888905222093, 642.0914826331115, 617.7248286862382, 499.1592334317783, 489.38660911442116, 448.5435014697288, 445.9948686163762, 442.8161228198717, 441.26753408230246, 424.23058783196547, 417.63814616873356, 395.77737477177664, 394.871300567574, 393.34128907549973, 369.60870578839524, 352.0517988456616, 330.7014093776859, 295.1648824356319, 294.23650054773276, 281.80463713028564, 1696.3682559312226, 1005.3374205998335, 4732.211254486983, 728.8598134113928, 631.0717420276206, 852.3860846563113, 15385.125715532766, 5395.697421641598, 3957.093193486569, 2192.4200145736017, 1297.9307413614738, 2694.135504829775, 1018.7217211596668, 3678.818607573714, 4621.948504659749, 2857.310079240519, 9615.860572620039, 64073.92594157123, 1880.7652431777603, 2564.8191877032414, 2414.387289887141, 21352.646859243712, 2048.757119870143, 2404.242277477504, 2126.5815905573554, 6533.835749664898, 25971.4816153824, 9140.12183529865, 4010.885992220427, 6196.930085973623, 17044.887922018177, 91194.2259246978, 6577.993288960182, 155714.3803611621, 26244.165780296975, 44755.52016201262, 21497.059924939156, 10444.290281572967, 45289.443791743106, 47239.012805368686, 19670.68021770104, 2191.6668692984763, 1303.602564900002, 1278.1360947027708, 1225.2128751852322, 1213.7233427422948, 1105.9288576060865, 1091.191280452801, 1058.0371440225695, 877.6645452799102, 796.8829183769349, 767.534640721752, 732.400739069067, 719.8976122538234, 706.6228884824928, 643.006532115201, 582.872348141158, 576.3890082956767, 520.2958220159483, 518.2746221871425, 489.94756933515333, 486.4684847539436, 464.30316134007074, 462.86328750218576, 457.816787094556, 437.3821333364205, 436.44399956078996, 489.8950908770516, 404.3734171882211, 399.9005238346795, 393.4779430017762, 777.9645172127099, 995.5806512152515, 909.8429245181059, 806.6705780522049, 1175.918503780422, 994.0944265104135, 2190.1532182148535, 580.4356670108181, 815.0939230036789, 717.047826336641, 1201.7966156855825, 2157.068106390127, 8902.004012181049, 1279.1927504802284, 1311.9676653170395, 1380.3856954166574, 1670.3852097647891, 1276.8546200089195, 1385.5979946438397, 1363.8402316863549, 2568.665295683038, 11184.616997196463, 2782.590807366872, 1246.3016665534262, 10058.608048903756, 9441.111329377338, 12630.49888696288, 11479.688464527862, 2097.01433954172, 25810.683299129243, 6328.434817312672, 20716.957010874205, 2783.2337612188735, 5622.377943232715, 966.3665281233772, 778.2317914593251, 755.37958183609, 480.62583259195355, 473.0654610209604, 439.4502935333674, 927.8108123465672, 353.722014998673, 341.51682693238575, 328.1700824802004, 316.0776447847759, 296.7633925539978, 292.1473592314153, 281.1659604642442, 275.2040335488969, 272.73285777248515, 255.3175417463811, 255.09003836273328, 224.2616339999086, 223.7623326944386, 221.42517524189648, 216.4171244123315, 214.39933220957903, 214.30808725000543, 213.7179352684526, 208.80253034670469, 206.71991601094393, 201.2039560455541, 195.18685918321313, 191.17769772480452, 1676.584049285697, 1042.0116525615447, 2344.987778064022, 1127.372288287719, 2521.2375369150514, 6705.674987244894, 759.5762042156664, 2056.4942338600526, 2505.448170767012, 3634.8100598317014, 14520.892373420247, 591.317230323842, 2896.53708564792, 463.68275548899226, 8386.923508332562, 4374.531201611105, 14331.73805260324, 5735.366076666007, 2005.3875034160938, 2057.112804319305, 12637.343734924412, 7521.261694908411, 3700.896543209371, 4525.174837010452, 44755.52016201262, 1549.4185155836003, 6893.116467222454, 64073.92594157123, 18266.020837697517, 21506.96295443864, 13939.851158066558, 52404.53341954283, 10444.290281572967, 64673.97141390066, 7229.176997671224, 9879.829019937633, 42310.69267844935, 42904.785562195, 29627.59679945139, 45986.532152795044, 1672.5250902263651, 1405.9762109321928, 1034.4972879940683, 1003.1788165141694, 812.0585330235715, 770.9987619373771, 504.42269964191377, 472.65624264684413, 440.2774618234156, 430.9055272284656, 389.40269734427653, 384.0823738279728, 348.9696857463143, 347.5017690961467, 309.481361050045, 288.7578008586948, 284.3641800778524, 252.49378000356296, 246.94991163616498, 232.6752519033335, 226.1059867744747, 225.1914860623587, 209.9621991398159, 196.071116196376, 178.5626783034674, 176.62464039318252, 175.7508739121127, 174.5898600617777, 171.23372375656058, 170.14118410658256, 1195.0989039121578, 2004.9841222225095, 1453.489045881001, 3681.029495802561, 590.8961251991097, 405.55758965098795, 2108.409318277484, 1663.795867722109, 4622.4164306805615, 5481.297017981129, 1272.8833847833434, 1020.7061819349443, 6795.447430738659, 3752.0385101477104, 10000.337381640791, 496.857777193134, 6388.336272686094, 2294.1380120062945, 939.6337108501798, 8613.552133117599, 2362.5503793716543, 2286.5117666417236, 5326.111290755076, 13510.318813438738, 2134.7426518894235, 2713.3723090567114, 44755.52016201262, 11511.482551467452, 42050.43209218572, 29627.59679945139, 6952.372880144339, 52404.53341954283, 64073.92594157123, 37323.50248298863, 22084.170362251032, 51518.644099876496, 51301.54546712539, 64673.97141390066, 7628.929126562578], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic11\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic12\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic13\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic14\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic15\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic16\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic17\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic18\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic19\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\", \"Topic20\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -5.853799819946289, -6.070099830627441, -6.079100131988525, -7.298600196838379, -7.3267998695373535, -7.5625, -7.630300045013428, -7.725399971008301, -7.771399974822998, -4.170199871063232, -7.801599979400635, -7.831500053405762, -7.834199905395508, -7.840799808502197, -7.94920015335083, -7.952000141143799, -7.953199863433838, -7.957099914550781, -8.031999588012695, -8.042499542236328, -8.163399696350098, -8.23900032043457, -8.24779987335205, -8.428899765014648, -8.449600219726562, -8.470600128173828, -8.501299858093262, -8.501700401306152, -8.512399673461914, -8.525500297546387, -7.065400123596191, -7.569799900054932, -6.365499973297119, -4.995800018310547, -6.689499855041504, -4.916299819946289, -7.6493000984191895, -4.958600044250488, -5.532199859619141, -5.21750020980835, -5.065499782562256, -6.14300012588501, -4.722799777984619, -6.636300086975098, -5.138199806213379, -5.453999996185303, -4.444399833679199, -4.676300048828125, -4.761899948120117, -6.89709997177124, -3.9535000324249268, -5.721099853515625, -5.339799880981445, -5.134200096130371, -5.950099945068359, -4.875500202178955, -4.181399822235107, -4.436100006103516, -4.8246002197265625, -5.887599945068359, -5.018099784851074, -5.349599838256836, -5.37939977645874, -5.448599815368652, -5.031099796295166, -5.5406999588012695, -5.304500102996826, -5.393099784851074, -5.316500186920166, -5.4268999099731445, -5.495500087738037, -6.084700107574463, -6.348499774932861, -6.7245001792907715, -6.851099967956543, -7.553800106048584, -7.7555999755859375, -7.923399925231934, -8.0108003616333, -8.015700340270996, -8.052200317382812, -8.178999900817871, -8.194100379943848, -8.232500076293945, -8.253100395202637, -8.389599800109863, -8.392200469970703, -8.39229965209961, -8.398900032043457, -8.470199584960938, -8.512100219726562, -8.544099807739258, -8.590499877929688, -8.625399589538574, -8.675299644470215, -8.746500015258789, -8.753000259399414, -8.759400367736816, -8.761199951171875, -8.791999816894531, -8.819999694824219, -4.145699977874756, -3.8285999298095703, -4.994900226593018, -7.273399829864502, -5.3871002197265625, -5.020999908447266, -8.081999778747559, -6.026899814605713, -7.677999973297119, -6.007900238037109, -7.162600040435791, -5.7758002281188965, -5.51800012588501, -7.000899791717529, -7.97730016708374, -5.3892998695373535, -5.548900127410889, -4.540800094604492, -5.899400234222412, -6.105500221252441, -6.708399772644043, -5.045300006866455, -6.368500232696533, -6.030200004577637, -5.568299770355225, -4.264800071716309, -6.625, -6.383999824523926, -5.164899826049805, -4.563899993896484, -5.986400127410889, -5.536399841308594, -5.820899963378906, -5.290900230407715, -5.332399845123291, -5.258200168609619, -5.378900051116943, -4.762599945068359, -5.207600116729736, -4.583099842071533, -4.765900135040283, -4.212200164794922, -4.64769983291626, -4.525100231170654, -5.001200199127197, -5.214600086212158, -5.241499900817871, -4.707699775695801, -5.191100120544434, -5.266600131988525, -5.004899978637695, -5.354499816894531, -5.339600086212158, -5.354400157928467, -5.378600120544434, -4.741300106048584, -6.44920015335083, -6.637199878692627, -6.903800010681152, -7.041900157928467, -7.132400035858154, -7.132800102233887, -7.154600143432617, -7.504000186920166, -7.570000171661377, -7.69789981842041, -7.7108001708984375, -7.732399940490723, -7.868100166320801, -7.883299827575684, -7.733799934387207, -8.021499633789062, -8.06980037689209, -8.083000183105469, -8.13010025024414, -8.211299896240234, -8.215700149536133, -8.245699882507324, -8.251700401306152, -8.255000114440918, -8.328700065612793, -8.33080005645752, -8.375699996948242, -8.41510009765625, -8.423199653625488, -4.662700176239014, -4.595399856567383, -4.756499767303467, -4.235099792480469, -4.593800067901611, -7.138000011444092, -6.600599765777588, -7.591599941253662, -5.047699928283691, -5.4019999504089355, -6.358799934387207, -6.65910005569458, -6.9644999504089355, -4.765699863433838, -5.911200046539307, -6.8403000831604, -5.412300109863281, -6.661799907684326, -5.331900119781494, -5.599100112915039, -6.061299800872803, -3.725600004196167, -2.9375998973846436, -4.349599838256836, -4.311200141906738, -6.122700214385986, -4.399899959564209, -5.264699935913086, -4.941500186920166, -4.9156999588012695, -5.175099849700928, -4.839799880981445, -5.574100017547607, -4.6697998046875, -5.622399806976318, -5.478000164031982, -5.028600215911865, -5.480199813842773, -5.692999839782715, -5.467400074005127, -5.303599834442139, -5.459499835968018, -5.480299949645996, -5.466400146484375, -6.35290002822876, -6.546599864959717, -6.992199897766113, -7.067500114440918, -7.11929988861084, -7.1528000831604, -7.322299957275391, -7.374000072479248, -7.438199996948242, -7.446800231933594, -7.468299865722656, -7.503799915313721, -7.512700080871582, -7.5671000480651855, -7.62529993057251, -7.6442999839782715, -7.682199954986572, -7.742599964141846, -7.940899848937988, -7.9496002197265625, -7.985300064086914, -8.08650016784668, -8.105500221252441, -8.11340045928955, -8.116600036621094, -8.203300476074219, -8.214400291442871, -8.275899887084961, -8.307100296020508, -8.312199592590332, -5.772200107574463, -7.080100059509277, -7.841300010681152, -6.821800231933594, -3.9456000328063965, -4.512499809265137, -5.826000213623047, -5.8902997970581055, -4.6092000007629395, -7.030700206756592, -7.291800022125244, -4.3582000732421875, -6.973199844360352, -5.61299991607666, -6.231400012969971, -4.432000160217285, -5.778500080108643, -5.829400062561035, -5.785200119018555, -4.726799964904785, -4.755799770355225, -3.8190999031066895, -3.442500114440918, -5.081600189208984, -5.58050012588501, -4.899499893188477, -4.94189977645874, -4.055699825286865, -5.911099910736084, -5.394499778747559, -5.204100131988525, -5.1894001960754395, -5.480899810791016, -4.060400009155273, -5.043099880218506, -4.9471001625061035, -5.0366997718811035, -5.3850998878479, -4.541200160980225, -5.2804999351501465, -5.012199878692627, -5.351900100708008, -5.237400054931641, -5.446000099182129, -5.417399883270264, -5.471499919891357, -4.824100017547607, -5.818399906158447, -5.959400177001953, -6.3267998695373535, -6.4105000495910645, -6.421999931335449, -6.527599811553955, -6.715700149536133, -7.064599990844727, -7.0808000564575195, -7.11959981918335, -7.192399978637695, -7.2621002197265625, -7.379000186920166, -7.475599765777588, -7.570400238037109, -7.5903000831604, -7.630499839782715, -7.695400238037109, -7.707600116729736, -7.7459001541137695, -7.779300212860107, -7.870800018310547, -7.894400119781494, -7.9105000495910645, -8.078800201416016, -8.111200332641602, -8.126199722290039, -8.149800300598145, -8.150400161743164, -5.082799911499023, -5.537300109863281, -7.878900051116943, -6.196899890899658, -6.904600143432617, -6.654900074005127, -6.776599884033203, -7.503200054168701, -5.1774001121521, -6.928800106048584, -6.504700183868408, -5.069399833679199, -7.1128997802734375, -5.61299991607666, -6.413700103759766, -6.805099964141846, -6.216599941253662, -5.398900032043457, -5.551000118255615, -4.903900146484375, -4.644599914550781, -4.425000190734863, -5.8165998458862305, -5.693900108337402, -5.914599895477295, -6.249599933624268, -5.772600173950195, -5.379799842834473, -4.685100078582764, -5.031400203704834, -5.404099941253662, -4.876100063323975, -5.289400100708008, -5.337900161743164, -5.5416998863220215, -5.461299896240234, -5.230000019073486, -5.562099933624268, -5.373499870300293, -5.498499870300293, -5.4197001457214355, -5.298799991607666, -5.507400035858154, -5.61299991607666, -5.592899799346924, -5.647500038146973, -6.019499778747559, -6.5320000648498535, -6.556700229644775, -6.5640997886657715, -6.815299987792969, -6.889400005340576, -6.9542999267578125, -7.063300132751465, -7.218100070953369, -7.238500118255615, -7.301799774169922, -7.3246002197265625, -7.512800216674805, -7.531700134277344, -7.570000171661377, -7.573200225830078, -7.651000022888184, -4.376299858093262, -7.788700103759766, -7.84630012512207, -7.84660005569458, -7.901400089263916, -8.089200019836426, -8.104900360107422, -8.135499954223633, -8.144800186157227, -8.183799743652344, -8.217900276184082, -8.224900245666504, -8.245200157165527, -3.7660999298095703, -6.2266998291015625, -4.862299919128418, -7.896699905395508, -7.1732001304626465, -4.564300060272217, -7.68149995803833, -2.6816000938415527, -6.445499897003174, -7.56820011138916, -5.270699977874756, -7.248799800872803, -4.125400066375732, -6.181600093841553, -6.442500114440918, -4.703199863433838, -5.285999774932861, -4.091400146484375, -6.44290018081665, -3.5522000789642334, -4.0995001792907715, -3.813800096511841, -5.797699928283691, -6.664400100708008, -5.055300235748291, -4.133500099182129, -3.7950000762939453, -6.451099872589111, -4.7866997718811035, -5.554500102996826, -5.045499801635742, -5.177199840545654, -4.921899795532227, -5.3308000564575195, -5.617199897766113, -5.3480000495910645, -5.595300197601318, -5.424799919128418, -5.337299823760986, -5.385799884796143, -5.517199993133545, -5.374100208282471, -5.578400135040283, -4.144000053405762, -5.44950008392334, -5.821599960327148, -5.837600231170654, -6.484099864959717, -7.094900131225586, -7.107800006866455, -7.168700218200684, -7.232100009918213, -7.348999977111816, -7.3815999031066895, -7.41540002822876, -7.493500232696533, -7.500800132751465, -7.611299991607666, -7.633699893951416, -7.706699848175049, -7.7144999504089355, -7.8379998207092285, -7.85099983215332, -7.858399868011475, -7.89109992980957, -7.906599998474121, -7.914400100708008, -7.924699783325195, -7.936100006103516, -7.962800025939941, -7.974800109863281, -8.00730037689209, -8.039799690246582, -5.8028998374938965, -3.746999979019165, -3.9514000415802, -5.3246002197265625, -5.359099864959717, -6.513899803161621, -7.323999881744385, -5.985099792480469, -6.80620002746582, -5.525700092315674, -3.4022998809814453, -3.8952999114990234, -5.382999897003174, -5.684199810028076, -4.566699981689453, -4.256400108337402, -5.342800140380859, -6.076099872589111, -4.9552001953125, -6.8317999839782715, -3.747299909591675, -4.793399810791016, -5.743100166320801, -6.205100059509277, -5.22629976272583, -4.540800094604492, -4.707200050354004, -4.228600025177002, -5.806300163269043, -5.197700023651123, -4.180099964141846, -5.184199810028076, -5.383900165557861, -4.660799980163574, -4.877500057220459, -4.905300140380859, -4.989099979400635, -4.844699859619141, -5.04010009765625, -5.095099925994873, -5.174900054931641, -5.1479997634887695, -5.247600078582764, -5.296299934387207, -4.987299919128418, -6.241199970245361, -6.894199848175049, -6.970900058746338, -7.182700157165527, -7.478400230407715, -7.699100017547607, -7.748499870300293, -7.785999774932861, -7.811500072479248, -7.815499782562256, -7.827300071716309, -7.899600028991699, -7.920499801635742, -8.004300117492676, -8.010499954223633, -8.094900131225586, -8.098600387573242, -8.106800079345703, -8.112199783325195, -8.156599998474121, -8.263400077819824, -8.269700050354004, -8.351699829101562, -8.365599632263184, -8.378000259399414, -8.402099609375, -8.407899856567383, -8.433099746704102, -8.435600280761719, -6.8927001953125, -5.336400032043457, -6.418099880218506, -7.157400131225586, -5.383699893951416, -6.539599895477295, -5.911900043487549, -7.50029993057251, -5.334099769592285, -6.972400188446045, -5.632699966430664, -6.21750020980835, -6.649700164794922, -5.369100093841553, -5.90939998626709, -3.7774999141693115, -4.758800029754639, -5.225100040435791, -6.2571001052856445, -4.446599960327148, -7.030099868774414, -6.920400142669678, -4.842299938201904, -6.239299774169922, -4.823299884796143, -5.76170015335083, -6.265999794006348, -5.989999771118164, -5.734799861907959, -5.040599822998047, -5.55709981918335, -4.967800140380859, -5.451000213623047, -5.442599773406982, -5.777400016784668, -5.580599784851074, -4.737599849700928, -5.226500034332275, -5.0269999504089355, -5.022200107574463, -4.769700050354004, -5.4456000328063965, -4.700300216674805, -4.549699783325195, -4.867499828338623, -4.785099983215332, -5.291200160980225, -5.063499927520752, -5.11870002746582, -5.212600231170654, -5.197999954223633, -3.690700054168701, -4.18149995803833, -4.300000190734863, -4.695400238037109, -5.0782999992370605, -5.151700019836426, -6.059800148010254, -6.187900066375732, -6.406000137329102, -6.576000213623047, -6.651400089263916, -6.664999961853027, -6.770400047302246, -6.7758002281188965, -6.874499797821045, -6.955399990081787, -6.957600116729736, -7.15310001373291, -7.158299922943115, -7.169300079345703, -7.221799850463867, -7.353300094604492, -7.556300163269043, -7.579999923706055, -7.580100059509277, -7.589099884033203, -7.726600170135498, -7.7266998291015625, -7.729100227355957, -7.77209997177124, -4.735599994659424, -5.895699977874756, -5.607699871063232, -4.642499923706055, -3.9019999504089355, -5.851900100708008, -5.445300102233887, -7.394999980926514, -5.605299949645996, -5.147500038146973, -4.691500186920166, -6.593400001525879, -3.7332000732421875, -5.538400173187256, -5.054200172424316, -6.156700134277344, -5.362599849700928, -3.9398999214172363, -5.1356000900268555, -4.776800155639648, -4.541900157928467, -5.420300006866455, -5.456699848175049, -5.556300163269043, -4.379300117492676, -4.6107001304626465, -5.084000110626221, -4.838900089263916, -5.35129976272583, -5.0833001136779785, -5.326399803161621, -5.323200225830078, -5.373000144958496, -5.4095001220703125, -4.5792999267578125, -5.738100051879883, -6.534299850463867, -6.648600101470947, -6.804900169372559, -6.845200061798096, -6.966400146484375, -7.034999847412109, -7.107600212097168, -7.217400074005127, -7.227399826049805, -7.275000095367432, -7.298099994659424, -7.339900016784668, -7.378900051116943, -7.451399803161621, -7.497499942779541, -7.781599998474121, -7.871600151062012, -7.877699851989746, -7.9070000648498535, -7.911399841308594, -7.983099937438965, -7.991300106048584, -7.994999885559082, -8.017200469970703, -8.035200119018555, -8.050999641418457, -8.056699752807617, -8.073699951171875, -5.368199825286865, -5.111000061035156, -6.230100154876709, -2.807499885559082, -4.965199947357178, -5.161300182342529, -5.264200210571289, -4.090700149536133, -4.136000156402588, -4.968699932098389, -7.086699962615967, -5.730100154876709, -4.682000160217285, -5.218200206756592, -5.7480998039245605, -5.005099773406982, -5.93179988861084, -5.461999893188477, -5.014800071716309, -6.065700054168701, -4.852399826049805, -4.745500087738037, -5.749800205230713, -5.581500053405762, -4.477399826049805, -5.951399803161621, -5.4847002029418945, -4.825200080871582, -5.541200160980225, -4.337800025939941, -4.7382001876831055, -5.3607001304626465, -5.2519001960754395, -5.10099983215332, -4.998600006103516, -4.955699920654297, -5.273399829864502, -5.220799922943115, -5.485000133514404, -3.340399980545044, -3.875, -3.905600070953369, -4.832399845123291, -6.051000118255615, -6.6265997886657715, -6.678899765014648, -6.698800086975098, -6.890100002288818, -6.941800117492676, -7.239699840545654, -7.292300224304199, -7.386300086975098, -7.396399974822998, -7.4328999519348145, -7.434199810028076, -7.452499866485596, -7.514100074768066, -7.535399913787842, -7.540900230407715, -7.64300012588501, -7.722700119018555, -7.7403998374938965, -7.759099960327148, -7.759399890899658, -7.764800071716309, -7.7718000411987305, -7.783699989318848, -7.788599967956543, -7.8292999267578125, -3.3970000743865967, -6.040599822998047, -4.062399864196777, -4.111000061035156, -6.1508002281188965, -6.2600998878479, -5.774899959564209, -5.426599979400635, -6.12529993057251, -6.7256999015808105, -5.582399845123291, -6.1645002365112305, -6.397600173950195, -5.193600177764893, -5.993199825286865, -6.181000232696533, -4.342199802398682, -5.451200008392334, -6.337699890136719, -6.053699970245361, -5.934500217437744, -5.679900169372559, -3.8622000217437744, -4.214600086212158, -5.97189998626709, -4.474299907684326, -5.010300159454346, -4.891499996185303, -5.870500087738037, -5.1504998207092285, -5.026000022888184, -5.59089994430542, -5.268799781799316, -5.536900043487549, -5.404300212860107, -5.503300189971924, -5.48360013961792, -5.609399795532227, -5.577700138092041, -5.814000129699707, -5.731800079345703, -5.7606000900268555, -6.599299907684326, -6.726500034332275, -6.875400066375732, -6.998000144958496, -7.09119987487793, -7.095099925994873, -7.11269998550415, -7.141900062561035, -7.158400058746338, -7.170599937438965, -7.186999797821045, -7.205100059509277, -7.24459981918335, -7.262499809265137, -7.265500068664551, -7.274099826812744, -7.386099815368652, -7.406599998474121, -7.444300174713135, -7.459700107574463, -7.581399917602539, -7.5980000495910645, -7.605299949645996, -7.662799835205078, -7.680799961090088, -7.71120023727417, -7.725800037384033, -7.7505998611450195, -7.797100067138672, -7.8028998374938965, -6.809800148010254, -5.813399791717529, -6.794899940490723, -7.214600086212158, -4.297800064086914, -5.758600234985352, -4.253200054168701, -6.167799949645996, -5.803899765014648, -6.426000118255615, -5.013700008392334, -6.192299842834473, -5.159200191497803, -5.982100009918213, -5.207099914550781, -6.3805999755859375, -5.917699813842773, -5.909800052642822, -6.368899822235107, -6.2829999923706055, -5.317399978637695, -4.9481000900268555, -4.97760009765625, -5.5081000328063965, -6.073800086975098, -5.2617998123168945, -6.30019998550415, -5.040999889373779, -5.223199844360352, -5.7789998054504395, -5.015200138092041, -3.889899969100952, -5.080999851226807, -4.996399879455566, -5.557300090789795, -4.636899948120117, -5.458099842071533, -5.5304999351501465, -5.028600215911865, -5.53849983215332, -5.7322001457214355, -5.73360013961792, -5.529699802398682, -5.526899814605713, -5.621099948883057, -5.743500232696533, -5.77239990234375, -4.23769998550415, -4.529799938201904, -6.241000175476074, -6.30620002746582, -6.382199764251709, -6.433499813079834, -6.638999938964844, -6.685200214385986, -6.696700096130371, -7.021100044250488, -7.125999927520752, -7.186600208282471, -7.22160005569458, -7.235499858856201, -7.313499927520752, -4.92609977722168, -7.343699932098389, -7.422599792480469, -7.446800231933594, -7.457699775695801, -7.494100093841553, -7.528900146484375, -7.595200061798096, -7.6194000244140625, -7.620200157165527, -7.642499923706055, -7.715799808502197, -7.749100208282471, -7.8358001708984375, -7.849599838256836, -2.6777000427246094, -5.145699977874756, -5.56850004196167, -4.951399803161621, -5.4583001136779785, -6.69350004196167, -6.521900177001953, -5.260700225830078, -5.342299938201904, -5.125400066375732, -6.474800109863281, -7.054100036621094, -3.912100076675415, -4.867700099945068, -6.190700054168701, -6.521200180053711, -5.802499771118164, -5.218599796295166, -5.225399971008301, -6.234600067138672, -5.546500205993652, -4.805099964141846, -5.3572001457214355, -5.210400104522705, -5.966700077056885, -5.919300079345703, -4.8231000900268555, -4.720600128173828, -5.413599967956543, -4.902599811553955, -5.921299934387207, -5.430799961090088, -4.829899787902832, -4.593999862670898, -5.462299823760986, -5.035200119018555, -5.702700138092041, -5.643499851226807, -5.308300018310547, -5.267399787902832, -5.38040018081665, -5.429900169372559, -5.076600074768066, -5.187600135803223, -5.78849983215332, -5.823599815368652, -6.045400142669678, -6.1717000007629395, -6.845300197601318, -6.858399868011475, -6.998799800872803, -7.1682000160217285, -7.279699802398682, -7.338500022888184, -7.359399795532227, -7.382999897003174, -7.389900207519531, -7.418000221252441, -7.440999984741211, -7.5381999015808105, -7.5441999435424805, -7.5619001388549805, -7.580399990081787, -7.642600059509277, -7.716800212860107, -7.750999927520752, -7.760799884796143, -7.797999858856201, -7.860400199890137, -7.877299785614014, -7.89769983291626, -7.9421000480651855, -5.783199787139893, -5.800000190734863, -2.962899923324585, -5.036900043487549, -6.303299903869629, -3.310699939727783, -7.4253997802734375, -6.5065999031066895, -5.186200141906738, -5.8358001708984375, -5.564300060272217, -5.394000053405762, -4.908999919891357, -6.4131999015808105, -5.4653000831604, -6.40749979019165, -4.825500011444092, -5.17080020904541, -5.880499839782715, -4.782100200653076, -5.712100028991699, -5.061999797821045, -4.535799980163574, -4.86899995803833, -4.956500053405762, -3.7551000118255615, -4.865799903869629, -3.728800058364868, -5.26230001449585, -4.746799945831299, -5.281700134277344, -5.448599815368652, -4.9695000648498535, -5.134699821472168, -4.9984002113342285, -5.1290998458862305, -5.359899997711182, -5.479700088500977, -5.384500026702881, -4.660799980163574, -4.961699962615967, -5.222499847412109, -5.965400218963623, -6.053199768066406, -6.286099910736084, -6.298900127410889, -6.310800075531006, -6.442699909210205, -6.46589994430542, -6.555600166320801, -6.717299938201904, -6.926799774169922, -6.933899879455566, -6.964900016784668, -7.003600120544434, -7.031199932098389, -7.047900199890137, -7.119900226593018, -7.196499824523926, -7.213500022888184, -7.260700225830078, -7.287499904632568, -7.303800106048584, -7.35699987411499, -7.395299911499023, -7.402100086212158, -7.4207000732421875, -7.453100204467773, -7.496500015258789, -3.1463000774383545, -6.1203999519348145, -6.206399917602539, -6.790999889373779, -5.601099967956543, -5.805699825286865, -6.0868000984191895, -6.430200099945068, -5.466800212860107, -6.467299938201904, -4.290500164031982, -6.223599910736084, -6.2245001792907715, -6.240300178527832, -5.018700122833252, -5.489699840545654, -6.145400047302246, -4.417500019073486, -4.033899784088135, -5.801499843597412, -5.003900051116943, -4.179900169372559, -5.734799861907959, -4.739999771118164, -4.562099933624268, -5.301000118255615, -5.222599983215332, -5.857699871063232, -4.84499979019165, -5.3256001472473145, -5.191299915313721, -5.451300144195557, -5.1458001136779785, -4.744999885559082, -5.540599822998047, -5.053100109100342, -4.736499786376953, -5.630499839782715, -5.577400207519531, -5.667399883270264, -5.443299770355225, -5.478499889373779, -5.624300003051758, -4.883699893951416, -5.809199810028076, -5.992700099945068, -6.206500053405762, -6.341700077056885, -6.438600063323975, -6.57889986038208, -6.60129976272583, -6.929699897766113, -7.016300201416016, -7.017499923706055, -7.017600059509277, -7.031300067901611, -7.073400020599365, -7.13730001449585, -7.1605000495910645, -7.254499912261963, -7.275899887084961, -7.276800155639648, -7.306300163269043, -7.315499782562256, -7.473199844360352, -7.561399936676025, -7.57390022277832, -7.586599826812744, -7.610199928283691, -7.690400123596191, -7.690899848937988, -7.706600189208984, -7.7006001472473145, -5.90339994430542, -6.198699951171875, -5.552299976348877, -5.084000110626221, -4.44920015335083, -5.475299835205078, -6.400400161743164, -6.819300174713135, -6.244999885559082, -6.0467000007629395, -3.902400016784668, -3.606300115585327, -6.928199768066406, -5.385200023651123, -4.729100227355957, -4.42519998550415, -5.532199859619141, -4.665900230407715, -5.436399936676025, -5.975299835205078, -4.993299961090088, -3.789599895477295, -5.246099948883057, -3.1157000064849854, -4.506400108337402, -5.217199802398682, -4.886199951171875, -5.616199970245361, -5.443999767303467, -5.123799800872803, -5.013899803161621, -4.96750020980835, -5.525000095367432, -5.645500183105469, -5.678500175476074, -5.477799892425537, -5.614299774169922, -5.6149001121521, -5.505000114440918, -5.774600028991699, -5.862800121307373, -5.879899978637695, -5.995500087738037, -6.0746002197265625, -6.092100143432617, -6.123799800872803, -6.296000003814697, -6.371399879455566, -6.488100051879883, -6.5152997970581055, -6.553999900817871, -6.767499923706055, -6.787300109863281, -6.874599933624268, -6.880300045013428, -6.887499809265137, -6.890999794006348, -6.930500030517578, -6.946199893951416, -7.000100135803223, -7.002299785614014, -7.006199836730957, -7.068600177764893, -7.117400169372559, -7.180099964141846, -7.2941999435424805, -7.297299861907959, -7.34060001373291, -5.561999797821045, -6.123300075531006, -4.662499904632568, -6.437300205230713, -6.57480001449585, -6.311399936676025, -3.7952001094818115, -4.811399936676025, -5.102399826049805, -5.605999946594238, -6.030200004577637, -5.457699775695801, -6.228899955749512, -5.229599952697754, -5.053500175476074, -5.4415998458862305, -4.59119987487793, -3.2390999794006348, -5.815000057220459, -5.662199974060059, -5.702700138092041, -4.377699851989746, -5.8506999015808105, -5.772299766540527, -5.840400218963623, -5.296299934387207, -4.673500061035156, -5.249599933624268, -5.597899913787842, -5.459700107574463, -5.147799968719482, -4.861599922180176, -5.548099994659424, -4.842299938201904, -5.2631001472473145, -5.310500144958496, -5.425000190734863, -5.550899982452393, -5.396699905395508, -5.49560022354126, -5.609399795532227, -5.158699989318848, -5.678599834442139, -5.698299884796143, -5.740600109100342, -5.75, -5.843100070953369, -5.856599807739258, -5.887400150299072, -6.07450008392334, -6.171199798583984, -6.208700180053711, -6.25570011138916, -6.272900104522705, -6.291500091552734, -6.386000156402588, -6.484300136566162, -6.495500087738037, -6.598100185394287, -6.6020002365112305, -6.658299922943115, -6.66540002822876, -6.712200164794922, -6.7153000831604, -6.72629976272583, -6.771999835968018, -6.774199962615967, -6.658699989318848, -6.8506999015808105, -6.861800193786621, -6.877999782562256, -6.200300216674805, -5.957699775695801, -6.051300048828125, -6.180600166320801, -5.861400127410889, -6.018700122833252, -5.306000232696533, -6.5142998695373535, -6.225299835205078, -6.3368000984191895, -5.929699897766113, -5.468299865722656, -4.393099784851074, -5.906499862670898, -5.916299819946289, -5.899600028991699, -5.774400234222412, -5.985400199890137, -5.94379997253418, -5.972599983215332, -5.6828999519348145, -5.134300231933594, -5.749499797821045, -6.035099983215332, -5.347400188446045, -5.381499767303467, -5.330699920654297, -5.620699882507324, -5.92519998550415, -5.646599769592285, -5.839000225067139, -5.7403998374938965, -5.91379976272583, -5.9243998527526855, -5.9633002281188965, -6.180099964141846, -6.210000038146973, -6.662700176239014, -6.678599834442139, -6.752500057220459, -6.005300045013428, -6.96999979019165, -7.005199909210205, -7.045199871063232, -7.082799911499023, -7.146100044250488, -7.161799907684326, -7.200200080871582, -7.221700191497803, -7.230800151824951, -7.296999931335449, -7.297900199890137, -7.427199840545654, -7.4293999671936035, -7.440000057220459, -7.462900161743164, -7.472300052642822, -7.472799777984619, -7.475500106811523, -7.498899936676025, -7.508999824523926, -7.536099910736084, -7.5665998458862305, -7.587500095367432, -5.43120002746582, -5.939599990844727, -5.172100067138672, -5.882500171661377, -5.172900199890137, -4.272600173950195, -6.298099994659424, -5.388400077819824, -5.254000186920166, -4.958499908447266, -3.746000051498413, -6.576700210571289, -5.249499797821045, -6.7982001304626465, -4.4253997802734375, -4.982500076293945, -4.141600131988525, -4.853899955749512, -5.676199913024902, -5.747700214385986, -4.464700222015381, -4.883299827575684, -5.407299995422363, -5.334199905395508, -3.878999948501587, -6.026000022888184, -5.192999839782715, -4.035999774932861, -4.757999897003174, -4.71150016784668, -4.941299915313721, -4.852200031280518, -5.368899822235107, -4.8993000984191895, -5.481400012969971, -5.433300018310547, -5.156099796295166, -5.25540018081665, -5.318600177764893, -5.276299953460693, -5.176400184631348, -5.350100040435791, -5.657100200653076, -5.687900066375732, -5.899499893188477, -5.951399803161621, -6.376299858093262, -6.441500186920166, -6.512599945068359, -6.534200191497803, -6.635700225830078, -6.649499893188477, -6.74560022354126, -6.749800205230713, -6.866000175476074, -6.935500144958496, -6.950900077819824, -7.070199966430664, -7.09250020980835, -7.152200222015381, -7.181000232696533, -7.185100078582764, -7.25540018081665, -7.324100017547607, -7.418099880218506, -7.429100036621094, -7.434100151062012, -7.440800189971924, -7.460299968719482, -7.466700077056885, -5.554999828338623, -5.103000164031982, -5.409200191497803, -4.5655999183654785, -6.3028998374938965, -6.654300212860107, -5.13730001449585, -5.364099979400635, -4.439899921417236, -4.404900074005127, -5.709499835968018, -5.914100170135498, -4.34630012512207, -4.866399765014648, -4.129700183868408, -6.517499923706055, -4.767399787902832, -5.47599983215332, -6.1006999015808105, -4.679999828338623, -5.55810022354126, -5.618100166320801, -5.156599998474121, -4.717800140380859, -5.680600166320801, -5.567399978637695, -4.304999828338623, -5.107399940490723, -4.629700183868408, -4.905399799346924, -5.327499866485596, -4.922800064086914, -4.905399799346924, -5.154699802398682, -5.258800029754639, -5.215099811553955, -5.353300094604492, -5.481599807739258, -5.543000221252441], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 2.3123, 2.3123, 2.3122, 2.3117, 2.3117, 2.3114, 2.3114, 2.3112, 2.3112, 2.3112, 2.3111, 2.3111, 2.3111, 2.3111, 2.3109, 2.3109, 2.3109, 2.3109, 2.3108, 2.3108, 2.3106, 2.3104, 2.3104, 2.31, 2.3099, 2.3099, 2.3098, 2.3098, 2.3097, 2.3097, 2.3089, 2.3065, 2.2514, 2.2083, 2.2025, 2.0145, 2.2488, 1.9883, 2.0096, 1.931, 1.8489, 2.0116, 1.7775, 2.0553, 1.7249, 1.738, 1.4694, 1.5245, 1.534, 2.0722, 1.2404, 1.6659, 1.5141, 1.4336, 1.7183, 1.2835, 0.981, 0.9595, 1.0663, 1.5392, 0.9299, 1.0683, 1.0857, 1.079, 0.5065, 1.0979, 0.6604, 0.5504, 0.0093, 0.4144, 0.2095, 2.3335, 2.3334, 2.3333, 2.3332, 2.3327, 2.3324, 2.3322, 2.332, 2.332, 2.332, 2.3317, 2.3317, 2.3316, 2.3316, 2.3312, 2.3312, 2.3312, 2.3312, 2.331, 2.3309, 2.3308, 2.3307, 2.3306, 2.3304, 2.3302, 2.3301, 2.3301, 2.3301, 2.33, 2.3299, 2.2754, 2.2486, 2.2565, 2.2883, 2.2198, 2.1795, 2.3019, 2.1922, 2.2773, 2.1493, 2.2341, 2.0959, 2.04, 2.1793, 2.287, 1.991, 1.9996, 1.8611, 2.0252, 2.0365, 2.1029, 1.8315, 2.0361, 1.9689, 1.8767, 1.5984, 2.0754, 2.0184, 1.7312, 1.5434, 1.9092, 1.7732, 1.849, 1.6892, 1.6278, 1.5801, 1.6116, 1.2247, 1.4315, 1.0302, 1.125, 0.7225, 0.9143, 0.6373, 0.9468, 1.1861, 1.1981, 0.3308, 1.1072, 1.1896, 0.3208, 1.3151, 0.6287, 0.5885, 0.879, 2.377, 2.3767, 2.3766, 2.3765, 2.3764, 2.3764, 2.3764, 2.3763, 2.376, 2.376, 2.3758, 2.3758, 2.3757, 2.3756, 2.3755, 2.3754, 2.3753, 2.3752, 2.3752, 2.3751, 2.3749, 2.3749, 2.3749, 2.3748, 2.3748, 2.3747, 2.3747, 2.3745, 2.3744, 2.3744, 2.3717, 2.3671, 2.3671, 2.3482, 2.3518, 2.3739, 2.3567, 2.3617, 2.2641, 2.2773, 2.2954, 2.3078, 2.31, 2.1584, 2.2345, 2.2921, 2.1539, 2.2665, 2.1005, 2.1284, 2.1804, 1.8877, 1.7213, 1.8549, 1.552, 2.0509, 1.4415, 1.6596, 1.5085, 1.1915, 1.3252, 1.0511, 1.5206, 0.5242, 1.4206, 1.1635, 0.509, 1.0876, 1.3768, 0.8284, 0.092, 0.5088, 0.4847, -0.5317, 2.5442, 2.5441, 2.5439, 2.5438, 2.5438, 2.5437, 2.5436, 2.5435, 2.5434, 2.5434, 2.5434, 2.5434, 2.5433, 2.5433, 2.5432, 2.5432, 2.5431, 2.543, 2.5427, 2.5426, 2.5426, 2.5423, 2.5423, 2.5423, 2.5423, 2.5421, 2.542, 2.5419, 2.5418, 2.5418, 2.5339, 2.5414, 2.5415, 2.5221, 2.4542, 2.4491, 2.4766, 2.4197, 2.2955, 2.4734, 2.4778, 2.1666, 2.4402, 2.2552, 2.3372, 2.0614, 2.257, 2.2538, 2.2353, 2.0342, 2.038, 1.6505, 1.4923, 1.9196, 2.0284, 1.7002, 1.6997, 1.3399, 2.0516, 1.836, 1.7439, 1.7327, 1.8061, 1.1019, 1.3748, 1.2119, 1.2756, 1.486, 0.4974, 1.1489, 0.3136, 1.0488, 0.604, 0.9935, 0.6699, 0.9393, 2.6029, 2.6027, 2.6027, 2.6026, 2.6025, 2.6025, 2.6025, 2.6024, 2.6021, 2.6021, 2.6021, 2.602, 2.6019, 2.6018, 2.6017, 2.6015, 2.6015, 2.6015, 2.6014, 2.6013, 2.6013, 2.6012, 2.601, 2.601, 2.601, 2.6006, 2.6005, 2.6005, 2.6004, 2.6004, 2.5809, 2.5582, 2.5948, 2.524, 2.5526, 2.5381, 2.5335, 2.5756, 2.3169, 2.4994, 2.4368, 2.2406, 2.4918, 2.1973, 2.3546, 2.4305, 2.133, 1.8429, 1.8448, 1.4757, 1.1247, 0.9008, 1.7529, 1.5874, 1.6893, 1.9165, 1.4107, 1.0049, 0.2496, 0.5467, 0.9826, 0.3179, 0.6756, 0.6056, 0.8876, 0.7377, 0.3076, 0.8499, 0.3315, 0.3954, 0.1423, -0.2602, 0.3443, 0.4655, -0.1233, -0.252, 2.8468, 2.8466, 2.8466, 2.8466, 2.8464, 2.8463, 2.8462, 2.8461, 2.8459, 2.8459, 2.8458, 2.8458, 2.8455, 2.8454, 2.8454, 2.8454, 2.8452, 2.8452, 2.8449, 2.8448, 2.8448, 2.8446, 2.8441, 2.844, 2.8439, 2.8439, 2.8438, 2.8436, 2.8436, 2.8435, 2.8171, 2.8372, 2.812, 2.8424, 2.8258, 2.7438, 2.8313, 2.6605, 2.7903, 2.8235, 2.6438, 2.7972, 2.4914, 2.6889, 2.7059, 2.4761, 2.5467, 2.3473, 2.6798, 2.2129, 2.2188, 2.1543, 2.4434, 2.6681, 2.1595, 1.7352, 1.2435, 2.544, 1.1613, 1.2487, 0.5326, 0.6641, 0.2404, 0.6312, 1.018, 0.4213, 0.9294, 0.481, 0.2248, 0.3621, 0.69, 0.1635, 0.7614, 3.0092, 3.009, 3.0089, 3.0089, 3.0085, 3.0079, 3.0079, 3.0078, 3.0077, 3.0075, 3.0075, 3.0074, 3.0073, 3.0073, 3.007, 3.007, 3.0068, 3.0068, 3.0065, 3.0064, 3.0064, 3.0063, 3.0063, 3.0062, 3.0062, 3.0062, 3.0061, 3.006, 3.0059, 3.0058, 3.002, 2.9616, 2.9396, 2.9229, 2.906, 2.9383, 2.9646, 2.8575, 2.9112, 2.7638, 2.4664, 2.5127, 2.6624, 2.6948, 2.3584, 2.2711, 2.3493, 2.5708, 2.0678, 2.7767, 1.4467, 1.8524, 2.2609, 2.4799, 1.957, 1.5377, 1.5001, 1.0971, 2.2005, 1.7388, 0.8585, 1.6168, 1.8308, 0.8768, 1.0705, 1.0566, 1.0049, 0.5509, 0.8508, 0.8484, 0.9124, 0.414, 0.7173, 1.133, 3.0423, 3.0419, 3.0414, 3.0413, 3.041, 3.0405, 3.04, 3.0398, 3.0397, 3.0397, 3.0397, 3.0396, 3.0394, 3.0393, 3.0391, 3.039, 3.0387, 3.0387, 3.0387, 3.0387, 3.0385, 3.038, 3.038, 3.0376, 3.0376, 3.0375, 3.0374, 3.0373, 3.0372, 3.0372, 3.0194, 2.9857, 2.9912, 2.9932, 2.9073, 2.9083, 2.787, 2.9452, 2.6562, 2.8659, 2.6528, 2.7388, 2.7985, 2.5576, 2.6394, 2.1363, 2.2893, 2.3964, 2.6395, 2.1531, 2.8082, 2.7677, 2.1058, 2.5505, 2.0466, 2.3675, 2.5381, 2.4151, 2.3041, 1.9498, 2.1951, 1.8423, 2.0571, 1.9384, 2.1792, 1.9949, 1.2497, 1.6391, 1.4081, 1.3957, 1.082, 1.8208, 0.8778, 0.6127, 1.0382, 0.6845, 1.5471, 0.6415, 0.4433, 0.7557, 0.1278, 3.0572, 3.0572, 3.0571, 3.0571, 3.057, 3.057, 3.0567, 3.0567, 3.0565, 3.0564, 3.0563, 3.0563, 3.0562, 3.0562, 3.0561, 3.056, 3.056, 3.0557, 3.0557, 3.0557, 3.0556, 3.0554, 3.055, 3.0549, 3.0549, 3.0549, 3.0546, 3.0546, 3.0546, 3.0544, 3.0511, 3.0532, 3.0493, 3.0229, 3.0069, 2.9835, 2.9262, 3.0418, 2.8528, 2.671, 2.5696, 2.9097, 2.1454, 2.5449, 2.2383, 2.7029, 2.2177, 1.0987, 1.9089, 1.6239, 1.3099, 2.0156, 2.0272, 2.0998, 0.5554, 0.5517, 1.2283, 0.6307, 1.4506, 0.4636, 0.617, 0.5826, 0.8278, 0.1281, 3.0947, 3.0944, 3.094, 3.0939, 3.0937, 3.0937, 3.0935, 3.0934, 3.0933, 3.0932, 3.0931, 3.0931, 3.093, 3.0929, 3.0929, 3.0927, 3.0926, 3.0919, 3.0916, 3.0916, 3.0915, 3.0915, 3.0913, 3.0912, 3.0912, 3.0911, 3.0911, 3.091, 3.091, 3.0909, 3.0785, 3.0702, 3.0775, 2.9668, 3.0181, 3.0203, 3.0145, 2.9606, 2.9372, 2.9304, 3.0472, 2.939, 2.8061, 2.7825, 2.8485, 2.6947, 2.8474, 2.7146, 2.5865, 2.8211, 2.4118, 2.2169, 2.5232, 2.2638, 1.6099, 2.4778, 2.1455, 1.5525, 2.0125, 0.5969, 0.6574, 1.6729, 1.3867, 0.847, 0.471, 0.2383, 0.8855, 0.3412, 1.5464, 3.1342, 3.1342, 3.1342, 3.1341, 3.1337, 3.1333, 3.1332, 3.1332, 3.133, 3.1329, 3.1325, 3.1324, 3.1322, 3.1322, 3.1321, 3.1321, 3.1321, 3.1319, 3.1319, 3.1319, 3.1316, 3.1314, 3.1313, 3.1313, 3.1313, 3.1313, 3.1312, 3.1312, 3.1312, 3.1311, 3.1182, 3.1279, 3.1067, 3.0696, 3.111, 3.109, 3.0698, 2.9873, 3.0301, 3.0626, 2.8963, 2.9227, 2.9569, 2.7474, 2.793, 2.7965, 2.2704, 2.3603, 2.7087, 2.5763, 2.5019, 2.3251, 1.0725, 1.1112, 2.4705, 0.8678, 1.1942, 0.8778, 2.1558, 0.5546, 0.168, 1.2722, 0.2008, 0.7614, 0.1426, 0.2447, 0.0945, 0.7753, 0.3658, 1.8062, 0.7069, 0.3538, 3.1575, 3.1574, 3.1572, 3.157, 3.1569, 3.1569, 3.1569, 3.1568, 3.1568, 3.1568, 3.1567, 3.1567, 3.1566, 3.1566, 3.1566, 3.1566, 3.1564, 3.1563, 3.1562, 3.1562, 3.1559, 3.1559, 3.1558, 3.1557, 3.1556, 3.1556, 3.1555, 3.1554, 3.1553, 3.1553, 3.1377, 3.106, 3.1265, 3.1362, 2.9698, 3.0525, 2.9246, 3.0539, 3.008, 3.0587, 2.9303, 2.9869, 2.7966, 2.8731, 2.6799, 2.9472, 2.8278, 2.8087, 2.9204, 2.8949, 2.5286, 2.3633, 2.3512, 2.5385, 2.7175, 2.3464, 2.8104, 2.1385, 2.1073, 2.3819, 1.788, 0.769, 1.7291, 1.6204, 2.0905, 1.1111, 1.9445, 1.937, 0.6764, 1.6595, 1.888, 1.711, 0.3642, 0.0512, 0.4933, 0.2247, 0.8397, 3.2368, 3.2367, 3.2361, 3.2361, 3.236, 3.236, 3.2358, 3.2357, 3.2357, 3.2353, 3.2351, 3.235, 3.2349, 3.2349, 3.2347, 3.2347, 3.2347, 3.2345, 3.2344, 3.2344, 3.2343, 3.2342, 3.2341, 3.234, 3.234, 3.2339, 3.2337, 3.2336, 3.2333, 3.2332, 3.217, 3.2039, 3.1981, 3.1835, 3.1851, 3.2134, 3.2, 3.1255, 3.1182, 3.1018, 3.1737, 3.2024, 2.9198, 3.0047, 3.1212, 3.1414, 3.0512, 2.8431, 2.7361, 2.9769, 2.7666, 2.5063, 2.6268, 2.4788, 2.8621, 2.8263, 2.2, 2.0895, 2.4323, 1.988, 2.7672, 2.2316, 0.7077, 0.065, 1.7171, 0.7128, 2.1843, 1.9647, 0.6566, 0.1282, 0.1816, 0.5136, 3.269, 3.2689, 3.2687, 3.2687, 3.2686, 3.2685, 3.2678, 3.2678, 3.2676, 3.2673, 3.2671, 3.267, 3.2669, 3.2669, 3.2668, 3.2668, 3.2667, 3.2665, 3.2665, 3.2664, 3.2664, 3.2662, 3.2659, 3.2658, 3.2658, 3.2657, 3.2654, 3.2654, 3.2653, 3.2651, 3.2523, 3.2491, 3.031, 3.0943, 3.1606, 2.9129, 3.2399, 3.1561, 3.0243, 3.0239, 2.9659, 2.9361, 2.8405, 3.0732, 2.8242, 3.0353, 2.6419, 2.6968, 2.8715, 2.5521, 2.7302, 2.4006, 2.0994, 2.2032, 2.24, 1.2835, 1.9661, 0.9301, 2.067, 1.3676, 1.9882, 2.124, 0.9244, 1.2774, 0.7067, 1.0781, 0.7186, 1.3213, 0.1936, 3.4807, 3.4807, 3.4806, 3.4802, 3.4802, 3.48, 3.48, 3.48, 3.4798, 3.4798, 3.4797, 3.4795, 3.4791, 3.4791, 3.4791, 3.479, 3.4789, 3.4789, 3.4787, 3.4786, 3.4785, 3.4784, 3.4783, 3.4783, 3.4781, 3.478, 3.478, 3.478, 3.4779, 3.4777, 3.4648, 3.4736, 3.4698, 3.4752, 3.4607, 3.4576, 3.439, 3.4477, 3.3999, 3.4195, 3.1541, 3.3464, 3.3351, 3.3152, 2.9791, 3.01, 3.1824, 2.3844, 1.7312, 2.8428, 2.1228, 1.3671, 2.7386, 1.6996, 1.406, 2.2287, 2.041, 2.8357, 1.0489, 1.8521, 1.6119, 2.0386, 1.4928, 0.5972, 2.1446, 0.8256, -0.0775, 2.1882, 1.9351, 2.2884, 0.4625, -0.3161, 0.2171, 3.6191, 3.6187, 3.6186, 3.6184, 3.6182, 3.6181, 3.6179, 3.6179, 3.6173, 3.6171, 3.6171, 3.6171, 3.6171, 3.617, 3.6168, 3.6167, 3.6165, 3.6164, 3.6164, 3.6163, 3.6163, 3.6158, 3.6154, 3.6154, 3.6153, 3.6152, 3.6149, 3.6149, 3.6148, 3.6148, 3.6132, 3.6063, 3.5927, 3.5652, 3.5505, 3.5517, 3.5484, 3.5734, 3.5273, 3.4972, 3.2508, 3.1215, 3.5524, 3.2125, 3.06, 2.9461, 3.1586, 2.7384, 2.9657, 3.1832, 2.6795, 2.0891, 2.7228, 1.5432, 2.1289, 2.5694, 2.24, 2.6381, 2.2185, 1.4887, 1.0734, 0.9383, 2.07, 2.3585, 1.9776, 0.0691, 1.2343, 0.133, 3.6356, 3.6355, 3.6354, 3.6354, 3.6353, 3.6352, 3.6352, 3.6352, 3.635, 3.6349, 3.6348, 3.6347, 3.6347, 3.6343, 3.6343, 3.6341, 3.6341, 3.6341, 3.6341, 3.634, 3.634, 3.6338, 3.6338, 3.6338, 3.6337, 3.6335, 3.6334, 3.633, 3.633, 3.6329, 3.6165, 3.5783, 3.4901, 3.586, 3.5925, 3.5553, 3.1784, 3.2099, 3.2291, 3.316, 3.416, 3.2582, 3.4595, 3.1748, 3.1227, 3.2155, 2.8523, 2.3078, 3.2603, 3.1029, 3.1229, 2.2681, 3.139, 3.0574, 3.1121, 2.5336, 1.7765, 2.2447, 2.72, 2.4232, 1.7233, 0.3324, 2.2752, -0.1834, 1.1764, 0.5953, 1.214, 1.81, 0.4972, 0.3561, 1.1184, 3.7636, 3.7633, 3.7633, 3.7632, 3.7632, 3.7632, 3.7632, 3.7631, 3.763, 3.7628, 3.7628, 3.7627, 3.7627, 3.7627, 3.7626, 3.7624, 3.7624, 3.7622, 3.7622, 3.7621, 3.7621, 3.762, 3.762, 3.762, 3.7619, 3.7619, 3.7619, 3.7617, 3.7617, 3.7617, 3.7578, 3.7537, 3.7502, 3.7412, 3.6835, 3.6942, 3.617, 3.7367, 3.6861, 3.7028, 3.5935, 3.4699, 3.1276, 3.5543, 3.5191, 3.485, 3.4195, 3.4772, 3.4371, 3.424, 3.0807, 2.1581, 2.9341, 3.4517, 2.0511, 2.0804, 1.8402, 1.6457, 3.0412, 0.8096, 2.0229, 0.9356, 2.7695, 2.0558, 3.7779, 3.7776, 3.7775, 3.7769, 3.7769, 3.7767, 3.7766, 3.7762, 3.7761, 3.776, 3.7759, 3.7757, 3.7757, 3.7756, 3.7755, 3.7755, 3.7752, 3.7752, 3.7747, 3.7747, 3.7747, 3.7746, 3.7746, 3.7746, 3.7745, 3.7744, 3.7744, 3.7743, 3.7741, 3.774, 3.759, 3.7262, 3.6826, 3.7046, 3.6093, 3.5314, 3.6839, 3.5976, 3.5345, 3.458, 3.2854, 3.6557, 3.394, 3.6773, 3.1549, 3.2487, 2.9029, 3.1064, 3.335, 3.238, 2.7056, 2.8059, 2.9911, 2.8631, 2.0268, 3.2431, 2.5835, 1.511, 2.044, 1.9271, 2.1309, 0.8957, 1.992, 0.6383, 2.2475, 1.9832, 0.8058, 0.6926, 0.9996, 0.6023, 4.0163, 4.0162, 4.0159, 4.0159, 4.0157, 4.0156, 4.015, 4.0149, 4.0147, 4.0147, 4.0144, 4.0144, 4.0142, 4.0142, 4.0138, 4.0136, 4.0136, 4.0132, 4.0131, 4.0128, 4.0127, 4.0127, 4.0124, 4.0121, 4.0116, 4.0116, 4.0116, 4.0115, 4.0114, 4.0114, 3.9737, 3.9083, 3.9238, 3.8381, 3.9302, 3.9551, 3.8237, 3.8337, 3.7362, 3.6007, 3.7562, 3.7724, 3.4444, 3.5182, 3.2746, 3.8889, 3.0851, 3.4006, 3.6685, 2.8736, 3.2892, 3.2619, 2.8777, 2.3857, 3.2681, 3.1414, 1.6008, 2.1562, 1.3384, 1.4129, 2.4404, 0.8252, 0.6415, 0.9327, 1.3533, 0.5499, 0.4159, 0.0561, 2.132]}, \"token.table\": {\"Topic\": [3, 7, 4, 5, 20, 1, 2, 3, 4, 5, 7, 10, 11, 12, 13, 14, 17, 19, 20, 2, 13, 1, 3, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 9, 14, 15, 6, 12, 15, 16, 1, 2, 4, 5, 12, 15, 19, 6, 12, 14, 15, 16, 19, 9, 4, 6, 7, 15, 19, 11, 5, 9, 17, 2, 2, 9, 14, 9, 9, 17, 18, 2, 3, 4, 6, 8, 9, 10, 12, 13, 15, 16, 18, 12, 5, 6, 8, 9, 18, 19, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 17, 20, 5, 1, 7, 11, 13, 14, 16, 9, 17, 2, 11, 5, 19, 12, 15, 19, 2, 15, 20, 20, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 18, 19, 12, 3, 12, 14, 15, 16, 5, 2, 2, 3, 13, 14, 1, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 16, 17, 19, 20, 1, 2, 3, 4, 5, 6, 8, 9, 10, 1, 2, 3, 4, 6, 8, 9, 10, 6, 12, 13, 16, 20, 1, 3, 4, 5, 7, 8, 9, 11, 12, 13, 15, 17, 19, 20, 9, 13, 19, 20, 19, 8, 13, 17, 18, 3, 5, 11, 14, 1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12, 14, 15, 16, 17, 9, 15, 20, 9, 1, 5, 17, 2, 4, 5, 6, 8, 9, 12, 13, 14, 16, 12, 16, 8, 6, 15, 5, 7, 14, 17, 7, 10, 14, 12, 19, 11, 14, 19, 2, 16, 11, 12, 15, 5, 6, 6, 6, 5, 14, 8, 2, 9, 12, 8, 1, 2, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 4, 5, 6, 17, 6, 20, 1, 2, 3, 14, 16, 12, 14, 15, 16, 3, 9, 1, 4, 17, 17, 8, 10, 11, 12, 15, 16, 19, 20, 15, 3, 8, 2, 5, 6, 7, 15, 20, 16, 2, 3, 4, 5, 10, 11, 13, 14, 16, 20, 14, 4, 2, 3, 4, 2, 4, 8, 9, 5, 3, 6, 18, 12, 15, 19, 4, 2, 4, 9, 17, 18, 17, 17, 1, 17, 7, 15, 15, 13, 19, 13, 1, 2, 3, 5, 7, 11, 13, 16, 13, 14, 16, 14, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 16, 5, 14, 5, 7, 14, 3, 11, 19, 1, 20, 13, 12, 15, 16, 20, 1, 2, 4, 6, 7, 11, 12, 13, 19, 20, 12, 17, 14, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 13, 15, 16, 17, 19, 13, 15, 19, 20, 6, 7, 16, 17, 20, 2, 11, 16, 20, 8, 15, 20, 11, 1, 2, 3, 4, 7, 8, 11, 14, 2, 4, 7, 14, 7, 5, 7, 11, 14, 20, 8, 16, 17, 4, 14, 19, 18, 11, 5, 11, 11, 20, 8, 20, 19, 3, 4, 5, 6, 7, 10, 13, 15, 20, 6, 7, 10, 12, 13, 14, 15, 12, 14, 16, 5, 5, 5, 11, 12, 13, 14, 2, 4, 1, 3, 4, 5, 7, 8, 9, 10, 11, 12, 13, 14, 16, 20, 2, 3, 9, 10, 11, 15, 16, 17, 19, 20, 1, 3, 4, 5, 7, 10, 11, 14, 17, 20, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 12, 5, 8, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 16, 20, 1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12, 13, 14, 16, 19, 20, 10, 19, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 20, 4, 10, 11, 13, 14, 2, 2, 3, 2, 1, 2, 3, 4, 6, 8, 9, 10, 12, 14, 15, 16, 19, 2, 3, 4, 7, 18, 15, 20, 4, 6, 8, 11, 12, 15, 20, 2, 4, 6, 8, 11, 12, 15, 20, 6, 11, 12, 15, 20, 16, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 14, 15, 16, 17, 17, 1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 15, 17, 19, 20, 3, 4, 5, 8, 9, 10, 11, 12, 13, 15, 16, 17, 1, 2, 3, 4, 5, 7, 9, 10, 13, 14, 15, 16, 17, 9, 1, 2, 3, 6, 7, 8, 9, 15, 16, 17, 19, 8, 8, 9, 1, 2, 3, 4, 6, 8, 9, 10, 11, 12, 15, 16, 17, 19, 20, 1, 9, 19, 18, 2, 3, 4, 8, 9, 10, 2, 4, 10, 13, 1, 13, 15, 18, 20, 13, 4, 3, 1, 4, 5, 9, 10, 11, 13, 16, 20, 20, 2, 7, 1, 3, 6, 7, 10, 11, 12, 13, 14, 15, 19, 15, 3, 5, 10, 1, 4, 5, 6, 7, 9, 10, 11, 13, 17, 20, 5, 1, 3, 10, 1, 1, 5, 7, 18, 12, 12, 9, 1, 3, 5, 6, 7, 8, 12, 14, 15, 17, 20, 14, 13, 3, 4, 6, 9, 15, 16, 17, 18, 2, 12, 13, 3, 4, 5, 6, 7, 9, 11, 12, 13, 14, 15, 16, 17, 19, 20, 14, 19, 8, 11, 13, 20, 13, 14, 9, 16, 6, 9, 15, 18, 11, 1, 3, 4, 5, 7, 10, 11, 12, 14, 17, 19, 20, 1, 3, 4, 5, 7, 10, 11, 13, 14, 1, 4, 5, 7, 10, 11, 5, 14, 16, 17, 19, 5, 10, 12, 15, 18, 19, 14, 7, 15, 2, 5, 7, 9, 12, 17, 3, 7, 20, 2, 3, 4, 5, 9, 10, 11, 13, 10, 5, 6, 1, 2, 4, 5, 8, 9, 10, 11, 1, 13, 1, 2, 5, 6, 8, 10, 11, 12, 13, 14, 6, 9, 15, 17, 19, 20, 15, 15, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 18, 1, 2, 3, 15, 4, 10, 13, 14, 7, 11, 13, 14, 15, 17, 19, 19, 20, 7, 1, 3, 6, 8, 10, 12, 18, 1, 2, 14, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 17, 17, 3, 8, 15, 17, 5, 13, 19, 20, 1, 2, 5, 6, 7, 10, 12, 14, 16, 20, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 16, 20, 3, 9, 11, 12, 16, 11, 1, 2, 4, 6, 8, 9, 10, 12, 13, 3, 9, 9, 3, 7, 14, 7, 1, 2, 4, 5, 7, 8, 11, 12, 13, 14, 20, 1, 2, 3, 6, 10, 11, 12, 15, 16, 17, 20, 1, 2, 3, 5, 7, 9, 12, 14, 15, 19, 13, 6, 5, 1, 2, 3, 4, 5, 7, 8, 9, 11, 13, 14, 18, 19, 11, 11, 18, 20, 14, 4, 10, 18, 4, 16, 9, 8, 3, 6, 8, 9, 13, 15, 16, 17, 19, 12, 13, 11, 12, 13, 19, 16, 1, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 16, 17, 19, 20, 14, 1, 8, 10, 8, 10, 11, 13, 3, 3, 7, 10, 11, 18, 1, 5, 7, 8, 11, 16, 4, 8, 1, 2, 3, 4, 5, 7, 9, 16, 17, 6, 20, 6, 3, 6, 8, 12, 13, 19, 20, 5, 7, 16, 1, 3, 6, 7, 8, 10, 15, 1, 2, 3, 4, 5, 10, 11, 16, 17, 9, 12, 13, 16, 19, 20, 11, 9, 16, 1, 3, 4, 6, 8, 10, 15, 18, 1, 2, 3, 4, 6, 8, 9, 10, 15, 17, 18, 19, 8, 9, 15, 17, 4, 1, 2, 4, 6, 7, 9, 10, 17, 19, 8, 1, 2, 3, 7, 9, 10, 12, 13, 17, 19, 1, 2, 3, 10, 13, 19, 1, 2, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1, 3, 4, 5, 6, 7, 9, 13, 2, 15, 16, 17, 19, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 2, 3, 12, 15, 15, 6, 11, 14, 1, 2, 4, 6, 8, 9, 10, 11, 12, 3, 1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 3, 6, 7, 9, 17, 3, 5, 6, 9, 11, 12, 16, 2, 3, 4, 1, 12, 13, 12, 2, 18, 4, 13, 14, 14, 14, 1, 2, 3, 4, 5, 6, 9, 10, 11, 12, 13, 14, 15, 17, 18, 19, 20, 3, 10, 1, 4, 5, 7, 17, 17, 1, 8, 18, 13, 11, 1, 4, 7, 10, 12, 13, 14, 15, 20, 6, 5, 6, 9, 12, 15, 19, 20, 6, 12, 19, 3, 6, 8, 12, 13, 19, 20, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 19, 20, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 3, 6, 12, 13, 15, 19, 1, 3, 13, 15, 19, 6, 19, 13, 19, 13, 15, 16, 15, 12, 12, 1, 5, 20, 20, 18, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 7, 1, 5, 6, 8, 9, 11, 13, 16, 19, 6, 17, 1, 2, 3, 5, 8, 18, 7, 13, 16, 19, 4, 3, 1, 2, 5, 10, 12, 13, 15, 16, 19, 19, 11, 10, 16, 3, 6, 11, 1, 2, 3, 4, 5, 6, 8, 9, 11, 12, 15, 20, 9, 16, 18, 2, 5, 9, 1, 3, 15, 14, 15, 14, 1, 3, 10, 12, 15, 12, 13, 18, 18, 4, 11, 3, 7, 13, 14, 6, 3, 8, 13, 14, 16, 18, 19, 20, 14, 7, 1, 3, 6, 14, 3, 3, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 17, 1, 1, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 16, 20, 12, 14, 2, 5, 1, 1, 1, 3, 4, 6, 9, 10, 13, 4, 6, 10, 20, 16, 16, 11, 3, 11, 11, 5, 10, 11, 14, 1, 3, 5, 7, 8, 10, 11, 12, 14, 15, 16, 10, 18, 2, 4, 5, 8, 9, 10, 11, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 13, 14, 15, 16, 19, 14, 7, 10, 2, 20, 5, 5, 12, 17, 12, 13, 16, 12, 15, 4, 3, 6, 16, 3, 9, 11, 13, 14, 16, 8, 2, 4, 15, 15, 16, 4, 18, 3, 7, 3, 16, 3, 16, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, 17, 5, 17, 9, 17, 18, 11, 19, 4, 9, 17, 18, 9, 12, 13, 14, 16, 19, 18, 18, 8, 2, 5, 7, 12, 14, 16, 6, 10, 13, 14, 6, 9, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 16, 18, 19, 20, 3, 8, 10, 11, 18, 20, 13, 6, 10, 13, 14, 14, 9, 3, 1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 19, 20, 8, 20, 14, 10, 1, 2, 3, 4, 5, 6, 8, 10, 11, 12, 13, 15, 16, 17, 18, 20, 1, 3, 4, 5, 6, 7, 10, 11, 12, 14, 15, 16, 17, 19, 3, 5, 12, 16, 18, 2, 4, 8, 2, 4, 16, 3, 5, 11, 13, 14, 16, 1, 3, 6, 7, 9, 11, 12, 14, 15, 16, 17, 17, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 12, 15, 13, 1, 2, 4, 5, 6, 7, 11, 12, 13, 15, 16, 20, 2, 3, 4, 5, 7, 8, 9, 11, 14, 15, 3, 12, 13, 15, 19, 19, 15, 11, 20, 2, 3, 11, 18, 14, 3, 16, 1, 12, 5, 16, 17, 3, 4, 8, 10, 3, 4, 5, 6, 8, 9, 10, 11, 13, 20, 10, 1, 4, 6, 2, 3, 7, 20, 14, 18, 1, 4, 18, 14, 1, 4, 18, 1, 2, 4, 10, 18, 4, 5, 7, 11, 5, 7, 11, 13, 14, 19, 4, 10, 5, 7, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 4, 10, 1, 3, 5, 3, 12, 8, 11, 12, 6, 12, 13, 6, 13, 18, 6, 2, 3, 5, 11, 1, 2, 3, 4, 5, 6, 7, 9, 13, 14, 16, 17, 1, 3, 5, 6, 7, 9, 13, 14, 16, 1, 2, 3, 4, 5, 6, 7, 9, 14, 15, 16, 1, 2, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 20, 2, 4, 7, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 15, 16, 19, 20, 12, 1, 2, 3, 4, 5, 8, 9, 10, 11, 18, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 5, 18, 12, 3, 4, 13, 1, 3, 1, 2, 3, 6, 8, 9, 12, 15, 17, 20, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 13, 15, 19, 20, 1, 2, 3, 4, 5, 6, 9, 11, 12, 15, 16, 17, 2, 5, 7, 16, 20, 2, 3, 4, 15, 18, 2, 4, 1, 3, 4, 6, 8, 9, 11, 12, 13, 20, 1, 3, 5, 9, 12, 13, 16, 17, 19, 1, 2, 3, 4, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 16, 17, 19, 20, 8, 18, 2, 4, 6, 7, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 5, 6, 16, 6, 2, 8, 10, 1, 2, 3, 4, 5, 6, 7, 9, 14, 16, 20, 19, 7, 1, 1, 3, 4, 5, 6, 7, 8, 11, 12, 13, 16, 20, 20, 1, 2, 3, 3, 3, 17, 3, 9, 11, 2, 10, 12, 13, 10, 4, 1, 3, 4, 8, 10, 11, 2, 2, 3, 4, 5, 8, 9, 10, 11, 13, 3, 3, 9, 18, 3, 9, 9, 9, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 1, 3, 10, 12, 13, 19, 3, 5, 6, 12, 14, 15, 16, 17, 19, 15, 15, 4, 5, 9, 10, 15, 16, 20, 3, 1, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 19, 1, 2, 4, 5, 7, 11, 14, 1, 2, 3, 4, 5, 8, 9, 10, 11, 18, 19, 16, 6, 6, 2, 1, 2, 4, 10, 1, 2, 4, 6, 8, 10, 11, 19, 20, 5, 4, 1, 3, 7, 10, 11, 2, 3, 10, 18, 3, 10, 18, 14, 4, 7, 7, 1, 2, 3, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 1, 3, 5, 7, 9, 10, 12, 13, 14, 15, 16, 17, 19, 6, 13, 16, 20, 11, 18, 6, 1, 2, 4, 5, 8, 15, 1, 3, 9, 16, 12, 13, 19, 12, 15, 19, 19, 9, 12, 19, 12, 14, 10, 1, 6, 13, 6, 1, 4, 5, 6, 7, 9, 10, 11, 13, 14, 15, 17, 18, 20, 9, 4, 6, 1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 1, 3, 10, 19, 10, 16, 16, 16, 9, 3, 1, 2, 3, 4, 5, 6, 10, 13, 14, 18, 5, 8, 11, 12, 13, 4, 2, 5, 6, 7, 20, 6, 11, 15, 20, 1, 2, 3, 4, 6, 7, 8, 9, 10, 12, 15, 16, 19, 20, 6, 15, 20, 12, 15, 17, 19, 10, 7, 10, 6, 11, 20, 1, 2, 3, 6, 7, 10, 12, 13, 15, 19, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 1, 8, 1, 4, 6, 8, 10, 15, 19, 3, 2, 4, 10, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 11, 1, 1, 13, 14, 1, 3, 4, 5, 6, 7, 9, 10, 11, 14, 17, 1, 2, 3, 4, 9, 10, 12, 15, 16, 17, 12, 14, 13, 2, 12, 15, 9, 17, 15, 8, 14, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 2, 4, 9, 17, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 16, 17, 18, 20, 1, 2, 8, 9, 10, 13, 18, 9, 12, 13, 1, 2, 4, 6, 8, 9, 10, 11, 12, 15, 17, 2, 5, 1, 3, 4, 9, 10, 11, 4, 5, 7, 9, 14, 17, 2, 5, 12, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 12, 13, 1, 8, 10, 12, 13, 8, 9, 15, 19, 15, 8, 15, 19, 2, 3, 5, 9, 12, 16, 17, 1, 10, 13, 1, 2, 4, 5, 6, 7, 10, 12, 13, 15, 16, 19, 20, 12, 20, 2, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 17, 3, 4, 5, 6, 8, 9, 12, 16, 20, 1, 2, 3, 4, 5, 6, 7, 9, 10, 12, 13, 14, 15, 17, 19, 20, 3, 11, 12, 16, 9, 14, 3, 2, 3, 11, 1, 11, 17, 13, 12, 13, 3, 4, 6, 8, 9, 11, 16, 19, 20, 12, 7, 14, 17, 19, 1, 6, 7, 8, 10, 11, 12, 13, 14, 15, 16, 20, 9, 19, 1, 10, 1, 2, 18, 11, 18, 5, 5, 13, 14, 16, 17, 19, 9, 12, 13, 14, 12, 13, 14, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 17, 19, 20, 1, 6, 8, 15, 19, 1, 7, 8, 11, 11, 18, 18, 7, 7, 7, 16, 19, 1, 3, 8, 9, 13, 16, 19, 20, 15, 19, 13, 13, 9, 16, 18, 19, 9, 15, 8, 1, 2, 3, 4, 5, 7, 8, 9, 11, 12, 13, 17, 19, 20, 5, 11, 9, 1, 2, 4, 6, 8, 11, 2, 4, 9, 12, 13, 14, 1, 2, 3, 5, 11, 12, 15, 17, 1, 9, 10, 13, 14, 1, 5, 6, 8, 9, 12, 13, 16, 17, 19, 3, 12, 15, 10, 5, 1, 2, 3, 4, 6, 7, 12, 14, 15, 16, 17, 5, 9, 12, 15, 4, 17, 4, 4, 1, 10, 14, 19, 1, 2, 3, 7, 9, 12, 13, 14, 17, 17, 3, 12, 1, 2, 3, 5, 11, 14, 16, 2, 3, 5, 7, 9, 11, 15, 16, 17, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 16, 17, 20, 1, 2, 3, 5, 6, 9, 12, 13, 14, 15, 16, 17, 19, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 18, 19, 20, 20, 4, 4, 5, 8, 9, 10, 12, 16, 19, 20, 1, 4, 8, 10, 12, 13, 2, 4, 8, 2, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 14, 15, 16, 1, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 18, 19, 20, 4, 11, 2, 2, 4, 8, 9, 10, 5, 12, 14, 20, 5, 7, 9, 11, 18, 4, 12, 2, 3, 4, 9, 17, 18, 18, 10, 1, 18, 13, 15, 12, 18, 1, 7, 13, 20, 13, 20, 19, 5, 5, 1, 2, 5, 8, 12, 14, 15, 16, 17, 16, 2, 2, 2, 19, 1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 5, 10, 5, 5, 1, 2, 3, 4, 6, 7, 14, 15, 17, 19, 20, 14, 6, 7, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 17, 19, 20, 6, 12, 12, 15, 6, 7, 13, 14, 7, 5, 17, 1, 3, 10, 13, 15, 16, 12, 15, 19, 1, 2, 3, 4, 5, 10, 11, 13, 16, 10, 13, 15, 19, 6, 15, 16, 20, 8, 1, 7, 8, 9, 11, 12, 13, 1, 2, 4, 1, 2, 9, 1, 4, 7, 1, 2, 4, 1, 7, 1, 9, 5, 1, 2, 4, 8, 10, 1, 3, 6, 9, 10, 11, 12, 13, 14, 16, 1, 1, 6, 9, 11, 12, 13, 15, 18, 19, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 1, 5, 9, 12, 14, 15, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 12, 12, 5, 8, 14, 17, 8, 9, 13, 1, 1, 4, 1, 1, 3, 2, 4, 17, 1, 2, 2, 8, 9, 18, 20, 13, 1, 2, 4, 8, 10, 18, 11, 6, 16, 6, 3, 5, 9, 13, 17, 20, 9, 13, 19, 7, 12, 9, 1, 10, 12, 13, 4, 5, 9, 17, 9, 17, 1, 3, 4, 5, 7, 9, 10, 11, 12, 13, 14, 16, 20, 19, 2, 3, 4, 5, 6, 7, 9, 10, 15, 16, 18, 6, 16, 5, 12, 8, 4, 1, 2, 3, 5, 7, 9, 10, 13, 14, 3, 1, 2, 3, 5, 9, 10, 16, 2, 4, 8, 10, 10, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 17, 20, 12, 13, 14, 10, 16, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12, 13, 15, 17, 18, 19, 20, 1, 3, 5, 7, 11, 14, 1, 2, 3, 5, 4, 4, 1, 4, 5, 8, 9, 11, 12, 13, 1, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 17, 7, 11, 13, 16, 17, 5, 14, 16, 7, 11, 3, 5, 9, 19, 9, 13, 17, 19, 20, 12, 15, 16, 2, 3, 4, 9, 13, 16, 17, 1, 2, 3, 6, 11, 15, 16, 17, 19, 17, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 1, 2, 3, 4, 5, 7, 9, 10, 11, 13, 14, 17, 20, 18, 14, 4, 6, 4, 6, 12, 1, 3, 6, 12, 13, 14, 15, 12, 3, 7, 11, 14, 15, 16, 17, 20, 1, 14, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 12, 10, 14, 14, 3, 6, 7, 6, 10, 12, 15, 19, 20, 20, 1, 5, 11, 14, 1, 2, 3, 6, 8, 9, 10, 12, 15, 17, 19, 20, 1, 10, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 20, 9, 20, 8, 1, 2, 4, 8, 12, 13, 19, 7, 2, 11, 6, 7, 9, 14, 1, 1, 3, 4, 6, 8, 9, 10, 11, 20, 15, 15, 7, 12, 19, 2, 3, 5, 7, 10, 14, 16, 19, 5, 18, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 16, 13, 1, 3, 4, 5, 10, 13, 15, 4, 10, 1, 12, 13, 19, 7, 1, 8, 10, 11, 19, 19, 19, 7, 16, 19, 5, 10, 1, 15, 15, 15, 3, 1, 1, 2, 4, 6, 10, 17, 18, 8, 2, 3, 4, 6, 7, 9, 10, 13, 15, 16, 17, 18, 1, 2, 6, 8, 10, 15, 1, 3, 6, 8, 9, 10, 12, 15, 19, 3, 4, 6, 7, 8, 9, 10, 13, 15, 16, 19, 20, 1, 2, 3, 5, 10, 11, 12, 13, 15, 17, 3, 8, 20, 18, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 13, 15, 16, 17, 18, 19, 20, 13, 12, 15, 2, 2, 3, 4, 6, 9, 15, 17, 20, 1, 4, 5, 15, 17, 20, 5, 9, 14, 16, 20, 1, 2, 4, 5, 6, 7, 9, 11, 12, 13, 14, 17, 20, 17, 5, 16, 4, 1, 2, 3, 5, 6, 9, 10, 11, 12, 13, 14, 15, 16, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 14, 15, 16, 17, 19, 10, 4, 11, 12, 14, 19, 8, 2, 4, 4, 1, 10, 16, 2, 13, 1, 4, 5, 6, 7, 9, 14, 7, 16, 8, 13, 19, 8, 15, 2, 12, 18, 9, 10, 4, 7, 4, 16, 2, 3, 10, 16, 5, 16, 1, 2, 3, 5, 8, 10, 11, 2, 3, 5, 6, 8, 12, 15, 20, 15, 15, 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 19, 20, 2, 3, 9, 15, 18, 1, 3, 4, 5, 6, 7, 9, 10, 11, 13, 14, 16, 17, 18, 20, 7, 10, 1, 1, 2, 5, 6, 7, 9, 12, 14, 19, 1, 3, 4, 5, 6, 7, 9, 12, 14, 16, 19, 5, 16, 5, 6, 6, 9, 12, 13, 15, 16, 17, 19, 10, 6, 10, 1, 3, 5, 6, 7, 11, 12, 14, 16, 17, 20, 1, 2, 5, 7, 12, 13, 14, 17, 20, 3, 5, 7, 14, 15, 16, 13, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 14, 15, 16, 17, 18, 19, 20, 2, 4, 8, 10, 1, 2, 3, 4, 5, 6, 8, 9, 10, 12, 15, 16, 17, 19, 6, 2, 18, 9, 4, 2, 5, 6, 7, 8, 11, 12, 13, 14, 15, 17, 20, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 15, 16, 17, 19, 20, 7, 18, 7, 16, 1, 3, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 3, 5, 6, 11, 20, 9, 1, 12, 18, 8, 17, 6, 7, 13, 14, 6, 7, 13, 14, 16, 1, 4, 6, 7, 13, 14, 6, 8, 9, 15, 19, 7, 16, 4, 2, 6, 14, 15, 19, 20, 1, 6, 7, 8, 10, 13, 14, 19, 20, 3, 8, 9, 10, 15, 16, 1, 2, 6, 13, 16, 13, 11, 5, 11, 11, 13, 1, 2, 3, 4, 5, 9, 10, 12, 14, 15, 17, 19, 12, 7, 5, 11, 15, 9, 8, 8, 20, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 5, 8, 17, 1, 2, 6, 10, 12, 15, 17, 7, 3, 4, 6, 9, 10, 17, 20, 2, 3, 4, 6, 8, 9, 11, 12, 13, 14, 15, 17, 20, 1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12, 13, 14, 15, 16, 17, 19, 20, 5, 17, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 4, 9, 17, 18, 19, 1, 3, 5, 9, 17, 7, 6, 6, 1, 4, 5, 7, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 14, 15, 17, 20, 5, 1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 15, 17, 18, 20, 1, 2, 3, 6, 9, 10, 15, 3, 18, 2, 10, 1, 2, 4, 5, 6, 7, 8, 9, 10, 13, 14, 16, 20, 11, 13, 2, 3, 4, 6, 8, 9, 10, 11, 12, 13, 17, 18, 20, 13, 17, 1, 2, 3, 4, 5, 8, 9, 12, 13, 14, 15, 20, 8, 12, 13, 14, 20, 12, 13, 14, 19, 20, 7, 17, 15, 20, 7, 17, 18, 6, 4, 9, 17, 18, 20, 1, 7, 15, 19, 5, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 14, 15, 17, 20, 3, 6, 10, 5, 3, 5, 7, 16, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 2, 14, 20, 14, 20, 1, 2, 3, 4, 8, 11, 8, 1, 3, 4, 8, 11, 1, 2, 3, 4, 8, 10, 18, 1, 4, 9, 18, 18, 2, 3, 4, 9, 17, 3, 4, 5, 7, 18, 1, 2, 3, 4, 7, 8, 1, 6, 7, 3, 4, 9, 17, 18, 3, 4, 9, 17, 18], \"Freq\": [0.9982671288504965, 0.9984356542531587, 0.9779048293850371, 0.006955226382539382, 0.014605975403332703, 0.03529610282463462, 6.192298741163968e-05, 0.04037378779238907, 0.07263566423385336, 0.1657059143135478, 0.5215773229682411, 0.030404186819115085, 0.005325376917401013, 0.012879981381621055, 0.016904975563377635, 0.06025106675152542, 0.026441115624770146, 0.0047680700306962556, 0.007554604464220042, 0.9968065392174856, 0.9970503080807234, 0.03454953619355099, 0.1127592739467606, 0.07241204161114112, 0.0111221109664171, 0.0022480862591694136, 0.0024847269180293522, 0.04460676419509837, 0.19534686388887906, 0.03880906805302988, 0.318163365837187, 0.03514113784070084, 0.00840074338952781, 0.06223649328016377, 0.034076254875831116, 0.02756863675718281, 0.9509115020323022, 0.002376060262638377, 0.046668260543102476, 0.7404648535920154, 0.21500336992381627, 0.034989841786317, 0.009514781538384446, 0.0009004692986919199, 0.06648464988675341, 0.04217197882207158, 0.6664973592484694, 0.07638981217236454, 0.1446754006565018, 0.00270140789607576, 0.008224145858120252, 0.235168930297388, 0.013221095240269267, 0.7212263608235078, 0.004996949382149014, 0.01707291038900913, 0.9986903545594783, 0.0077032911043765665, 0.02723663640476, 0.1879052794388998, 0.05144697987565778, 0.7254849515086074, 0.9986391801644189, 0.04015036307177664, 0.09551560057075285, 0.8640780768447089, 0.9968097463901346, 0.9048606129850062, 0.09385912355111896, 0.9959870083631864, 0.9999199477927931, 0.08826113528693139, 0.17892939244532455, 0.7317650489243765, 0.03383211876775557, 0.08496853434787137, 0.08319373467480878, 0.056793589538002794, 0.3732625562409754, 0.15596052127037485, 0.08785258381659808, 0.02018834628108693, 0.0017747996730625873, 0.02207407093371593, 0.01697152187366099, 0.06311631337328827, 0.9975706196748669, 0.006953883354709016, 0.06212135796873387, 0.15252184157995108, 0.00602669890741448, 0.7454562956248064, 0.026424756747894258, 0.00012691910367490652, 0.19963528880704964, 0.054541369485896496, 0.34911214784177624, 0.09505394737892667, 0.0016499483477737849, 0.00022845438661483176, 0.08193051205894132, 0.08226050172849608, 0.12723217079730462, 1.6922547156654205e-05, 0.002969907025992813, 0.005237528344984476, 0.9968724998981751, 0.107475960899471, 0.012712210428969688, 0.01040089944188429, 0.21957454377311278, 0.002889138733856747, 0.64658924863714, 0.0557026913079468, 0.9439616794864555, 0.9982792808329627, 0.9989417580090327, 0.9969053831063722, 0.9986978798276852, 0.029688557053723957, 0.3846604348699887, 0.585380896689731, 0.05738923602313325, 0.11762421928708301, 0.8243181174231866, 0.9991620130453807, 0.15346323635114073, 0.255163079488603, 0.03736278139921564, 0.05366198133847078, 0.011570640835998706, 7.16448348978248e-05, 0.01805449839425185, 0.04040768688237319, 0.21389565458745594, 0.01432896697956496, 0.05907116637325655, 0.03976288336829276, 0.019344105422412695, 0.01447225664936061, 0.038401631505234096, 0.0004656914268358612, 0.030520699666473364, 0.9976784529129292, 0.9987575259167815, 0.788338965279972, 0.15147699416407148, 0.05532203265122611, 0.003951573760801865, 0.9989207402111431, 0.9979570845251727, 0.02735366346044684, 0.01886459548996334, 0.9385136256256761, 0.014148446617472504, 0.1916582707273379, 0.15069531564795138, 0.08808931775173626, 0.1455275354353899, 0.011426009460801096, 0.10105617911077816, 0.0655928800374204, 0.03292681979471519, 0.04750564929345518, 0.07576250256580976, 0.036933034730141305, 0.0033661687623106964, 0.015005526947483598, 0.004859609832913329, 0.023634297577632146, 0.005973764282410532, 0.15289913690245702, 0.06749865928515376, 0.42465460863311955, 0.15172524717575867, 0.07300126737905217, 0.002421147561315298, 0.023844635073559755, 0.07483547007701831, 0.029053770735783576, 0.29322388862627025, 0.17708361758125638, 0.2081221147908629, 0.1052337965847113, 0.002228204459631703, 0.08725179568242036, 0.042179519507765044, 0.08467176946600471, 0.901710744140827, 0.021343878411874934, 0.02515852902165684, 0.004268775682374987, 0.04741065757871794, 0.057206700166008546, 0.012543661830420478, 0.010833162489908595, 0.06347853108121879, 0.07279124971289459, 0.03135915457605119, 0.011023217972187693, 0.021476269497538093, 0.5380470703321268, 0.06632936331540526, 0.020335936603863503, 0.0205259920861426, 0.014634272135490558, 0.059487365953357726, 0.9937918824497853, 0.0020517750116939974, 0.0039569946654098515, 0.9966214529207539, 0.9965174327426399, 0.16479435394464348, 0.2507300599893962, 0.05515611982741646, 0.5292066812769021, 0.2680503442645173, 0.1345360685952787, 0.5725446362244645, 0.024863627866975557, 0.11116239882655542, 0.6051978369235557, 0.0875020368682493, 0.027377575931805582, 0.013924801551521804, 0.015753906840069158, 0.004543261523166012, 0.029855718580805223, 0.06814892284749019, 0.0013570781173093283, 0.018586069867497324, 0.0024191392525948897, 0.006018346433284847, 0.0008850509460713011, 0.0073754245505941755, 0.07911996332266491, 0.008943995853866467, 0.9109115777322464, 0.9965807928396976, 0.004692709174872125, 0.07156381491679992, 0.9221173528623726, 0.034086363962303225, 0.016749334015959346, 0.009696982851344883, 0.03349866803191869, 0.0026446316867304227, 0.003673099564903365, 0.15853097722122925, 0.06949504376797166, 0.09990830816537154, 0.5715342922989636, 0.9990499235859013, 0.9951908286282741, 0.9949082402888918, 0.022459368077704836, 0.9766616632647646, 0.17387263397080419, 0.08755288660941203, 0.7383421247519077, 0.9989622974953524, 0.9063853531716868, 0.055575467585777895, 0.03738713273952331, 0.6435801125030846, 0.35621038565158286, 0.9977197861613323, 0.9994112341555963, 0.9961565104341785, 0.08754155645243554, 0.911713283053414, 0.9981718258047722, 0.13463195513110582, 0.8647514041113334, 0.9991234179925996, 0.9992289973673761, 0.9982476054749821, 0.9996400729247957, 0.9732373165779001, 0.026107707449183608, 0.9954984700744384, 0.9967697124122763, 0.9998366131861176, 0.9975788886922663, 0.9984335025587543, 0.17167626003160438, 0.054270951779148896, 0.06863337980449868, 0.06290233017241242, 0.13568898076291694, 0.1152242610240502, 0.08714907861585432, 0.03181080585259219, 0.06276311439187592, 0.011508504524351369, 0.06566344315305317, 0.05673043056862721, 0.01682190681482811, 0.014060793834187358, 0.01113726244292068, 0.0008816999433978872, 0.027147077204619157, 0.005916670672801611, 0.734042116126879, 0.06018256502049335, 0.1764737983524005, 0.02925798545611677, 0.998915286323642, 0.9932927226727911, 0.0046825369000363555, 0.0024167932387284415, 0.9901299799915584, 0.0027188923935694965, 0.9959986721726127, 0.9048318897104943, 0.012811778969352133, 0.06566036721792967, 0.016815459897274673, 0.9985713107072924, 0.9986087674433343, 0.001965806751437038, 0.9966640229785784, 0.9982095019801341, 0.9977934568394269, 0.9978896383877659, 0.006169431368652284, 0.13282422828980797, 0.28161639659259835, 0.524401666335444, 0.01052432409946566, 0.03556495730164257, 0.008709785461626754, 0.9984316931896648, 0.04674994538011345, 0.9521405542416439, 0.037209975037812926, 0.1860498751890646, 0.016225279812999822, 0.0012980223850399856, 0.003894067155119957, 0.7552326910290983, 0.9956997041101078, 0.00046438448832517086, 0.038660008653070475, 0.029604511130729642, 0.008242824667771783, 0.33876848423321215, 0.168571569262037, 0.0040633642728452445, 0.05990559899394704, 0.03297129867108713, 0.3187999512352298, 0.9971951439615018, 0.9981155344172544, 0.918401551347589, 0.04755245550163814, 0.0340266594582274, 0.8922950376019413, 0.07408240671732874, 0.003918408289181024, 0.029510512427894587, 0.9995409131402038, 0.4372883783905839, 0.07677582216017885, 0.485452092913429, 0.7960342452089825, 0.08438889218763615, 0.11955093059915121, 0.9988091490002198, 0.06345310468438535, 0.17864489472680797, 0.09664395944237153, 0.6081736033595703, 0.052714886968566285, 0.9965900120003871, 0.9994884736091568, 0.9984126330743134, 0.9970992477504877, 0.9985452053398853, 0.9987418640604062, 0.9988720228232295, 0.0010778059348875834, 0.9980482957059021, 0.9989268612215708, 0.021617412355143882, 0.027536465738099945, 0.0054043530887859705, 0.6251035072695772, 0.08878580074434095, 0.12661627236584275, 0.07025659015421762, 0.03499962000356628, 0.9987908352326136, 0.8221240899558437, 0.17725797451730874, 0.9991046651756127, 0.10401944433367845, 0.3298514516542444, 0.08428702119510603, 0.09354720011271618, 0.03434993069699892, 0.05350056248996232, 0.023611032109299185, 0.16648929006844643, 0.03296817625117751, 0.02651998883734426, 0.013114546582269876, 0.014787196700895794, 0.0006060326516760571, 0.009090489775140856, 0.0069087722291070516, 0.002981680646246201, 0.003321058931184793, 4.848261213408457e-05, 0.9955336093978286, 0.026072910913964235, 0.9699122859994697, 0.01965141724005593, 0.14066277603408456, 0.8396326587093371, 0.09220407175284769, 0.8633155051620798, 0.04418111771490618, 0.998329826715821, 0.9984446202239392, 0.9975817296910802, 0.7914560826128131, 0.19618990927781355, 0.0031090639828666106, 0.009167752769991287, 0.19544210730261766, 0.04492066212288736, 0.0032263458983289263, 0.02705166945521946, 0.02940938376553675, 0.2650567245704072, 0.2806920931546166, 0.07643957974502379, 0.005211789528069804, 0.07259278271240084, 0.9962998321931202, 0.9983001135155454, 0.9978377975613285, 0.11508680509586261, 0.005553273457204685, 0.027670621191933687, 0.025372714933780027, 0.004883050798576533, 0.1062781644396069, 0.04662834782170141, 0.049022000173944806, 0.023936523522433986, 0.09699079331290252, 0.0463411095394322, 0.11020375429728607, 0.01369169145483224, 0.16104493025893585, 0.16745991856294817, 0.24116869931375778, 0.10423974112518819, 0.5886345030643851, 0.06606422189732322, 0.2667691117957115, 0.10207447696932244, 0.6309071395657058, 0.11874625437746959, 0.8795273417449867, 0.9962063867466133, 0.8371553227852446, 0.1616672747612143, 0.9996860494174745, 0.9949433154559997, 0.39232006708322675, 0.607403147338773, 0.9983249897877045, 0.00025844648203004095, 0.262249337408483, 0.014657607623703751, 0.002178334634253202, 0.6085676233287378, 0.04105606971677222, 0.006830371310793939, 0.06420549032146303, 0.002094443088953268, 0.03381029557881704, 0.9534204147070842, 0.010621818522548718, 0.9999029260420463, 0.001812395219288962, 0.7929229084389209, 0.048934670920801976, 0.13683583905631663, 0.019936347412178583, 0.9977240276756003, 0.99717291003704, 0.997677627990955, 0.013165236015161818, 0.07635836888793855, 0.9097178086476817, 0.9980659780873306, 0.99864202888953, 0.9993714026168202, 0.9999651205174532, 0.999922711299775, 0.9985560675059244, 0.9997662152866978, 0.9995192950239313, 0.9977477514028166, 0.023876740051456166, 0.00014383578344250703, 0.30133596631205223, 0.06573295303322571, 0.09061654356877942, 0.055664448192250214, 0.13650015848693917, 0.11923986447383832, 0.2066920208068826, 0.045143478344838686, 0.031163562470307996, 0.3372654704730529, 0.05067719504517375, 0.03320230020201039, 0.026212342264745045, 0.4758996362288156, 0.8424164100790321, 0.056633035971699636, 0.10087759532458998, 0.9991685876197682, 0.9981198187035535, 0.019501465607349246, 0.10171352650107646, 0.10094876314392551, 0.6634322123284498, 0.11433212189406715, 0.95559471208617, 0.044104371327054, 0.00032617863735553716, 0.015221669743258401, 0.00913300184595504, 0.0496878790904935, 0.0254419337137319, 0.0006523572747110743, 0.003153060161103526, 0.7492323300056689, 0.0015221669743258402, 0.04653481892938997, 0.027290279325413277, 0.02239759976508022, 0.017939825054554544, 0.03163932782348711, 0.041021132857583374, 0.019559745468516576, 0.0035316207095932705, 0.022819703046602673, 0.010866525260286987, 0.0019016419205502226, 0.011953177786315685, 0.031784586386339436, 0.020103071731530926, 0.8364507819105907, 0.04421446208956591, 0.03835824194525255, 0.012590873310273738, 0.0775949169121521, 0.0026352990649410146, 0.009369952230901386, 0.7882472314245791, 0.0040993541010193564, 0.023132069570037796, 0.992795088902496, 0.15032000044174443, 0.011848752975996326, 0.044653882484165255, 0.09054569438373311, 0.36218277753493244, 0.04350437659843427, 0.08196861200558651, 0.017949976523337716, 0.0596858825283397, 0.01618150592990543, 0.033954635393899917, 0.03758000011043611, 0.027588141257543684, 0.012202447094682782, 0.0032716705978497315, 0.005924376487998163, 0.0005305411780296862, 0.9975080261602622, 0.22514414307163888, 0.7743206995105636, 0.04499509253869646, 0.54740018997612, 0.033866627138083034, 0.11441265509171213, 0.07573371859120166, 0.03362601166996166, 0.0012632312076372003, 0.004812309362427429, 0.06093586730173732, 0.06785356201022676, 0.003729539755881258, 0.011369080868734801, 0.07253804676802193, 0.008558247192421237, 0.28449270102548657, 0.006832794129433084, 0.03540629685251689, 0.013734606381385694, 0.022706962308924085, 0.006970830374472136, 0.24128735632826323, 0.04141087351171566, 0.14549020227116102, 0.03713174991550504, 0.026502959047498022, 0.00904137405005792, 0.036372550567790256, 0.011595044583280385, 0.9974963377830477, 0.9940162406882224, 0.16046993634550552, 0.01517358715444125, 0.12471948465967565, 0.08053103816601015, 0.03589848668245857, 0.1434459117332056, 0.019244549561730367, 0.022723371982504702, 0.04640897144309592, 0.04433648149029419, 0.022353284490932965, 0.01273100971006778, 0.07616400576546364, 0.19570226554313497, 0.040300782048848446, 0.0182150427339428, 0.028005628203437057, 0.8736389871267316, 0.03961771794632559, 0.9980552486375828, 0.7937989019554033, 0.20579971532177121, 0.9975925348782754, 0.006642346236405055, 0.47064145555382825, 0.011354438010948811, 0.025661029904744313, 0.00028386095027372026, 0.22413660633612953, 0.010105449829744442, 0.12149248671715228, 0.08424993004124018, 0.014590452844069223, 0.008345511938047376, 0.00840228412810212, 0.013965958753467038, 0.08916807893479965, 0.7583914810440746, 0.017998170488569713, 0.13390638843495867, 0.00041138675402445054, 0.9890646463059933, 0.01066638344055483, 0.9970928020620446, 0.14708087098662095, 0.08532936026704728, 0.5313436808734227, 0.06736528442135312, 0.0948727755600723, 0.07382112417839945, 0.048729575970988884, 0.013771401904844684, 0.3012494166684775, 0.08527675794923055, 0.052966930403248784, 0.18723809897548446, 0.2628483921261221, 0.04780265468893203, 0.022424942668283685, 0.1303636667116225, 0.1967414970097422, 0.6243104038850178, 0.02571393425963196, 0.9987463733283878, 0.09822308982266198, 0.3610945523802842, 0.10469775638812065, 0.0824440876001738, 0.05342798928830344, 0.01376466151323437, 0.13452918308230802, 0.03160596493805383, 0.03179780691036372, 0.030119189652652208, 0.0006714469030846033, 0.02561090330336987, 0.005371575224676827, 0.0005275654238521884, 0.026090508234144588, 0.9983531075462716, 0.06708823457669517, 0.49366935137363555, 0.04040687168577243, 0.08754822198584027, 0.01616274867430897, 0.13167509138236635, 0.0012827578312943628, 0.023025503071733813, 0.0011544820481649266, 0.028092396505346545, 0.0006413789156471814, 0.06452271891410645, 0.007824822770895613, 0.013148267770767219, 0.02379515777051043, 0.023886038851732662, 0.4490195154966296, 0.004751864493050264, 0.3919337833867858, 0.004688506299809594, 0.009883878145544549, 0.04631483925892991, 0.011214400203598623, 0.02958827624339298, 0.0008236565121287125, 0.014889175411557494, 0.013051787807578059, 0.023316487559323733, 0.1275150647435215, 0.048567953339338235, 0.0010642380213799214, 0.035313352527606486, 0.015673323587595208, 0.03395886777312295, 0.009481393281384755, 0.1055530619386813, 0.044504499075887625, 0.001257735843448998, 0.510060258974086, 0.04373050778761132, 0.997684567400625, 0.12592456787815268, 0.04650123685803, 0.19821640669105647, 0.06818878850190115, 0.017486809658797, 0.3315655417986425, 0.12426380941893733, 0.013481451021865843, 0.028428277154804057, 0.004591508681360106, 0.041421269806312444, 0.9956821226855415, 0.9772039230534092, 0.02209757614944895, 0.0721475648106883, 0.007884598475442726, 0.007256621605717199, 0.028677610384132392, 0.028817160799626953, 0.001465279362692896, 0.31712831921139106, 0.007605497644453603, 0.00041865124648368456, 0.05916937616969408, 0.014024816757203433, 0.002930558725385792, 0.013466615095225187, 0.41648821504351885, 0.022676942517866245, 0.9978878479805763, 0.5450030759981426, 0.4550248785229906, 0.9991601108880575, 0.20042558490758813, 0.04046347676424826, 0.6002257553262904, 0.1356840220847909, 0.0165532404944652, 0.006621296197786079, 0.03923983987666809, 0.9088743272252158, 0.05176319302879621, 0.9962618910146105, 0.06379571989093157, 0.894474716964484, 0.01628258959559341, 0.021354215863073327, 0.003470060077749416, 0.9998956915995595, 0.9994634387518725, 0.9984311258643643, 0.04684405397132612, 0.05387066206702504, 0.2304727455389245, 0.021079824287096753, 0.05480754314645156, 0.08104021337039419, 0.025764229684229364, 0.012647894572258052, 0.47312494511039377, 0.9973756523410232, 0.999873106944647, 0.9963996593817436, 0.20323672518961927, 0.05576824807210969, 0.016889164558423465, 0.004193953615178981, 0.09634758305140903, 0.06302265432539225, 0.18510070955641286, 0.0006801005862452402, 0.0858060239646078, 0.2858689464184159, 0.002947102540396041, 0.9986705716711881, 0.036781559189686605, 0.007662824831184709, 0.9532554089993779, 0.09005632697749358, 0.34696620048527493, 0.11416912853303095, 0.013376444658546278, 0.011968397852383511, 0.14796225188093734, 0.0004693489353875887, 0.07714923125433489, 0.0027574249954020833, 0.14766890879632008, 0.047462911091069905, 0.9990219174253412, 0.7386335415248564, 0.09878277093086384, 0.16245807623473077, 0.9962890937561654, 0.9985004895494414, 0.9511512406525383, 0.04829760599546058, 0.9987531390040132, 0.9986296815213983, 0.9971114847216085, 0.9987295776031185, 0.06393869182171107, 0.00039961682388569414, 0.024376626257027342, 0.03796359826914095, 0.012787738364342213, 0.6114137405451121, 0.06593677594113953, 0.0475544020423976, 0.07392911241885342, 0.0547475048723401, 0.0067934860060568005, 0.9978383345582134, 0.9967017430550871, 0.003898910320050614, 0.10566046967337163, 0.0027292372240354298, 0.08850526426514893, 0.032360955656420096, 0.036259865976470705, 0.5867860031676174, 0.14347989977786257, 0.9961832566023063, 0.9005506693455654, 0.09848811148003449, 0.062025025604454505, 0.09642545997331163, 0.06428363998220775, 0.027972070370636346, 0.002171744593993505, 0.1415108777446168, 0.009729415781090904, 0.0265821538304805, 0.036919658097889586, 0.001737395675194804, 0.23698077009657129, 0.05828962490278568, 0.028667028640714267, 0.05107943285072724, 0.15558378271369472, 0.9952015443214421, 0.9974276053814188, 0.16517881980370616, 0.8092148045106646, 0.016679294507866094, 0.008608668133092178, 0.9497028645002363, 0.05005703938659915, 0.04367283734942147, 0.9548470347759876, 0.09818633074838971, 0.03494767704603701, 0.023298451364024676, 0.8429046868484642, 0.9995054012168493, 0.342302373680721, 0.1567752766694409, 0.002565951929820884, 0.10177179427635735, 0.20959660336152294, 0.05747074386406518, 0.05149448830102081, 0.013948251515949419, 0.00940849040934324, 0.03674574750781958, 0.006546467103004563, 0.01137133397959084, 0.12596005346406075, 0.044520835223510836, 0.0598351274379863, 0.20143763652111843, 0.24847439117986453, 0.021932254207159513, 0.0223151115125214, 0.1329608727621067, 0.14258699929691984, 0.17252398809861672, 0.10718613944602721, 0.30352036196159987, 0.349136602309236, 0.026375646879388894, 0.04120693767782946, 0.07550118257187449, 0.03509209894185716, 0.05582833922568184, 0.6864227232414786, 0.14674877739322084, 0.046363853387137687, 0.04491498296878963, 0.08041230821831692, 0.01738644502017663, 0.7563103583776835, 0.05433264068805197, 0.9987534336895304, 0.9954472111139627, 0.9978140585411266, 0.06063479292640915, 0.00021655283188003267, 0.3421534743704516, 0.3569873433542339, 0.07135415810447077, 0.16847810320266543, 0.20486335623823818, 0.3115277483292217, 0.48295266418973093, 0.031225064491209396, 0.030861982345962775, 0.04738221995468403, 0.0003630821452466209, 0.017246401899214493, 0.7317920637445644, 0.1214509775849947, 0.01978797691594084, 0.9989770766190061, 0.0019987758823968534, 0.9978888592866291, 0.02447318367810486, 0.6331785394165002, 0.014163204171158556, 0.037490834570713824, 0.1521503036328136, 0.0095809910569602, 0.015517039863989888, 0.11351391578355019, 0.02198165223301415, 0.9769623214672957, 0.09371908255609876, 0.05834651054076187, 0.007110980972155353, 0.03883689607869462, 0.18360917535796, 0.0010939970726392852, 0.44525680856418903, 0.15170092740598087, 0.015315959016949992, 0.004740653981436902, 0.007002356416987702, 0.0007370901491566002, 0.15515747639746433, 0.07481465013939492, 0.3453267348798672, 0.4168244793480574, 0.9987010253800377, 0.9993309474400432, 0.9953825251775806, 0.9991412782239578, 0.13636863219940176, 0.09718042734951574, 0.15943910763522176, 0.10760954638214669, 0.014063508998547806, 0.01959410242494301, 0.01485359377374712, 0.07648020623929369, 0.02544072976141794, 0.14774585296227188, 0.014063508998547806, 0.012009288583029586, 0.17539882009424793, 0.6828137896047856, 0.023305017651779166, 0.29019005368394785, 0.0035615641594081114, 0.9969752888986055, 0.0027540753836978052, 0.9086967854431465, 0.08991315561226923, 0.020598211714682128, 0.13842696516731293, 0.6060761955370877, 0.028977145293535875, 0.0075061279977231485, 0.051844651519157556, 0.14663133762994057, 0.292667234928364, 0.7055940973000193, 0.9969168067994109, 0.2753229904409441, 0.0824777096905339, 0.013348993475924564, 0.06007047064166053, 0.5647100990083087, 0.0042907479029757525, 0.9990369679257217, 0.0030657849510741415, 0.01328506812132128, 0.9830950409777748, 0.11137444635737956, 0.015249985981707433, 0.05750400851225059, 0.05169580085495769, 0.06744127374581807, 0.07380002241328092, 0.1060892526597481, 0.006964343778649784, 0.03575763861053782, 0.034959354145791405, 0.062018444795644126, 0.06958838368548084, 0.055934966633266255, 0.14933424900859715, 0.04745663507664912, 0.00963446767797401, 0.019984638669168945, 0.023893479841375544, 0.0013212984244078642, 0.9988043288792194, 0.997127515657959, 0.007559523457332321, 0.6683508091982634, 0.0066701677564696945, 0.3170553073575262, 0.06466111518486578, 0.03233055759243289, 0.1185453778389206, 0.7827913792834509, 0.5630082725849885, 0.14079250252376688, 0.005337337832606901, 0.024179757756810052, 0.0002426062651184955, 0.1460489716013343, 0.016578094783097193, 0.09340341207062076, 0.01018946313497681, 0.0002426062651184955, 0.6290182500798155, 0.022298660209296148, 0.03130388837074267, 0.004839544386083505, 0.0064935658851247025, 0.03399933081362462, 0.005268364774723815, 0.024810322485617965, 0.16773003201388145, 0.0018990617211213751, 0.02358512137521708, 0.024197721930417523, 0.01531501388001109, 0.004288203886403105, 0.0049620644971235936, 0.17984441749864763, 0.038572529222230055, 0.7135917906112561, 0.053519384295844206, 0.014464698458336272, 0.9976493101288313, 0.11079578912664419, 0.00018543228305714507, 0.1715248618278592, 0.06925895772184369, 0.09178898011328682, 0.033655959374871834, 0.05748400774771498, 0.4460573568939625, 0.019192241296414517, 0.9992322436393789, 0.9966833933799288, 0.998817346790118, 0.013481725734856351, 0.8590387116678782, 0.12723378662270682, 0.9996974468907004, 0.555643693734451, 0.013386199807156565, 0.02549198050232424, 0.08194682316728888, 0.008031719884293938, 0.025899386583411614, 0.1553381186317429, 0.02875122915102323, 0.06466116515543888, 0.03864537683457373, 0.0022116330116171714, 0.04473583279077114, 0.06607364777321133, 0.12111049469343635, 0.03193314380130703, 0.041939843241347946, 0.0110368008529863, 0.034581976006023744, 0.007210709890617717, 0.036053549453088585, 0.04120405651781552, 0.5642012596046597, 0.07685079197411392, 0.2715628137401252, 0.6130218230452485, 0.0004002645415318433, 0.010556977282902367, 0.006637720313736401, 0.00648762111066196, 0.006120711947591104, 0.008372199993707722, 0.9980725905426191, 0.9982574449700989, 0.9952651545763859, 0.999627753749758, 0.010975726947519355, 0.05423300374068387, 0.006886730633737634, 0.0014347355486953404, 0.16370332610613833, 0.04949837642998924, 0.06535220424307275, 0.09713159664667455, 0.0029412078748254477, 0.004375943423520788, 0.3444082684643165, 0.006599783523998566, 0.19246977385747993, 0.998064930201811, 0.9973445257394714, 0.9988920350071838, 0.9957276234513167, 0.999722795683981, 0.9892253903627601, 0.007391472406197461, 0.002956588962478984, 0.9977987982084725, 0.993898627930517, 0.9982763196834954, 0.994928432466931, 0.07987508680538169, 0.04943605441073315, 0.06038534663902399, 0.20053628716114677, 0.004653449197023608, 0.33400815942401213, 0.029344103171819458, 0.06525778168061341, 0.17644784425890692, 0.9967545591913621, 0.9985511447958406, 0.9374931083440471, 0.005196746720310682, 0.057324113822503985, 0.9985859111593705, 0.9978938437141425, 0.14843336612888974, 0.07246982098828107, 0.00838493796558624, 0.0012976689708645373, 0.09522893832344373, 0.011179917287448321, 0.002894800011928583, 0.027151227698088778, 0.037033476014672564, 0.296966552947846, 0.05540048298690909, 0.07726121411147321, 0.023457862165628174, 0.10181710386783292, 0.016570234551039474, 0.0243562483762267, 0.9969701265487345, 0.10628711505613635, 0.20976011097636685, 0.6838309500251216, 0.016767511001096243, 0.9825761446642399, 0.032915886889135805, 0.9666876254809358, 0.9993727352282241, 0.9050393507249754, 0.009083304029094299, 0.02830304878630832, 0.005134041407748952, 0.05239355077651494, 0.3718074769609309, 0.041328225661404226, 0.16003695894416103, 0.010698441394618825, 0.06609585025990534, 0.34997093219657194, 0.055074475193671195, 0.9447775880950686, 0.20066219557209725, 0.5708775790618686, 0.047573131588489054, 0.048391789684658085, 0.05157546005864875, 0.056123560592921125, 0.01546354181652608, 0.004730024555643271, 0.004457138523586928, 0.9898379366291431, 0.009462072681531904, 0.9982297495558399, 0.08567328924675216, 0.05635857340810443, 0.5090851356204598, 0.03303066573368758, 0.21201558567810713, 0.09434383900184515, 0.009083433076764083, 0.023844169368491232, 0.03901773169389475, 0.934257908892702, 0.010335225568366014, 0.029945653569881013, 0.051676127841830066, 0.7300909343807274, 0.016960370163472432, 0.03710080973259595, 0.12375770103658791, 0.010659930311816326, 0.005083966764097017, 0.018203880994024806, 0.0006559957114963893, 0.07953948001893721, 0.8483664538927055, 0.022467853118751335, 0.0016399892787409733, 0.013119914229927787, 0.6796201053892476, 0.22906162946556563, 0.017247705256984467, 0.004992756784916556, 0.039790758619183464, 0.029200062408754404, 0.9979614674649134, 0.9961704168480751, 0.003748524616549671, 0.11939354205213129, 0.37789481181354284, 0.20125887526294278, 0.03238193547700378, 0.03673647447757886, 0.02303946998486088, 0.06318040222652571, 0.14607499011020042, 0.11687500856261249, 0.0032912674670118555, 0.20734985042174692, 0.0016106202498143124, 0.06617548417715327, 0.47086132868484504, 0.059943084080045714, 0.0011204314781316956, 0.05434092668938723, 0.006722588868790173, 0.006232400097107556, 0.005392076488508785, 0.6040229253901507, 0.29147146533927404, 0.030403838526349865, 0.073779981490609, 0.99953592296526, 0.2509277195755599, 0.24983227067902908, 0.009532736142151589, 0.18527070805369925, 0.14387672421883071, 0.005896778102602329, 0.10562924253357214, 0.0033329615362534897, 0.04568254972767021, 0.9966097805694272, 0.41525255124744775, 0.1392261318286352, 0.2754199583591981, 0.0018627018259587162, 0.07147576774027631, 0.0203164454970846, 0.014381790842285901, 0.01563803160863015, 0.009919970189408047, 0.0365176195182139, 0.45002294767270434, 0.15396735908330608, 0.22333916918713273, 0.10391355096184178, 0.05610870426518982, 0.012628783385484656, 0.7423211641649917, 0.23695738503756658, 0.020737663394877707, 0.055733609406907844, 0.12171033885951595, 0.06214849266785144, 0.1058800624252519, 0.028211690900278846, 0.12419351947665541, 0.03107424633392572, 0.00034488619682492477, 0.07870303011544783, 0.013898913732044467, 0.05138804332691379, 0.03383333590852512, 0.09115342182082761, 0.06883928488625499, 0.019313627022195787, 0.043421172180258025, 0.04469725110851025, 3.448861968249247e-05, 0.01686493502473882, 0.008518689061575642, 0.13211125636444926, 0.02606838183619936, 0.07053797438030415, 0.42735632304321397, 0.011795647889682969, 0.09802183396326547, 0.12892643143423485, 0.10509922269707525, 0.05115186757748717, 0.1286210003578844, 0.05837984886561036, 0.6529276430271279, 0.10860505217538943, 0.9962623482223685, 0.07799644526956045, 0.16008259178921022, 0.042809080617818, 0.07863380130853542, 0.11796398021361511, 0.0692859127369027, 0.22955440003748062, 0.07172911088630671, 0.007568602962827624, 0.0009294775568384801, 0.009825905600863933, 0.023714955950193222, 0.07802300177118442, 0.008976097548897322, 0.022891704399850568, 0.9977415725681645, 0.9973479066567985, 0.006252446283295299, 0.9923525458201539, 0.999068728288889, 0.10333107669208147, 0.002870307685891152, 0.8926656903121483, 0.0014500469482618306, 0.6943912323488841, 0.016494284036478322, 0.00018125586853272882, 0.20046899059719805, 0.0045313967133182205, 0.020300657275665625, 0.05637057511367866, 0.005800187793047322, 0.9987332361545457, 0.13579075537295698, 0.08174136379944585, 0.10850656319318731, 0.17323237779356485, 0.030249865242788127, 0.12529968691252924, 0.035439793103070404, 0.03807182794649927, 0.030805928942104085, 0.05757112833584554, 0.0010750564853441859, 0.13645803181213614, 0.0035588076756221327, 0.011788550425498314, 0.008044388183437529, 0.021983051579624213, 0.0003707091328773055, 0.06072616185940716, 0.050670855837232597, 0.10193320026400488, 0.5991779412036959, 0.1875018828840786, 0.0313011886865459, 0.050502758216948, 0.013677830350423416, 0.8772223888204249, 0.0021042815923728335, 0.021831921520868144, 0.00315642238855925, 0.010396229136033682, 0.9800808740060845, 0.009451117396394256, 0.9989534781462546, 0.9489879121724268, 0.050952371123351776, 0.9985802849449259, 0.06639208332721562, 0.9325069885504376, 0.03482740083189298, 0.24833451027958472, 0.7167378142215657, 0.999133121403264, 0.9980134371053627, 0.0012164831711882975, 0.17030764396636164, 0.3677357068668624, 0.056960035545052044, 0.08529693765037945, 0.025975493596550117, 0.006941109859133227, 0.1066211720629743, 0.07298899027129785, 0.019606846406211385, 0.0050806061855511245, 0.004651259183955255, 0.009374076201509821, 0.03155700461729642, 0.008586940031917394, 0.003148544678369711, 0.023971874255769392, 0.21810498547545054, 0.7818174177239338, 0.0038522856733905647, 0.03390011392583697, 0.09245485616137356, 0.06702977071699583, 0.8020458771999156, 0.9989443563776915, 0.9985461073158914, 0.9953506179040794, 0.9990197470585708, 0.9983878988932754, 0.9994412597722956, 0.053053117419049195, 0.010371469596640252, 0.13473149092482548, 0.0013665936409690686, 0.010444679970263595, 0.001952276629955812, 0.7880364616816635, 2.440345787444765e-05, 0.9947090092827543, 0.9993737061880342, 0.13564256522373158, 0.03815400497737049, 0.349479079811732, 0.07775873257745469, 0.08007988877379661, 0.30262073909807924, 0.016103021112122147, 0.8683461991615089, 0.13156760593356195, 0.9938397745196211, 0.25310673090390573, 0.014304013416220727, 0.2452116585637839, 0.3495194966573935, 0.11406057451376009, 0.010310035644159096, 0.013468064580207828, 0.06075649008891758, 0.07931676449263929, 0.014317925968585315, 7.575622205600696e-05, 0.053029355439204874, 0.0631806891947098, 0.013408851303913233, 0.00045453733233604174, 0.03454483725753917, 0.16052743453667875, 0.1503003445591178, 0.02590862794315438, 0.25711661765808763, 0.04598402678799622, 0.04098411613229976, 0.11701277732802481, 0.1062312673491706, 0.027612114936994767, 0.058907117353491946, 0.08331340277465042, 0.03909967070207483, 0.030569874311724685, 0.038546283464222134, 0.02812733753775417, 0.05560587624492243, 0.12907280264950421, 0.08012665557736076, 0.03782115535944964, 0.03242085921074921, 0.030608038948817973, 0.007823750604124295, 0.05596844029730867, 0.04110331414947251, 0.004121648901139252, 0.008908079883107415, 0.0969252273848553, 0.4685384105682169, 0.04334379167004503, 0.3779950911593191, 0.05136164448244731, 0.1381279176858049, 0.13563463397306474, 0.03241268826562209, 0.6417712276593174, 0.9849040851243428, 0.013430510251695582, 0.09489246576271382, 0.9036350716949338, 0.022742893411540413, 0.9408375906037244, 0.03590983170243223, 0.9997332458525043, 0.998131911081026, 0.9987813046936006, 0.027123151632956262, 0.02958889269049774, 0.9394473429233033, 0.9971819226766767, 0.9993034311503527, 0.9983490727045785, 0.05617828800560726, 0.31847277752144254, 0.04990181720773942, 0.18790668746703118, 0.01592363887607213, 0.02545457601357515, 0.01193304324532899, 0.10251568969850815, 0.028941504234612843, 0.05865788140723406, 0.03494676950417776, 0.0068188818544737085, 0.008058678555287111, 0.01638856263887715, 0.005462854212959051, 0.014567611234557468, 0.002402106107825966, 0.05211020508106329, 0.0033319536334360167, 0.9984401272211825, 0.007595276479976043, 0.02002391071993684, 0.15190552959952086, 0.06179793135980508, 0.04004782143987368, 0.014154833439955354, 0.018297711519942285, 0.005523837439982577, 0.6804677246378537, 0.0411997531635033, 0.9571019581059996, 0.02690710484987606, 0.03209970403143109, 0.06608762594706401, 0.0882741860864355, 0.738293192722915, 0.04814955604714664, 0.04311169307182015, 0.7927761337095816, 0.0700964194760335, 0.09388768713418609, 0.9982160817122981, 0.9983599801647273, 0.009415266484853645, 0.010810120778906038, 0.06625557896748861, 0.009938336845123293, 0.24357643109889895, 0.005405060389453019, 0.10914734850959967, 0.03469700056455325, 0.5105166716231755, 0.9938962301106283, 0.9982094730709302, 0.9982870622918171, 0.9950736226304754, 0.01685549528226519, 0.9445320134098973, 0.03745665618281153, 0.2640784325509813, 0.18332287390035332, 0.027485150668224517, 0.2362958005457988, 0.005375912732169155, 0.07376474723211551, 0.08805447573956118, 0.08162675399457633, 0.0006587086746926633, 0.01601087052841683, 0.022438592273401694, 0.0008818196774111461, 0.008367642686616427, 0.050205856119698564, 0.939965195129912, 0.031028450122224327, 0.0025965230227802784, 0.9662960429276806, 0.008110437940829334, 0.9331774477801281, 0.058204319340069345, 0.9998516598222206, 0.9976511515194458, 0.9994485739899153, 0.5856574634920932, 0.34927276549244995, 0.054864896503856904, 0.009879730440546927, 0.0002834348896878217, 0.9785019774955337, 0.02094070379854255, 0.9985033633111263, 0.9989082753187812, 0.022425098998457224, 0.9770935992184933, 0.7998931516115267, 0.014107462991384951, 0.07277099659722737, 0.11321239050586424, 0.9994469967119847, 0.07566177267996017, 0.010728161797904801, 0.17616770952348937, 0.5832732177492452, 0.032749125488340976, 0.03952480662385979, 0.05053528846907788, 0.031055205204461266, 0.9981081936844726, 0.998623377269826, 0.9982224776457967, 0.015440456881697883, 0.9516936150719241, 0.032284591661731935, 0.9978172487733448, 0.9986823251761541, 0.13593148957306045, 0.18176525692341694, 0.1543886787084401, 0.05175624169920901, 0.09181024492598658, 0.026425176713153132, 0.02882746550525796, 0.10158589535722505, 0.03995886307659519, 0.034274239103198614, 0.04730843967818324, 0.010013500806694392, 0.017743638009011915, 0.02480779416005285, 0.016673311319460257, 0.021977374692127356, 0.013343406063077323, 0.00014271022527355428, 0.0012368219523708037, 0.9957975963368549, 0.9981598069716994, 0.09932393736699487, 0.09695060553026859, 0.13361858240768962, 0.00011866659183631405, 0.018630654918301306, 0.35077844546814435, 0.01020532689792301, 0.004509330489779934, 0.0987306044078133, 0.06063862842835648, 0.08994927661192605, 0.002491998428562595, 0.03393864526518582, 0.9982602589406181, 0.9958571074302875, 0.10472428281691935, 0.8946703816514404, 0.99985403506861, 0.9994683760652984, 0.01734421569920498, 0.0870530252079714, 0.6852210001355765, 0.14692791337532254, 0.04987499346996264, 4.1493338993313344e-05, 0.013485335172826836, 0.748790291872267, 0.2318403579421884, 0.0193995361241063, 0.9980443874555801, 0.9987227397033162, 0.9971896869256335, 0.999955800017795, 0.7216377960767231, 0.27816720070062684, 0.9983222028849854, 0.15993192355012772, 0.07851203519733542, 0.12043358485517193, 0.6409392996819512, 0.005686175829266481, 0.004101503876847953, 0.004287935871250133, 0.0003728639888043594, 0.1357224919247868, 0.1761782347100598, 0.13385817198076502, 0.04306579070690351, 0.48817217734210755, 0.008575871742500267, 0.9987962259885788, 0.9969241228633993, 0.9989826883603927, 0.7098580307376802, 0.16496975686835527, 0.0008785371667545547, 0.004099840111521255, 0.026551345484137654, 0.06940443617360982, 0.017082667131338564, 0.007125912574786944, 0.09710648946984411, 0.10014971278656287, 0.013141191594921924, 0.07054744961484402, 0.07580392625281278, 0.06003449633890647, 0.06210942132757836, 0.048276588069765806, 0.05574631802898458, 0.015492773248750058, 0.07884714956953155, 0.09005174450835972, 0.006086446633437523, 0.010374624943359414, 0.21620718381961018, 0.9981921349413353, 0.9981596992550305, 0.9987852961570446, 0.9983505688009747, 0.9988249188531856, 0.9994211505471028, 0.9990974947852568, 0.9980230541612196, 0.9971666386276274, 0.7517631721894447, 0.07679759988314418, 0.17108798640633785, 0.12556051910369528, 0.8736919454298796, 0.9966151708808436, 0.2018459291308486, 0.6899330196280311, 0.10810893514365862, 0.23913235589653276, 0.010243208391206621, 0.3758326278809993, 0.10056968238639229, 0.12515338252528818, 0.1489921220539145, 0.9938701680114456, 0.9987422835381955, 0.9987061080259906, 0.9993255665932627, 0.9936411616849288, 0.0034987364848060873, 0.07361114873595885, 0.9250467691152162, 0.9991768907887618, 0.9976027593499457, 0.06484686462748643, 0.9347067596696286, 0.11384631038878307, 0.8852825031724774, 0.00023320397002685143, 0.7454364901908306, 0.009328158801074057, 0.08908391655025726, 0.0005830099250671286, 0.0003498059550402772, 0.09246537411564659, 0.013409228276543958, 0.03847865505443049, 0.0005830099250671286, 0.00652971116075184, 0.0034980595504027715, 0.9923292770160027, 0.006457674253900234, 0.8628283424243093, 0.13619313155468776, 0.9982159083773674, 0.9972976294077724, 0.9966407345852804, 0.14051652832490955, 0.07115670743818948, 0.35218976408800856, 0.4359246773864841, 0.01789297186814584, 0.2948080126846886, 0.09276653867354183, 0.5340200056362098, 0.04388038339092908, 0.016614902448992566, 0.9966035918043994, 0.9991184994250178, 0.9975537237930521, 0.7344805069222767, 0.0055515017701408915, 0.07116015905362416, 0.12095544765852428, 0.05753374561782379, 0.010093639582074349, 0.9959213983003044, 0.9991685740016057, 0.9642692882387804, 0.03552571061932349, 0.9986905455536305, 0.9992944329456002, 0.9975003073591506, 0.09834761661769831, 0.07325982779050866, 0.018118958597414747, 0.02909486620931022, 0.003919967004248383, 0.05932216733095886, 0.0152443161276326, 0.2946944083416062, 0.01707363406294851, 0.022561587868896248, 0.022822919002512806, 0.10305157702279637, 0.010366134966790168, 0.06359057584669599, 0.0016550971795715394, 0.12021232146361707, 0.0032230839812708925, 0.04338096818034877, 0.11041951770081099, 0.6156520284631476, 0.19133763754262667, 0.07299488727397123, 0.006237438404473292, 0.003203008910405204, 0.9956225525605987, 0.9978770569402331, 0.003469458043113136, 0.9803318325387576, 0.01617607189527908, 0.9994231285625907, 0.9994988854051653, 0.9967094850135891, 0.07357158107182417, 0.0940777026046092, 0.1230367291967102, 0.10722666603021182, 0.05917033541521178, 0.01064439896358307, 0.0209757273694137, 0.01925383930177526, 0.01534045732986972, 0.0026610997408957676, 0.06480560545475576, 0.01534045732986972, 0.39384276165257365, 0.9952791508574149, 0.9968488470893613, 0.9953660588119948, 0.9990486513898735, 0.08821890043820381, 0.0693656676832651, 0.055136812773877386, 0.011916665986612208, 0.14388929527118324, 0.0019564675500408106, 0.07416790621518345, 0.2203693904091422, 0.046955221200979454, 0.012450248045714249, 0.00889303431836732, 0.0001778606863673464, 0.009782337750204052, 0.0697213890559998, 0.18124003940832598, 0.005869402650122432, 0.003673186917995435, 0.08218755729014786, 0.004438434192577817, 0.05953623796250935, 0.0104073629343204, 0.07499423290907346, 0.007040274926157918, 0.05509780376993153, 0.13085728395358737, 0.16085497711721677, 0.04530263865527703, 0.0006121978196659059, 0.33196426771383747, 0.033211731716875394, 0.935114828496047, 0.007787215782062848, 0.007138281133557611, 0.02206377804917807, 0.027904189885725204, 0.7425363251061275, 0.256665796741188, 0.0005437834676720085, 0.8568214511430493, 0.14231148843933486, 0.9949914548228448, 0.9715383184320379, 0.0013198455623312565, 8.79897041554171e-05, 0.007743093965676705, 0.0028596653850510557, 0.01641007982498529, 0.08925708701129427, 0.021192325128379923, 0.02817332634714037, 0.008726251523450556, 0.011468787716535018, 0.2366060770215594, 0.1436091679287863, 0.023436218377267212, 0.03665025639849234, 0.000747964416295762, 0.4001609627182327, 0.9988266155858107, 0.09573974942016207, 0.13619067675820104, 0.08041609026481326, 0.00315746867322029, 0.1099593985499094, 0.06098551381422686, 0.05332368423655245, 0.045507293255293825, 0.03543872182180815, 0.04943756894643517, 0.0611621554183231, 0.01664847118607062, 0.09587223062323426, 0.08785711783736737, 0.01512493735074055, 0.04332135340460286, 0.00982568922785335, 0.040043703210719164, 0.95854614560659, 0.9987852002841381, 0.11983230015218804, 0.02756214246405754, 0.007657471849375779, 0.009203234800336729, 0.5001137670570579, 0.06059390767766921, 0.0006896480858133465, 0.053198026481532976, 0.02002357545706337, 0.12556351355498171, 0.006920261826609788, 0.06867943695961878, 0.1473011220467737, 0.0007649798606006712, 0.1687205581435925, 0.467657688113877, 0.1286866121054907, 0.022439409244286355, 0.0006799820983117077, 0.011899686720454886, 0.050573668561933266, 0.001274966434334452, 0.13095588417042495, 0.011402491233836473, 0.21250097299422518, 0.5283154271677566, 0.1167891526374766, 0.9943742762531146, 0.9974973735585558, 0.9974437489133033, 0.9952027007147001, 0.016157582297512556, 0.04507115061937713, 0.015307183229222423, 0.9226829890947961, 0.9987643647781521, 0.9994572825039957, 0.9973364346948194, 0.9937820227565145, 0.004737935746157399, 0.9780667010176225, 0.0050542733986600336, 0.01671798124172165, 0.017894046111326892, 0.9006669876034535, 0.06486591715355998, 0.01565729034741103, 0.15368437915592864, 0.6025187938993033, 0.01574857595590788, 0.014336634663309245, 0.007928593412284659, 0.08183828953639027, 0.10899100670174869, 0.00754845537196964, 0.0038556858374808956, 0.0034755477971658774, 0.998055836127199, 0.998688108778758, 0.0012714043396292272, 0.9950382729040401, 0.10419330524358777, 0.8955116234812324, 0.9984143581224153, 0.9972212894531497, 0.9979885828574188, 0.9977481303949184, 0.9970028260983743, 0.9992367482034485, 0.9996957250630477, 0.9955969804674624, 0.06776022497894606, 0.9314989963973186, 0.9981348974405716, 0.07113861454095735, 0.03596017877894547, 0.057067240236152596, 0.024234033524941516, 0.8106675085601404, 0.0134647882599055, 0.037761250631112755, 0.932661000136121, 0.016038058905131884, 0.03392660626438191, 0.9171802392158589, 0.037644590512533355, 0.010456830697925931, 0.0004647480310189303, 0.9989753254463734, 0.9974253696374904, 0.999184575400018, 0.04316374082253126, 0.023214112711277313, 0.9334612353511277, 0.1481090698238151, 0.0762591843163128, 0.042538890966966905, 0.12548430708352515, 0.19780403590672035, 0.06595877316458335, 0.08955936432977399, 0.048249294342311656, 0.023636732958705484, 0.04720118233038129, 0.03556352481860275, 0.013444747187520551, 0.034551554600187225, 0.003578037557969179, 0.01911900876935046, 0.0005059851092077627, 0.02844359149617923, 0.143806228218342, 0.855753318658902, 6.320550175800085e-05, 0.9750712756206791, 0.024839762190894333, 0.9974553113677067, 0.9970286737019206, 0.8744735628240038, 0.040906530299798946, 0.08412852457883178, 0.970294066039738, 0.002903359856672381, 0.026790093222931514, 0.9757612158903525, 0.02181579954226398, 0.998087469066665, 0.995936253734088, 0.008021325313128049, 0.01646482564273652, 0.0375735764667577, 0.9376507116030208, 0.013159829172438502, 0.01584053511497227, 0.056132357766388925, 0.006661148099629366, 0.09008796637181667, 0.18838051759805485, 0.1005670896017214, 0.09406840852891225, 0.03720494914183231, 0.3572649919776823, 0.0314373696897142, 0.009179387015342906, 0.030209007130663712, 0.07536352305228736, 0.03540283642681291, 0.17521224135784952, 0.06794376691493137, 0.0836312513196269, 0.09147499352197468, 0.4195342113093578, 0.021093306733340627, 0.05823873478781862, 0.13494226508299367, 0.02010757090836678, 0.1290939846553968, 0.05708409836310849, 0.201150807387714, 0.11639298398358529, 0.14106277686275798, 0.13727969979643126, 0.004440187226730853, 0.0002065203361270164, 0.0033907960861797952, 0.6158207353438844, 0.19497077495533824, 0.009650727322204032, 0.015388997621892917, 0.04238495107724744, 0.005216609363353531, 0.025300555412264628, 0.034299206564049466, 0.02256183549650402, 0.0029995503839282804, 0.015258582387809078, 0.011476540599377768, 0.0011737371067545444, 0.9256407277210513, 0.07423319390679671, 0.9980491955172691, 0.13732063530533686, 0.07284532749054537, 0.04302713239567222, 0.0850080123318752, 0.01660925779407408, 0.0006539077871682708, 0.04459651108487607, 0.05584372502417032, 0.007192985658850979, 0.04629667133151357, 0.002615631148673083, 0.020009578287349086, 0.390644512054325, 0.04158853526390202, 0.03570336517938758, 0.9975635386774456, 0.032992289193778744, 0.6233671014966916, 0.02110185348879063, 0.06822320980115093, 0.019707296214748815, 0.10470189218003421, 0.0047708538322483165, 0.04851591358640211, 0.053250068543017746, 0.02341388265364943, 0.06511019790158656, 0.04371274960441318, 0.017152378125616197, 0.07268248523463451, 0.08283623415849427, 0.03774670503898146, 0.02816661424641322, 0.029256564695867092, 0.10882294750599975, 0.10199641574363076, 0.12482800936903292, 0.08226257602720276, 0.05048191555365302, 0.09207213007228761, 0.029486027948383696, 0.014169355842900336, 0.019217547398265637, 0.9992423377599561, 0.9975094514291362, 0.9981078590043833, 0.9850686534118037, 0.014072409334454338, 0.9977953950390982, 0.009835054442371751, 0.9901264286003404, 0.09374555055278977, 0.14976653347870236, 0.07903296917830767, 0.0426287614183712, 0.47797027183253377, 0.033386242349786294, 0.0077335363635098195, 0.0626227822606161, 0.030556899777770506, 0.022446117737991916, 0.35736990455240725, 0.04685497339222992, 0.004173200947096646, 0.263746299856508, 0.07203808255574416, 0.0015541575940911647, 0.03922808890270847, 0.04124273763578961, 0.10976957525673522, 0.01203033100611309, 0.004835156959394735, 0.039515895864577204, 0.0013526927207830506, 0.006302972464925278, 0.15388302134537132, 0.006776500022548462, 0.03360014594513613, 0.007905916692973206, 0.11943581289741664, 0.0321883751071052, 0.033317791777529936, 0.5150140017136832, 0.003388250011274231, 0.04348254181135263, 0.020047145900039202, 0.031058958436680453, 0.030902091400367152, 0.7799844335738241, 0.005476319995001773, 0.1834567198325594, 0.9978985481242494, 0.7295095544297201, 0.1768836851945621, 0.03825245339330254, 0.007324937883823891, 0.04801903723840106, 0.9447474181213786, 0.05383906589022782, 0.21933258274778217, 0.04107724833187157, 0.036330804516063304, 0.04107724833187157, 0.36940224462784366, 0.007031768616012252, 0.08443982146394713, 0.03773715823926575, 0.13489276128383504, 0.02871305518205003, 0.11206078428240354, 0.04376991246041363, 0.034574552699822535, 0.05652081132843329, 0.4439519692413383, 0.2802745655028167, 0.0008582335776551693, 0.0004904191872315253, 0.0275860792817733, 0.002226939427402081, 0.4793487117482979, 0.4381931580995787, 0.03184095123602783, 0.04837169390866636, 0.01643952812908739, 0.10588609456372822, 0.02550068536559225, 0.04025742715075731, 0.023947344125048557, 0.15895858694897097, 0.01825175957638836, 0.06549922230959228, 0.01708675364598059, 0.00893171213312622, 0.051260260937941775, 0.03016070908722332, 0.06769978906702917, 0.24633403172955354, 0.0941065901562719, 0.017733979162873798, 0.0120383946142136, 0.13652012905458205, 0.8634099131846644, 0.23401026617324433, 0.6167752968377811, 0.023726766977524343, 0.12020221439969535, 0.005268146566196083, 0.11896858280223724, 0.04576209127779196, 0.004499082007648086, 0.00314935740535366, 0.05270353208959186, 0.0007712712013111004, 0.05366762109123074, 0.000514180800874067, 0.012018976220431314, 0.41565090490657386, 0.008419710614312846, 0.05437461969243258, 0.06131606050423248, 0.02872985224883849, 0.06407978230893059, 0.02680167424556074, 0.011247705019120214, 0.03734238066347911, 0.03513266748198169, 0.5248964454524006, 0.16912094123076848, 0.01897294891950594, 0.05004933077042085, 0.05711511864389202, 0.011514617275286364, 0.009028506727213172, 0.012168856893200363, 0.01000986615408417, 0.02329093039773833, 0.0331699486282397, 0.005037645057937784, 0.013542760090819759, 0.01570175082993595, 0.0013739031976193958, 0.00987901823050137, 0.9968518278327624, 0.334094352539402, 0.6655502501722738, 0.9973700851102536, 0.9978350581955417, 0.9992383318821871, 0.9987077417041822, 0.16146690254114113, 0.09893195173216845, 0.022592542541962985, 0.2476504746753405, 0.1799105641488538, 0.04808930173790118, 0.15316914067264054, 0.03775481650167771, 0.00908982095594838, 0.013615872884221432, 0.02775978516007472, 0.9960726695102301, 0.9962425935547625, 0.9996588729774744, 0.05050358887006264, 0.057844547689426935, 0.014240356205984876, 0.005464322730203499, 5.5195179092964636e-05, 0.000607146970022611, 0.30114489713121506, 0.008886423833967306, 0.23949188208437355, 0.31748267014273257, 0.0011039035818592928, 0.003201320387391949, 0.9954172744248351, 0.023293285416660515, 0.10933154686558674, 0.8670977958706418, 0.9970098334601092, 0.9995491543340631, 0.9988265255150683, 0.9216117273878376, 0.07816774969135767, 0.995417720834938, 0.9976766930303381, 0.040415222039051436, 0.06870587746638744, 0.8904820589271001, 0.9966577688957635, 0.9991255006857277, 0.08567038009093536, 0.015319971925705798, 0.0032324748948100467, 0.01577055933528538, 0.8798600756103565, 0.00013713529856769897, 0.9966189830293326, 0.25207183351617224, 0.03210319701895899, 0.4440119095391405, 0.004753742635499696, 0.032041460101614835, 0.07710940976284573, 0.05068600913954872, 0.05327895966800309, 0.053896328841444616, 0.9973000647296695, 0.1913156906495446, 0.025153058930019807, 0.7827936824584952, 0.9997614698826469, 0.995681948196456, 0.9995550223610895, 0.9995535979926745, 0.4590785475249553, 0.08221169388099668, 0.21254247635231577, 0.006864725944298398, 0.04270651621116407, 0.0022772408180605263, 0.0003960418814018306, 0.01059412032749897, 0.003894411833784668, 0.059835327581793246, 0.014224504240349083, 0.008778928371073913, 0.02620477115275446, 0.04376262789490228, 0.022178345358502514, 0.0012211291343223111, 0.0032343420314482835, 0.08264874031852487, 0.02806521395842957, 0.4399829999309707, 0.03756760923569313, 0.011270282770707938, 0.40020553132847203, 0.011941396622739787, 0.023560052796216337, 0.017750724709478062, 0.27997733973585853, 0.04227899885348411, 0.1274824774589788, 0.19993770831857563, 0.2972439537714417, 0.9934732436190092, 0.9991800267603598, 0.9987801079583712, 0.023499207179892435, 0.01989932863318551, 0.010699639013823365, 0.003599878546706926, 0.05179825242206077, 0.41438601937648617, 0.476083937801991, 0.9990290295510227, 0.25846056280732843, 0.10176373226015432, 0.29977776493773645, 0.05756237478622755, 0.0030719608077478698, 0.08557221830840027, 0.02052445430504035, 0.08738319957060971, 0.028372039774614603, 0.04465745645848322, 0.012421989991155142, 0.00044268430854008605, 0.5237850802429508, 0.056997250758144734, 0.05739033524613194, 0.1402328910894354, 0.0055031828318208706, 0.016116464007475406, 0.19998173326349059, 8.404237900804784e-05, 0.29187918229495013, 0.00025212713702414354, 0.49232025622914427, 0.0005882966530563349, 0.019329747171851003, 0.013026568746247415, 0.13547631496097312, 0.040676511439895154, 0.003781907055362153, 0.0025212713702414354, 0.9958547265094554, 0.9993354951209752, 0.999043697899828, 0.9995961512473467, 0.002631475756256245, 0.15751262026733812, 0.7499705905330298, 0.08984610082074894, 0.06187474944998807, 0.11194608284023946, 0.14338044350459084, 0.08113295460008475, 0.5240716730523086, 0.011306430120379346, 0.04708941775410739, 0.012797387938451348, 0.006212324241966674, 0.9977367038451412, 0.99792625736262, 0.03299850644151194, 0.8931474202042377, 0.04986238404283711, 0.023974053022424426, 0.9959305467168265, 0.049076283498432044, 0.179705802810435, 0.049076283498432044, 0.7209883413960825, 0.9187384929863665, 0.06305068089122122, 0.018014480254634636, 0.9950041437641731, 0.09790454306045743, 0.9019515150545523, 0.9962715272807858, 0.025932094329594417, 5.137611556135595e-05, 0.5190336294730437, 0.008984398208792122, 0.0028385303847649167, 0.014006413504914666, 0.011745864420215005, 0.008534857197630258, 0.0003660548233746612, 0.09168710023368487, 0.04192291029806646, 0.09642012487977479, 0.028481634064326706, 0.12540909808526987, 0.021937601344698993, 0.0026587139803001705, 0.013672239879246055, 0.44416630616559527, 0.0044767511109035756, 0.009558468588145472, 0.0010889394594089778, 0.01935892372282627, 0.03194222414266335, 0.05444697297044889, 0.08094449981606736, 0.027828452851562765, 0.21234319458475068, 0.05468895951698422, 0.045614464021909405, 0.6676891681142306, 0.016392092301559604, 0.3042926430064163, 0.011543726972929299, 0.9306879643812273, 0.06833722815386634, 0.9990955141762041, 0.08733362322346681, 0.01471914998148317, 0.08046468656544133, 0.030419576628398552, 0.7595081390445315, 0.026494469966669706, 0.06122041693603569, 0.8215086891492186, 0.11712736372290602, 0.9987815038803606, 0.5326285749479687, 0.4472524909636082, 0.019905535063748904, 0.1716259809391151, 0.04510171127004653, 0.7830934293082414, 0.9965905694295157, 0.023797837023089505, 0.13168136486109525, 0.8440299530855744, 0.10194540460025486, 0.8971195604822427, 0.996329320420587, 0.9406802377806479, 0.05883453953238506, 0.9971284441770554, 0.9971485486757542, 0.04962691324282559, 0.09257506432960735, 0.0019479722955127801, 0.00909053737905964, 0.30675925625051254, 0.06029438057539557, 0.05417218193235541, 0.007513607425549295, 0.03070375380070144, 0.3005442970219718, 0.010945749089071812, 0.015305496607600414, 0.037846318884248296, 0.022540822276647884, 0.9991810668357787, 0.9985544553372521, 0.9971074603937542, 0.06931956095831644, 0.06337538675255917, 0.09012417067846691, 0.10480977753974959, 0.01687096502516403, 0.05131220968793412, 0.02080460972015046, 0.013112148983288104, 0.05061289507549208, 0.026136883640020956, 0.07858547957317337, 0.27771531546604206, 0.03164398621300196, 0.016346479065832503, 0.026836198252462987, 0.04169663376685617, 0.020629781067039953, 0.7730859590232128, 0.2017848543467336, 0.024634416688649702, 0.9984171920591739, 0.0674965567323495, 0.9309430749310846, 0.9943690290809433, 0.9972625093291774, 0.9992225267599766, 0.9986368153558146, 0.09341651557364591, 0.10778828720036067, 0.06898450380823083, 0.01293459446404328, 0.24108646903814004, 0.014012477336046887, 0.06718803235489149, 0.005748708650685903, 0.018324008824061315, 0.370073119387905, 0.16883080577280507, 0.08242447357304399, 0.7107617648690024, 0.012343761742823013, 0.025483895210989444, 0.9984326545479238, 0.030126305384714572, 0.0019647590468292115, 0.9653516116754192, 0.0022267269197397727, 0.0002619678729105615, 0.8296768939979524, 0.10368258789358388, 0.055929844419965895, 0.01069508848503668, 0.07620542171856988, 0.02172029213017822, 0.026767008800282186, 0.011432754302658598, 0.5302740488868085, 0.0367439794481031, 0.010714567699605342, 0.008327082505671542, 0.013179694688463816, 0.028222792455119865, 0.17382056838761925, 0.011685090136163796, 0.019662784564674296, 0.03121200155971991, 0.01592233284120428, 0.9840182631464713, 4.5233900117057616e-05, 0.019409299049707587, 0.979907314185237, 0.998035828166719, 0.9973129098617941, 0.9985869229256508, 0.9973651146125845, 0.9980942626465275, 0.0030000746736789197, 0.9840655898800237, 0.012863333874815095, 0.29683410035736635, 0.09657337506927474, 0.03250110215379058, 0.07936964431548, 0.013902474311850335, 0.18119713175010288, 0.005347105504557821, 0.0002789794176291037, 0.13693239748628508, 0.1569724189859757, 0.16508861094483962, 0.09033779114272453, 0.10696142566038162, 0.20081646686808927, 0.016290421353606064, 0.01828970033791226, 0.0024805868879354685, 0.1125149783945655, 0.023213850428888638, 0.1057026203739666, 0.040318792850175006, 0.013254479192252205, 0.023398968853361436, 0.015068639752085607, 0.023547063592939673, 0.012958289713095731, 0.027175384712606478, 0.002591657942619146, 0.04900889769534792, 0.9497330326113634, 0.5520067071664204, 0.029950823932124723, 0.15248876010660023, 0.033987674114280664, 0.009896793994962952, 0.1721521271229082, 0.04935374900119683, 0.9965667402735838, 0.15202043173687574, 0.34271958967324245, 0.505083321225263, 0.9988204253944726, 0.07734659772662676, 0.11590294104902286, 0.0990418505667819, 0.059160011113989976, 0.22802431960838707, 0.08839889634330957, 0.06110927012927794, 0.00072122583565655, 0.03342979211218873, 0.05590474855845906, 0.1047141943012699, 0.003937503210881705, 0.0004678221636691135, 0.02206561205305985, 0.015223712909399067, 0.0072707361270241385, 0.027309118804184497, 0.9981326907781175, 0.9986769483172331, 0.9990831121568532, 0.7282988161233613, 0.27166657102084335, 0.0073411761868749205, 0.06479649725274723, 0.7794994351154462, 0.0022448224703667113, 0.023358287867329294, 0.013893630965242619, 0.02821195807352759, 0.007219834431719963, 0.004732328451043337, 0.061216915475675995, 0.007523188819607357, 0.13634192647057156, 0.04883785920075148, 0.3842236711728166, 6.966884336769112e-05, 0.18016362894884927, 0.13536656266342387, 0.008569267734226008, 0.006339864746459893, 0.020412971106733502, 0.07970115681263866, 0.9689846743027123, 0.03097777091760589, 0.9977017797195596, 0.9947451992217824, 0.998482429956164, 0.9983998893930864, 0.16098606380288996, 0.8383054785833417, 0.9980268315858101, 0.9984128103792125, 0.9968265716016987, 0.09673555834517578, 0.10291839030332282, 0.06111987008626618, 0.05880130810196104, 0.12792343725905816, 0.09879650233122479, 0.0479974533000947, 0.11478491934799569, 0.04244256521269696, 0.01956286674257466, 0.04785254317607563, 0.04472892494722009, 0.016632462012411215, 0.046161925062519794, 0.018178170001947977, 0.023443237841307578, 0.011512304297070685, 0.010047101931988961, 0.010385225554700128, 0.028910568939775422, 0.4274188429585503, 0.08693969652392897, 0.4566413964552298, 0.03511004366818051, 0.0003755084884297381, 0.05688953599710533, 0.08336288443140186, 0.04262021343677528, 0.08355063867561673, 0.03529779791239538, 0.05350995960123768, 0.08073432501239369, 0.060644620881402704, 0.0236570347710735, 0.05933034117189862, 0.060644620881402704, 0.004130593372727119, 0.00018775424421486905, 0.3201209863863517, 0.33400375571270624, 0.02902533697376209, 0.4285838781442822, 0.024919313694546967, 0.16494886621674554, 0.013167591895414022, 0.005380306365868095, 0.9855262609219816, 0.014523544897797624, 0.9994173858095482, 0.08202890623199653, 0.3173763624052091, 0.22405840205370633, 0.0018692914288792775, 0.024447399667891726, 0.23853624743424193, 0.037935620174314746, 0.0149909842041495, 0.011252401346390944, 0.029652093450261482, 0.017813247734026056, 0.9550516191722417, 0.04364952555631818, 0.0342744515887531, 0.0098502430313831, 0.9135093416502388, 0.015013381571996548, 0.0225933083656631, 0.0047237224946037925, 0.08099332885246549, 0.12213279747594004, 0.018427053654264638, 0.7015136472565398, 0.0034282890519562116, 0.07285114235406949, 0.8680094903670941, 0.13168085685246314, 0.9984042559128088, 0.10982467442903186, 0.13804904671752916, 0.06942285119348128, 0.07621339237579447, 0.12894441049543326, 0.0859250043460301, 0.19506683105840478, 0.010204779765599161, 0.06980221103606861, 0.011456667246137347, 0.027958820398686177, 0.004704062048082884, 0.00015174393703493174, 0.014036314175731188, 0.03315605024213259, 0.002541710945335107, 0.0024658389768176412, 0.01820927244419181, 0.0017829912601604481, 0.8604693000209881, 0.13932575085809923, 0.13286462089820666, 0.027284698934453153, 0.7809750781963041, 0.0510105240948472, 0.007513177967458115, 0.07219633353930173, 0.013751682578914615, 0.8474474389256131, 0.06617997241102659, 0.9995521008942082, 0.007118710299067603, 0.9669581489566828, 0.02491548604673661, 0.05938825263731839, 0.008908237895597759, 0.028951773160692716, 0.17593769843805573, 0.03971589395120667, 0.0014847063159329598, 0.6851919648030609, 0.8959848376635522, 0.09517625498896429, 0.008410924859489867, 0.030073313270433683, 0.08546086330049169, 0.0258205214948168, 0.006142921453668833, 0.5333878446831241, 0.09535029179458492, 0.0034089838836294075, 0.0258205214948168, 0.027609394225830253, 0.02443667655195734, 0.006379187663425327, 0.062104260850278314, 0.073985075969462, 0.9986843397911823, 0.9964634583725577, 0.9996706683328392, 0.09370343491100588, 0.15108826540610293, 0.05935866769161384, 0.11415956585672528, 0.3239246279229181, 0.01726210348226497, 0.05085322377207788, 0.0542266909806702, 0.03796945007117741, 0.04927415401486445, 0.032945137207316504, 0.009617970339390875, 0.0055267441502469955, 0.01058143716892805, 0.08173248020137527, 0.06859690302615426, 0.04123111724444378, 0.048711098691444646, 0.00018243857187806982, 0.04342038010698062, 0.04560964296951746, 0.6596978759111005, 0.14985329051287039, 0.04206702185793985, 0.39234620784636326, 0.1436102763128375, 0.000251396544967768, 0.11268850128180201, 0.012444128975904516, 0.03215780804379366, 0.022751387319583004, 0.0021578203443066756, 0.011522341644356034, 0.019587980795405257, 0.03823322454718139, 0.017346361602775993, 0.002576814585919622, 0.00035614510537100466, 0.024252087048947935, 0.9750765587032889, 0.9959497007799192, 0.999080285440866, 0.998407826739977, 0.99823402737484, 0.9994810240803509, 0.11047778029974296, 0.2101814117467246, 0.6791134141954788, 0.09850540128954552, 0.9009499860634456, 0.9960534517994838, 0.9975901837409281, 0.037875222450740445, 0.9621087434909738, 0.03260612666816041, 0.09165777542662604, 0.09120699948190493, 0.06491173603984007, 0.16077675361719648, 0.4611437914496972, 0.08083915275331936, 0.014725347527556314, 0.001953362427124817, 0.998901707137284, 0.0065833354629627645, 0.01175595618386208, 0.5920299534192943, 0.3893572688095121, 0.017322324334687444, 0.20222169136285437, 0.13962012683686367, 0.0001644524462153871, 0.034315743776944116, 0.025216041753026025, 0.2540242119207013, 0.06994710712361132, 0.01238875094822583, 0.15425639455003312, 0.04703339961760072, 0.043470263282934, 0.9993119285078671, 0.9980798242953539, 0.07694304389403482, 0.9228371308163055, 0.05747177324056766, 0.23347907878980612, 0.7088185366336678, 0.005141622672369678, 0.9936185814354404, 0.9962408311280795, 0.08753156319409468, 0.03992667794818353, 0.7916231723957159, 0.005374745108409322, 0.07524643151773051, 0.9965931142866676, 0.006058580322059542, 0.7060999975345758, 0.24840179320444125, 0.039105382078747954, 0.7682598046149652, 0.09956741332816652, 0.13197100938171183, 0.11982287273726581, 0.00682630936189112, 0.016461675231109116, 0.07466653425926924, 0.10006886245993488, 0.1156545953392969, 0.2210697266357571, 0.08677870264032385, 0.044401215760973216, 0.0039266381285214405, 0.017760486304389287, 0.009846800229984536, 0.11178836702813733, 0.007702251713638211, 0.03056736758510537, 0.01685433904396126, 0.015797167240128567, 0.05533225285217574, 0.03713085388764425, 0.8736671502975117, 0.0162599164083148, 0.017473343005950232, 0.09236831208849952, 0.0433332822143578, 0.8381569059882364, 0.025087689703049254, 0.9962985196915275, 0.9995377694734374, 0.9981728927402618, 0.9979431512565788, 0.9992067892686219, 0.9972489822613229, 0.9993601975311677, 0.9939193694279436, 0.014583546384529432, 0.03645886596132358, 0.08798739651999424, 0.043750639153588296, 0.1424326363555708, 0.031111565620329455, 0.582369618955542, 0.06076477660220597, 0.9963690088456678, 0.9984866721296632, 0.9998730246641764, 0.9983479206543138, 0.99205510262709, 0.0076984875688874705, 0.01908642755705179, 0.9805652157435356, 0.9999143778657889, 0.9977905300006065, 0.9963061896260165, 0.4303611482126293, 0.01184748856229879, 6.757122754162808e-05, 0.05788601826066139, 0.05664721242239821, 9.009497005550411e-05, 0.4040308932139082, 0.0006757122754162809, 0.011374489969507394, 0.0012613295807770576, 0.023154407304264556, 0.00018018994011100823, 0.002319945478929231, 0.00011261871256938014, 0.9987207541192927, 0.9982710180696647, 0.9999347567259742, 0.07942829326325027, 0.6540576741554065, 0.009152231322514434, 0.0003268654043755155, 0.22275877308191383, 0.034157434757241374, 0.9967123238864894, 0.9981291392429048, 0.9980120780792167, 0.021300722037753857, 0.8307281594724004, 0.14782701094201176, 0.07964343537094783, 0.07240312306449802, 0.07710932606369039, 0.004706202999192372, 0.025703108687896797, 0.08453064617780144, 0.6054711166268647, 0.050320170529826125, 0.02415041132881288, 0.007187622419289548, 0.013800235045035933, 0.8881026261274165, 0.06641363115423542, 0.0017857409908887307, 0.10995062386757756, 0.029209620493822808, 0.021683997746506017, 0.08354716778800847, 0.34375514074608066, 0.13801226801011476, 0.08724620269770655, 0.0015306351350474834, 0.18316600449401552, 0.9945690490844054, 0.005387623156370832, 0.996268414776657, 0.9949085424975838, 0.9986310436222218, 0.09389936588269016, 0.004964255752401574, 0.014377608641389464, 0.059290073420192387, 0.05207785279877877, 0.31448091865449596, 0.04102535885946961, 0.10092425609835276, 0.0021074670646987815, 0.06224052731077068, 0.2545820214156128, 0.8469705287422431, 0.006976692987992118, 0.14558032701610218, 0.9978628849016947, 0.018863828586814468, 0.9803295918710144, 0.9991572366845809, 0.9988783210006817, 0.22192339898857302, 0.7604399008993366, 0.017172643969353866, 0.997958806723761, 0.0638386695355188, 0.011567665894517456, 0.803550695025571, 0.019176344531018245, 0.028393361741088304, 0.0009897468145041674, 0.035136011914897944, 0.03457927933173935, 0.002783662915792971, 0.9995024290168798, 0.997229752263393, 0.0024683904758994878, 0.0044204565873518535, 0.03025249976968925, 0.7797961698625379, 0.10042724809389993, 0.019201358301309614, 0.02389809342537096, 0.04171805904313312, 0.45366765182138313, 0.30558816886649104, 0.05203826791179671, 0.042964368254907785, 0.06231473258345404, 0.019787660697552948, 0.020252288089622563, 0.04028592799474178, 0.0030884056061097837, 0.997144698758404, 0.06624638989457798, 0.08464976990454141, 0.00829163275174177, 0.4089623951821625, 0.06546634082037231, 0.026781684881061397, 0.01626546773251086, 0.09461706363050278, 0.08834778033040534, 0.07253011854790145, 0.05321668128469805, 0.003105750943596656, 0.0016323249145414984, 0.008956119000139194, 0.0009389479596920124, 0.20676525427103298, 0.00292628665262542, 0.4195370969342971, 0.0011551131523521395, 0.005121001642094485, 0.06865222502146216, 0.014862455893597528, 0.018173780263673663, 7.700754349014264e-05, 0.03680960578828818, 0.03765668876667975, 0.15570925293706842, 0.020060465079182157, 0.012475222045403106, 0.1019734933692322, 0.06022413240722861, 0.07756687128840797, 0.08014790553443206, 0.023863246450082313, 0.12361795599378504, 0.07127277023231417, 0.0004075317230564342, 0.01743330148630302, 0.09337004588248526, 0.015893737199200935, 0.09839627046684794, 0.018746459260595972, 0.006475226266341122, 0.018746459260595972, 0.06013356980210496, 0.004120598533126168, 0.057914785976575484, 0.06968792464265025, 0.9993056703772067, 0.9976525701556129, 0.30050627532221724, 0.5033426564556026, 0.038339717236405474, 0.01563575060479106, 0.04605049835657641, 0.007496592755721741, 0.03534108013411678, 0.012422925138053171, 0.0404816008808974, 0.22985947186450295, 0.15836835823524578, 0.009946589722331433, 0.43562954674523446, 0.13490062310912004, 0.031238508346697155, 0.8570645612718787, 0.06312379583446893, 0.07976107535673208, 0.9985231266834785, 0.08519048427193784, 0.2674164311084186, 0.06377616391043019, 0.030458515609555863, 0.0060100136164449305, 0.004726321387689703, 0.24576871215986454, 0.0043178738603584935, 0.051464388443732315, 0.05613236018466042, 0.1056712102852599, 0.026315690689482172, 0.010911383944419437, 0.04171999743454491, 0.00011669929352320253, 0.14910490948929433, 0.10334529336891524, 0.17560494034381768, 0.054255072277749054, 0.0018825158530535705, 0.12448739448782457, 0.016942642677482134, 0.09325693918203841, 0.030168523286114912, 0.007143906314152011, 0.06482612283720372, 0.08649918996594867, 0.009171231078978933, 0.059130305640785225, 0.022493650962127278, 0.0015928980295068674, 0.0058360609338627915, 0.9938811770368334, 0.9982116133472229, 0.8315639746874126, 0.05838143810034171, 0.08789060135833261, 0.005095107325120731, 0.01698369108373577, 0.9987950566390696, 0.004183754150917964, 0.037653787358261685, 0.958079700560214, 0.07933274897324549, 0.6450549283326773, 0.027368066239678576, 0.24804475224822609, 0.9968399867505392, 0.9960443616933758, 0.9986524863197919, 0.15494104515686663, 0.0163095837007228, 0.12667110007561377, 0.07149034188816829, 0.6303654100329363, 0.9990100698337431, 0.9987853372462759, 0.9969173374714239, 0.2490494963301136, 0.7502811870573863, 0.9992119624131504, 0.9976086312044073, 0.025842657253039608, 0.9734067565311586, 0.04887819255713993, 0.010473898405101413, 0.04339186482113443, 0.8972639633703544, 0.08123255163304008, 0.9172508955230776, 0.9964345242218385, 0.9998900456304894, 0.998216295531265, 0.005978839292773417, 0.2484735270790835, 0.1114877679887749, 0.04906165184364069, 0.020750089310213625, 0.13628236623233525, 0.011605982156560163, 0.4079678576245391, 0.008089017866693447, 0.9980767816057431, 0.997613901634497, 0.9986550001287161, 0.9990603665699992, 0.9957268485679427, 0.13912194294281474, 0.2932975087248639, 0.14530881650531327, 0.1274429784103977, 0.042150143949856354, 0.0022497722045449232, 0.04420140684223555, 0.009429192327872106, 0.07817958410793609, 0.0932332069471705, 0.012737680863967581, 0.009429192327872106, 0.0005624430511362308, 0.002547536172793516, 6.616977072190951e-05, 0.12554494004722874, 0.8744587961767523, 0.9970092715356609, 0.9998306315300444, 0.006934874650755255, 0.32121424893333406, 0.002324326119209179, 0.21200902503737495, 0.0775410434850931, 0.11335852794503783, 0.00030482965497825295, 0.16841838437548476, 0.08546661451452768, 0.005448830082736272, 0.007011082064499819, 0.9996852165349163, 0.9977931461700764, 0.9960286259561273, 0.9970978782753653, 0.16447653058779937, 0.0324904408114976, 0.04099261223880538, 0.011538661222774848, 0.11154039182015686, 0.02196394285387844, 0.007186359182605388, 0.0750012979480365, 0.027834489791781433, 0.06376628570480837, 0.013866636732632932, 0.1254070285527898, 0.05273370611461137, 0.04777410611534849, 0.1659947754855329, 0.037348824484244904, 0.10001468113484945, 0.899315683837034, 0.8096998061879656, 0.18959158606429963, 0.13528807963723094, 0.39002030429491463, 0.35457632987203586, 0.12005878041506915, 0.9981106213693076, 0.8413483812528897, 0.15790885790577233, 0.0005356140672109469, 0.06284538388608443, 0.3504701379783629, 0.5432912021743037, 0.028209007539776534, 0.014461579814695565, 0.0006843940144940027, 0.7418831117114989, 0.25664775543525103, 0.027030119518522036, 0.08945018933449045, 0.14880498786485327, 0.013375729246278946, 0.02006359386941842, 0.5394877462665841, 0.10226859652884111, 0.054896222114936506, 0.004458576415426315, 0.9756617167534462, 0.0032616282039896797, 0.00804534956984121, 0.013046512815958719, 0.8158414823564595, 0.09892015523979117, 0.08509797866588095, 0.9961534238669236, 0.9961359127892729, 0.06739795445250865, 0.08153235959243049, 0.23996546579358827, 0.029386785827634106, 0.002315806491851601, 0.36062696955868373, 0.2188037857818409, 0.9010587223690294, 0.013832221280803522, 0.08503951426482165, 0.999038690103803, 0.3858594426692839, 0.6140996789124669, 0.3120301982977837, 0.5968206388204562, 0.09104459580690348, 0.10827906839959636, 0.07880665924941037, 0.8127337175437159, 0.7862336783945676, 0.21329697114597151, 0.998902101346116, 0.9998445503143125, 0.9996780412382253, 0.010963756918621906, 0.7722139456349362, 0.08149725976175616, 0.03983498347099292, 0.09501922662805651, 0.0218265840132455, 0.03735079981884474, 0.16052502552416648, 0.015663238633709085, 0.04810189852600601, 0.017841262940763308, 0.07224552967441557, 0.0907819067557281, 0.31043797516928157, 0.22526332248065048, 0.9992574661408892, 0.9981325496547064, 0.9993094355431308, 0.021338262552483736, 0.06103735567338371, 0.06153359433739496, 0.6247644779901634, 0.011165369940253118, 0.013150324596298118, 0.1535858665114818, 0.05309753704920372, 0.12218390397804033, 0.051498179219385584, 0.07923561551708555, 0.057860888621008515, 0.030819373664111065, 0.02187181356807882, 0.06491951936343396, 0.059650400640214964, 0.02246831757448097, 0.08182046621149486, 0.039568099091342596, 0.02376074292168563, 0.040065185763344384, 0.06163874732822213, 0.018591041532866996, 0.013421340144048367, 0.0030819373664111066, 0.18034304460224992, 0.02714093229129781, 0.023981979862054924, 0.00017441439899676308, 0.007499819156860813, 0.8280323592371328, 0.00967999914432035, 0.11546233213585716, 0.015086845513220008, 0.09448164240999392, 0.24185272341877365, 0.049672974837385704, 0.049039188874548244, 0.08537096919420548, 0.07263187134117259, 0.07462829712411058, 0.07434309344083373, 0.030152367181992025, 0.06369548926516444, 0.025747554740271697, 0.025573263600491395, 0.047106141687894, 0.026111981668903234, 0.010932807858946136, 0.002836192183697621, 0.0021548722736473543, 7.922324535468214e-05, 0.016003095561645794, 0.007589586904978549, 0.9995744304804776, 0.9985209759087408, 0.9239919387122948, 0.05558126720554377, 0.020143546504022575, 0.9990561000787811, 0.9975988544416734, 0.9998945090400787, 0.9982989688196923, 0.9990852284549886, 0.9382636354881554, 0.06053313777342938, 0.9987401329819022, 0.9976086322134482, 0.9983558927578223, 0.7882822419041515, 0.054094672065892184, 0.15749687707680113, 0.9966673672682149, 0.0028681075317070932, 0.009752268994893754, 0.010325931876946328, 0.8151749553967073, 0.16464124714908868, 0.00028683144102628687, 0.9956414514954623, 0.02368684526266338, 0.31707787573829815, 0.19037205266659088, 0.0774522241922009, 0.3870104665137805, 0.00451178005003112, 0.9967809027718315, 0.8534708368859432, 0.1459998335180522, 0.9990421887991803, 0.01767039286385287, 0.09078925988669234, 0.0968824988052623, 0.7714040470909563, 0.006702562810426951, 0.016451745080138882, 0.9290612382604493, 0.022588611826233347, 0.048105377037348795, 0.01907879539615843, 0.9793781636694662, 0.9984839451403348, 0.010803573567246264, 0.154989728483956, 0.14626376521810325, 0.6872734877009739, 0.14431143041242128, 0.032453844920334624, 0.22458060684871559, 0.5984489003309704, 0.04802020821560213, 0.9508001226689222, 0.019360582691952864, 0.06124762952234145, 0.00827999762926286, 0.05284586722206002, 0.02410940486167715, 0.007062350919077145, 0.6015174748317431, 0.0006088233550928573, 0.011445879075745718, 0.08730526912031575, 0.05710763070771002, 0.006209998221947145, 0.06283057024558288, 0.995853123677137, 0.15157736193985782, 0.02286531633658195, 0.11871793382702152, 0.1408261204835842, 0.16793136302827405, 0.0030285187200770796, 0.012189787848310246, 0.00022713890400578098, 0.13052915683532212, 0.25174561860640726, 0.00022713890400578098, 0.9964931050200232, 0.002807022831042319, 0.9996718207600868, 0.9979564781813263, 0.9994763882426856, 0.9967335640753433, 0.28760362717193705, 0.2985670844845231, 0.26554462269962525, 0.001122763700686527, 0.11551257132357269, 0.012020176089702819, 0.0035664258727689684, 0.0005944043121281614, 0.015454512115332195, 0.999517843328762, 0.05834730406949977, 0.10623788026228113, 0.4880012589566752, 0.2207050197411513, 0.03904257568171193, 0.08761376729842171, 0.99395900995888, 0.7429069334643992, 0.08760990856222439, 0.10433733740465387, 0.06502787962494459, 0.996493620944943, 0.9983117287033394, 0.2129514557604586, 0.0007178138958217705, 0.07231975000404338, 0.11389313813705425, 0.08865001613398865, 0.029609823202648034, 0.001973988213509869, 0.0016150812655989835, 0.005622875517270536, 0.05646802647131261, 0.037146869108776626, 0.006639778536351377, 0.28682646920544913, 0.008195041977298546, 0.032062354013372416, 0.010886844086630185, 0.03433543135014135, 0.028819030443974415, 0.9674960220477126, 0.0033450660336756016, 0.9976026001131202, 0.9975639616650954, 0.09267355722815034, 0.07130751786720478, 0.08258039753003495, 0.20527127386037258, 0.18980383432300096, 0.06462243806715433, 0.04915499852978271, 0.0069472397922092895, 0.02372547929037512, 0.00235943992942957, 0.014680959560895102, 0.01441879956873626, 0.014943119553053944, 0.0005243199843176822, 0.012321519631465532, 0.002621599921588411, 0.15192171545604843, 0.002478656662928181, 0.02567888302793596, 0.4685652555599434, 0.2645222390676955, 0.11500966915986761, 0.1237345406133748, 0.036325031923472494, 0.01210834397449083, 0.049190147396369, 0.9013148546011612, 0.9987566813347699, 0.9962437558749648, 9.099288464153804e-05, 0.09363167829614265, 0.6960045746231245, 0.0004549644232076902, 0.1468625158114424, 0.036488146741256756, 0.009099288464153804, 0.01728864808189223, 0.9958806107558874, 0.14946469355256944, 0.23345718021633005, 0.0993360460656503, 0.12293907843750132, 0.07265159493192908, 0.012548045473595096, 0.04539533413105669, 0.0494297690048455, 0.03630991386409923, 0.05927760216133785, 0.036151077845446127, 0.013215156751938127, 0.014739982531007912, 0.0009530161119186149, 0.016677781958575763, 0.009911367563953595, 0.000571809667151169, 0.016804850773498244, 0.01026080680499042, 0.9977693272134215, 0.009757844314046379, 0.018270006375235775, 0.9481718081329747, 0.023667962804282707, 0.9970123747439714, 0.04800023110671375, 0.782575196436244, 0.16928652934957084, 0.9927745608526246, 0.006897085220471851, 0.9969273856864905, 0.08963040020155326, 0.025367094396666016, 0.8844660246304218, 0.06759075601155279, 0.049112707605516774, 0.034038510221645286, 0.8344297648620473, 0.015074197383871486, 0.7048362203615892, 0.2947361597288166, 0.9996899513551099, 0.15744244559540474, 0.02145324896392018, 0.056734184463826824, 0.0432623575078106, 0.03263740719155629, 0.6078081625891698, 0.0806276134046858, 0.3792950053912867, 0.0072970582199526094, 0.12298583541545127, 0.022955328983600917, 0.01976286601237165, 0.0287321667410634, 0.010489521191181876, 0.25646119202208445, 0.1518700242027637, 0.9985923683176545, 0.99878829708167, 0.09993324417417901, 0.13359878749825457, 0.029749781503029253, 0.10741447602397358, 0.1822893466276868, 0.033978303852913144, 0.14776058424401955, 0.0542201652792804, 0.0276104994857803, 0.0016138443288018392, 0.1322601724348298, 0.001488740117266813, 0.0180775585668113, 0.025258540308921808, 0.0012885733788107708, 0.00242702170377951, 0.0010258545345872155, 0.039586808752983864, 0.40563686524796627, 0.06586947261366058, 0.16886030055620613, 0.0670324223420091, 0.024235872338783306, 0.05735668060214936, 0.032888218317696345, 0.012745929022699857, 4.6517989133941084e-05, 0.03595840560053646, 0.08875632326755958, 0.001069913750080645, 0.9975901547814316, 0.9980249206145873, 0.8824804218497007, 0.11723534752151292, 0.9967467472486443, 0.9987907965488438, 0.9966833010636442, 0.07872131115769297, 0.008682497554157313, 0.0032800546315705404, 0.11403013454459937, 0.674533587762977, 0.015435551207390779, 0.10515469260034968, 0.9985139194321255, 0.10774933749083002, 0.032709620309716254, 0.008081200311812252, 0.6718940830678186, 0.006926743124410501, 0.0346337156220525, 0.0019240953123362502, 0.13622594811340652, 0.005179382989107075, 0.9799392615390585, 0.013984334070589102, 0.10279612317662831, 0.1745887686435449, 0.0924539009937327, 0.07385645213570069, 0.06351422995280509, 0.03645285486886075, 0.02782660677012271, 0.07800725431224399, 0.046168978399428594, 0.052429964922706206, 0.0348992026575289, 0.04039495749462813, 0.055305380955618884, 0.03169914287896479, 0.026829486694193314, 0.01579159934204464, 0.01282342795323155, 0.017391629231326693, 0.01674234174002383, 0.9989384267688672, 0.9969472638145634, 0.9974120174562523, 0.9983989216699225, 0.045382092616279665, 0.8361306760817587, 0.11758087632399732, 0.04331689704906514, 0.2125902403663976, 0.012051600927800317, 0.12024054411393917, 0.6105685361478721, 0.0011707269472720308, 0.9963978232461076, 0.05085016207019663, 0.18433183750446278, 0.20054032666433796, 0.5641189854662438, 0.10980626498181223, 0.010675609095453967, 0.09313924261850144, 0.0660144807331133, 0.05555674121103595, 0.08594954669707326, 0.028323044538959504, 0.19085374627791174, 0.23638848711362356, 0.041722023301621114, 0.044881132115581986, 0.036819957900647356, 0.01588003794588752, 0.9839952084326731, 0.12682189148389575, 0.1798086260088795, 0.008043595506515573, 0.13944636873627445, 0.2022801955181136, 0.12072607246774718, 0.010352071346950535, 0.0016952869453194257, 0.0006131888951155369, 0.034987836956592404, 0.09453929965281307, 0.010243861541930147, 0.037909501692142904, 0.0007213987001359258, 0.031813682675994326, 0.9994129335940752, 0.9945371035920292, 0.9925086242716817, 0.204670712653648, 0.06851487562786508, 0.6108660467331338, 0.04229744872944732, 0.030412215202164604, 0.022721769978628726, 0.020449592980765853, 0.9989206079278311, 0.9978244393858916, 0.9976664452286697, 0.7385453433154173, 0.22769770053046753, 0.004907278028673869, 0.028462212566308442, 0.9974068626673791, 0.02164592220264524, 0.0011180744939382871, 0.4297878354698776, 8.944595951506297e-05, 0.4109147380121993, 0.036046721684570376, 0.08667313477009601, 0.013014387109441663, 0.0006708446963629723, 0.9988620433694909, 0.9988157193983197, 0.03368887494382632, 0.05756959642299435, 0.9083202991183553, 0.008351135434765273, 0.025053406304295818, 0.05547539967379789, 0.023263877282560404, 0.026992062744509184, 0.051001577119459345, 0.029079846603200503, 0.780831163150553, 0.009039950695118659, 0.989372381632431, 0.4547470759423128, 0.09762372058604524, 0.0012604353718456503, 0.0013804768358309503, 0.08330877600579821, 0.022237681203276828, 0.02505865560693138, 0.07115457777728659, 0.10758716209682515, 0.0007202487839118001, 0.034151796503817854, 0.02547880073087993, 0.06287171676230088, 0.012454301888474878, 0.9982415196566048, 0.04839540086499913, 0.036906878404465215, 0.03791212411976193, 0.014217046544910723, 0.8541716449406969, 0.004451802453456893, 0.00380557306505186, 0.07157423200047922, 0.9282895074347868, 0.01863351955260302, 0.6197670633800569, 0.3490139227504948, 0.01247635657000376, 0.9994318052217406, 0.052272533339525355, 0.0005375067695581014, 0.6702709416389524, 0.14673934808936168, 0.13021101492545004, 0.998173657497153, 0.9948395956761565, 0.4731843021951984, 0.2834006059336908, 0.2433311115214723, 0.9372389330282989, 0.06220347736754504, 0.9980701418222702, 0.9997980157622154, 0.9992944650289158, 0.9995018743977595, 0.9978958782741978, 0.9986093924532029, 0.7400880493674463, 0.05188027813877664, 0.08660830105616181, 0.06733848346175907, 0.05315081556258341, 0.0006352687119033874, 0.9994040299656259, 0.994584591387017, 0.007867949347041395, 0.15718016991021333, 0.04828059826593584, 0.0030398895204478116, 0.0013411277296093288, 0.44087338898024, 0.028878950444254214, 0.004381017250057141, 0.0062585960715102005, 0.0037551576429061206, 0.09727646465432997, 0.20072211686486285, 0.03266268958043843, 0.2418295286243999, 0.025125145831106484, 0.6683288791074324, 0.006909415103554283, 0.02481108150821765, 0.06371457311625146, 0.004344175439744418, 0.02920251267828192, 0.6772086824401576, 0.01713535867899187, 0.025582366478494906, 0.011584467839318447, 0.13684152635194916, 0.03451206043796954, 0.12838541467713516, 0.011111949000680226, 0.03344457448737023, 0.010851003035889302, 0.06277925002928339, 0.4017915492868269, 0.004870991342763935, 0.0032618245598865637, 0.07028144651702249, 0.21645467779407235, 0.041729608869482106, 0.015026138472544102, 0.461506990805533, 0.1050227519515361, 0.3116936202028062, 0.028019702078598725, 0.04468835696477242, 0.0005113084320912175, 0.009203551777641917, 0.018202580182447345, 0.0049085609480756884, 0.01605508476766423, 0.08999504247237135, 0.9083220565816084, 0.9951085471452914, 0.9975406432563424, 0.04073013982188176, 0.0024827268095710467, 0.1973432309986067, 0.2810849352781923, 0.0212373793305199, 0.0955178814439023, 0.0013084641293685246, 0.16057203392712202, 0.061564914804903656, 0.05616330647597206, 0.006206817023927617, 0.01274913767077024, 0.02824940504944353, 0.008555342384332662, 0.0001342014491660025, 0.01539961629179879, 0.010702565570988701, 0.9977423135808772, 0.6963516100263735, 0.3033954671799853, 0.9952962490529852, 0.06626677531793025, 0.2971512261265669, 0.42954487505521155, 0.0631423038567752, 0.09434038456592041, 0.015202652184127561, 0.02327031730024433, 0.011052234870055926, 0.0769905563789573, 0.05499325455639807, 0.01649797636691942, 0.06834875923438045, 0.01256988675574813, 0.7706911817118073, 0.0637097387103887, 0.030051763542636178, 0.02344037556325622, 0.04928489220992333, 0.8324338501310221, 0.014241249554177143, 0.10825413610385379, 0.0678007315731477, 0.2006158632849302, 0.011042128277514163, 0.06336324077003454, 0.3528321175777656, 0.001547961908062733, 0.03250720006931739, 0.0009287771448376398, 0.021052281949653168, 0.11238203452535442, 0.013312472409339504, 0.9989979905691811, 0.025653985641551653, 0.9737112772393383, 0.9997426074322975, 0.052686194208965316, 4.530197266463054e-05, 0.10999318962972295, 0.00018120789065852216, 0.029672792095333002, 0.009196300450919999, 0.1164713717207651, 0.42153485564438714, 0.05422646127956275, 0.03909560240957615, 0.042402646414094185, 0.005708048555743447, 0.11873647035399663, 0.05759516192962179, 0.2209441522610915, 0.0024404729631195676, 0.035061461570151116, 0.06613681730054027, 0.0163511688529011, 0.03351582869350873, 0.0763054546468718, 0.02139481297668154, 0.026926551693085894, 0.22338462522421107, 0.058571351114869614, 0.049378902953785914, 0.008460306272147833, 0.06996022494276093, 0.03359717779227938, 0.9978108328168942, 0.9982003714044486, 0.9980963087827018, 0.718430778461708, 0.16899755406071046, 0.11241013776888886, 0.9991705775276123, 0.06555762597765598, 0.9342575537265206, 0.9979215544031704, 0.07368114871899648, 0.92627729818167, 0.9982660518420365, 0.9994563906543195, 0.9977229855626374, 0.024109930963709707, 0.04309412857292995, 0.0011390518565532145, 0.14655800554318027, 0.7067816769912696, 0.02297087910715649, 0.0550541730667387, 0.9315929887481579, 0.0682031472627603, 0.9986411374605683, 0.05086315481186007, 0.9491256624326342, 0.7913876754352042, 0.20753970739078842, 0.997199901370698, 0.013189089761131841, 0.985884459644605, 0.9978717523934418, 0.999748458334859, 0.41065775383914127, 0.5888133963898643, 0.9988198834416906, 0.9943690011066005, 0.02430557682786916, 0.02048612904063258, 0.007638895574473166, 0.9472230512346725, 0.012133109933733927, 0.9871939446083513, 0.04162050093470735, 0.04515688336706811, 0.07154373690083682, 0.010065088461334458, 0.5339937472864741, 0.27338956496327377, 0.02421061819077748, 0.022388178986561036, 0.0239321913304618, 0.02316018515851142, 0.01389611109510685, 0.7835862645296363, 0.13278506157546546, 0.922336357051944, 0.07768860284012631, 0.99982900521423, 0.9964729492451878, 0.997915845243409, 0.05290967441397095, 6.703083751769968e-05, 0.05585903126474974, 0.007507453801982365, 0.013875383366163835, 0.09382082891227365, 0.053825762526712846, 0.13475432702308227, 0.08419073192223081, 0.01479147147890573, 0.0433466082614458, 0.012490079390798041, 0.004669815013733078, 0.04888782416290897, 0.06848317233058318, 0.04779298715011988, 0.173431120270795, 0.08928507557357598, 0.03886085684278928, 0.026396053704536116, 0.20896875849424423, 0.013198026852268058, 0.7119602263084602, 0.05981351507208751, 0.04785081205767001, 0.05937509140140205, 0.23574667092286636, 0.06332090443757117, 0.2806537811916483, 0.010021112472810472, 0.021044336192901993, 0.017536946827418326, 0.03319493506618469, 0.07785151752314635, 0.07828994119383181, 0.0018789585886519636, 0.007453202401652789, 0.006137931389596414, 0.99632625879739, 0.9984089431281449, 0.999750224800479, 0.04550006805709786, 0.07374967552906993, 0.06385835638622256, 0.09661840538733302, 0.0895757861576257, 0.01709219947884024, 0.10769668282732206, 0.16387937555869508, 0.3419231201299476, 0.013048679479872491, 0.0001842166514805528, 0.03104050577447315, 0.012925868378885456, 0.06131344216777733, 0.05996252005691994, 0.07402439111993547, 0.0027632497722082923, 0.7002688978280748, 0.037610899677279534, 0.006908124430520731, 0.9986428881037653, 0.9993209553011, 0.15386741386362643, 0.8457132856200047, 0.06522750264980114, 0.1156236937922229, 0.20506558257652097, 0.07657799615034658, 0.2745306027998591, 0.04176981608200722, 0.06220070438298902, 0.15890690900763618, 0.9998551208215479, 0.9973540520413922, 0.9972391860560158, 0.2912753539571301, 0.04023760961093498, 0.07652219656102319, 0.04527251215790822, 0.4779828558436505, 0.0026630889504651897, 0.017018802824066603, 0.04115304643765738, 0.00016644305940407436, 0.003453693482634543, 0.004244298014803896, 0.24492482369828664, 0.07397058433840871, 0.06739542128610572, 0.44546729679352803, 0.010410674832813079, 0.022647783846821434, 0.10976869428983614, 0.02209985359246285, 0.0032875815261514986, 0.008421406015318988, 0.407736407908361, 0.17287275125890925, 0.029240993108746487, 0.006549982456359214, 0.374752567681695, 0.9991250013095737, 0.07191949933766766, 0.053383545900124445, 0.03791926474651697, 0.10210662350738088, 0.11990113880742236, 0.033894314857221865, 0.049782274946544615, 0.026479933482204582, 0.019489231042902573, 0.194150872291524, 0.021183946785763668, 0.010380133925024198, 0.024361538803628218, 0.009956454989308923, 0.00444862882501037, 0.02605625454648931, 0.18567729357721854, 0.0070966221732308285, 0.00190655521071873, 0.9432943473805767, 0.011259084723671726, 0.035385694845825426, 0.010062105616836193, 0.02677159455667532, 0.4857226587714821, 0.026573286448848092, 0.001388156754790572, 0.000925437836527048, 0.003305135130453743, 0.33533901033583674, 0.0001322054052181497, 0.0032390324278446683, 0.08236396745090728, 0.014939210789650919, 0.01632736754444149, 0.00218138918609947, 0.000925437836527048, 0.9979907267438947, 0.9680955981122225, 0.029515109698543367, 0.9977175363819667, 0.9991476216513059, 0.30080372528167154, 0.05692989022923487, 0.01838244987832437, 0.10728666201712951, 0.001893949381403117, 0.057932569313507105, 0.07497811374613517, 0.029189102231036275, 0.0003342263614240795, 0.21312500980142135, 0.02506697710680596, 0.1139711892456111, 0.026297748658893557, 0.0007023137624036855, 0.06114811824661422, 0.06918570908301196, 0.05929088851936892, 0.05493654319246607, 0.00010924880748501776, 0.018790794887423055, 0.07474179129225, 0.032431288850552416, 0.05020763052561459, 0.1207667531884382, 0.028716829396061808, 0.26492835815116805, 0.1035366555508011, 0.034210483715308417, 0.9975084517722381, 0.9991111316647113, 0.0057867098917177345, 0.9936607556921024, 0.02563768656593587, 0.036869434966250635, 0.40104666842428255, 0.11243956822489018, 0.01098757995682966, 0.1042599253681392, 0.004028779317504208, 0.03357316097920174, 0.14991942429985358, 0.09131899786342872, 0.018434717483125317, 0.011598001065542417, 0.04351353814785333, 0.9562998223227768, 0.23192790991090556, 0.6534271849382974, 0.11415605365325196, 0.9979674812748297, 0.008677643874036255, 0.012396634105766078, 0.9780944309449435, 0.997280788102558, 0.9978790251332591, 0.3230930524294372, 0.5168422085086664, 0.08120663183224401, 0.07880643581749788, 0.5027183999963364, 0.3077361276923435, 0.09554710416254214, 0.07147419739951204, 0.0225011362183649, 0.020495932450564833, 0.019053466616333906, 0.3288822102046517, 0.5810553791053511, 0.009774320727475246, 0.04071198347060725, 0.0013115655566753766, 0.015381086982829417, 0.43198200107589907, 0.015500320215254451, 0.5358341465181039, 0.997421829272393, 0.9972169304769357, 0.9980086140783094, 0.004030470021616931, 0.051052620273814464, 0.7828068441984884, 0.019928435106883715, 0.13300551071335873, 0.008956600048037625, 0.4096550824784422, 0.0735178789408389, 0.06264551656226414, 0.050867123985474806, 0.022133023413527207, 0.3659067671932246, 0.002718090594643692, 0.012296124118626225, 0.9987045868467189, 0.27640675756700855, 0.10289688508776494, 0.38393400248372295, 0.015820396082243858, 0.02726767454825771, 0.1935747650713578, 0.02495144765320269, 0.008949975788648791, 0.034443846216921106, 0.4114276748903096, 0.5201834412917692, 0.9972472941835769, 0.9994828014551653, 0.02703120018497304, 0.9728860908679331, 0.9954684075997143, 0.9981667757325726, 0.01001397161417219, 0.004900454194169369, 0.04644778323169228, 0.06434509420170216, 0.0068180232266704275, 0.10589242323922507, 0.013636046453340855, 0.4600035045744204, 0.0023436954841679594, 0.14573524647008038, 0.03472930581085249, 0.10504017033589128, 0.9970716415523642, 0.99751135593336, 0.9326251334680401, 0.05513717443718766, 0.011430877627221833, 0.997827218226075, 0.9964416646562252, 0.9964939481366066, 0.9970985073409732, 0.9988207522920783, 0.12209179743847486, 0.07582523967282433, 0.049922548106673875, 0.03138667707768548, 0.10315376747197388, 0.05836788579443782, 0.06248087492808909, 0.0906320005539689, 0.027730686736662128, 0.01495300049478551, 0.07580695972111921, 0.08357593919579384, 0.03617602442442607, 0.0771048362921825, 0.025774731904214636, 0.025957531421265802, 0.006196903628034582, 0.019486428517654468, 0.01338092464814547, 0.9997023177692546, 0.9952636694557054, 0.9984720117772102, 0.01674184399826472, 0.042718998680354815, 0.7006097760143388, 0.016969314704762883, 0.21482333521686414, 0.006187203216750006, 0.0019107539345845604, 0.9997835378463463, 0.2146111322432125, 0.5352583376090833, 0.06481095836734624, 0.11017862922448861, 0.00026726168398905667, 0.007216065467704529, 0.0676840214702286, 0.7159909180345946, 0.03638282613016572, 0.09147681998441666, 0.00808507247337016, 0.019866178077423823, 0.01201210767472138, 0.025641229844116792, 0.03638282613016572, 0.027142743303456965, 0.00011550103533385943, 0.013629122169395413, 0.01201210767472138, 0.0012705113886724536, 0.15083657572097908, 0.010233819694011898, 0.11044489475777737, 0.07076225442002684, 0.09316793818428384, 0.10902681350687503, 0.14190266384029432, 0.04830930128073977, 0.013400867821027129, 0.02937791658119351, 0.019900406887662862, 0.04653669971711184, 0.0377918653365474, 0.012408210945395489, 0.03523931908492319, 0.0008981181255714831, 0.051145463782544455, 0.018600499074335714, 0.7511934877589796, 0.2486837747853424, 0.16431649035419976, 0.025466195503280987, 0.154420700966161, 0.07820766050734379, 0.10072058136513196, 0.06831187111930503, 0.11853300226360172, 0.0002473947347009689, 0.05343726269540928, 0.040742820371065816, 0.021229560671526895, 0.00021647039286334778, 0.07972295325738722, 0.020270906074560637, 0.0037263831914333438, 0.00722083381908453, 0.0007731085459405278, 0.00012369736735048445, 0.043263154230831935, 0.019049394571974604, 0.11100124703378782, 0.15863237915649528, 0.5984955297157589, 0.11762818715520798, 0.014082247758017858, 0.011199344527740473, 0.015749078242135037, 0.08084526830962653, 0.2351862350825499, 0.6565615729387851, 0.9992348466970116, 0.998167440432331, 0.9954410977399701, 0.15895718883363869, 0.02108121254348562, 0.03755848211770426, 0.7824279919875294, 0.12965977983570176, 0.06266007319406974, 0.06321046572888252, 0.06742308551456491, 0.10448990583984064, 0.06149578129350426, 0.020936085266532088, 0.14079464419383714, 0.1742204062118899, 0.0430999692645696, 0.018734515127280988, 0.040305668703212436, 0.0001481826055265163, 0.014839429496298275, 0.0376172128600885, 0.020343354844426023, 0.9992760352358377, 0.040002847683390706, 0.04563577879543443, 0.5932048790881124, 0.09795878062227906, 0.0008133109092255641, 0.003765328283451686, 0.05181091718029519, 0.0030122626267613485, 0.005030478586691452, 0.14368492729651633, 0.011958682628242553, 0.0002409810101409079, 6.024525253522697e-05, 0.0028315268691556676, 0.7231221666564231, 0.059237033781761955, 0.16062349544670068, 0.004113682901511247, 0.024935247126083557, 0.01689774361082312, 0.011075300119453357, 0.9999179918276269, 0.9984346471382025, 0.9991204552518862, 0.9992267978940684, 0.16622234215097229, 0.007877074241196946, 0.1533886055471174, 0.02100553130985852, 0.09018446223084667, 0.12284484828533332, 0.028373542930025735, 0.02063043253646819, 0.2265328663582319, 0.008761235635617011, 0.02998110910169858, 0.07839564363857912, 0.045762050353620354, 0.9997544891227085, 0.9988736432653347, 0.028027032535873846, 0.09342344178624616, 0.023535520911535088, 0.009162683713651065, 0.6794758785299673, 0.0016169441847619526, 0.021738916261799586, 0.055515083676827046, 0.03683039531957781, 0.0019762651147090535, 0.025332125561270593, 0.009342344178624616, 0.014013516267936923, 0.9977893744733766, 0.001917596491620839, 0.051401178696837614, 0.09503569577739482, 0.022593924701906642, 0.025276953260258056, 0.0031066646465121635, 0.023723620937001977, 0.006919389439958909, 0.01906362396723373, 0.07823146428035176, 0.651411091561846, 0.007484237557506576, 0.015674535261947734, 0.9969468646348585, 0.3488626175954225, 0.6251358085483192, 0.0010834242782466537, 0.024557616973590816, 0.45147285972298584, 0.48163179344010154, 0.06678700427385442, 0.9956249422169788, 0.9986115857834243, 0.9571063139572458, 0.042935610345745605, 0.5296277139997562, 0.47014846618475464, 0.9984096994963353, 0.9981569713074705, 0.9971932964309147, 0.9977830439295564, 0.11539759640864496, 0.048348400076349274, 0.7261382351089438, 0.10490690582604087, 0.005017286800375868, 0.9990941996175707, 0.03636775573246689, 0.0345937188674685, 0.9287082988266544, 0.9986720717250822, 0.03453144278912838, 0.006586482472457784, 0.04492514056358489, 0.0975027838841872, 0.03258976298510904, 0.606565541914436, 0.0066245546254777715, 3.8072153019987195e-05, 0.006129616636217938, 0.0882893228533503, 3.8072153019987195e-05, 0.01382019154625535, 0.0377675757958273, 0.00338842161877886, 0.02116811707911288, 0.9988037671143921, 0.9963773898956887, 0.9967930759318754, 0.998086855642581, 0.0014779416374102491, 0.2811200567158232, 0.02566951264975696, 0.6916766863079966, 0.08436651063448011, 0.1574681746785609, 0.07067492847540432, 0.07693650543655714, 0.1548616809196121, 0.0566537896341626, 0.03942696306639767, 0.013362025476909846, 0.04757600102540995, 0.05296874673357984, 0.029330544712768476, 0.0023368564735402873, 0.07939320070361232, 0.055095885318469075, 0.008238917054148448, 0.024177476591628354, 0.029720020791691858, 0.00014979849189360815, 0.007519884293059129, 0.009796821369841974, 0.004358935664578737, 0.4550728833820202, 0.5400721288413055, 0.9971097832326552, 0.9986964818661159, 0.2881675278545158, 0.09105914894160554, 0.10575091990106196, 0.3104289168463825, 0.19267101661804906, 0.011857825292150107, 0.993763837416021, 0.32206340127936234, 0.043949320670808346, 0.10874416893251393, 0.4217745082558208, 0.10335907430486548, 0.031147864262938196, 0.04573610448735229, 0.07491258493618047, 0.7475487423105167, 0.039033399519378245, 0.04455327419888628, 0.01695390080134611, 0.018099977109424674, 0.9358752870108404, 0.009582340822636592, 0.03619995421884935, 0.9992428254240369, 0.005719810265258705, 0.06688278139717281, 0.2790357439631321, 0.015664480385538047, 0.6326890127503209, 0.29353765991512826, 0.04204518205680882, 0.01907605482207067, 0.1401506068560294, 0.5049314919229726, 0.3757813470724317, 0.03512390726304083, 0.05379737694718911, 0.4777740600615655, 0.056731779326126705, 0.0007113702736818396, 0.9984264651906752, 0.9789129986838967, 0.020087134035921272, 0.05509094411999977, 0.2711586378016502, 0.0037906612926605346, 0.6656401229911899, 0.004296082798348606, 0.24789514999516377, 0.15805395469490308, 0.025371819043129178, 0.5606756077071825, 0.007486766275021724], \"Term\": [\"aaron_courville\", \"absolute_discounting\", \"accelerated\", \"accelerated\", \"accelerated\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"accuracy\", \"acm_symposium\", \"acnn\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"across\", \"action\", \"action\", \"action\", \"activation\", \"activation\", \"activation\", \"activation\", \"active\", \"active\", \"active\", \"active\", \"active\", \"active\", \"active\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"activity\", \"actor_critic\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"adaptation\", \"adjacency\", \"adversarial\", \"adversarial\", \"adversarial\", \"adversarially\", \"adversary\", \"adversary\", \"ag_cvae\", \"agent\", \"aggregation\", \"aggregation\", \"aggregation\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"ai\", \"aifnn\", \"al\", \"al\", \"al\", \"al\", \"al\", \"al\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"algorithm\", \"alice\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"alignment\", \"allocation\", \"allocation\", \"almost_surely\", \"amino_acid\", \"amortized\", \"amp\", \"amplitude\", \"amplitude\", \"amplitude\", \"analog\", \"analog\", \"analog\", \"analog_vlsi\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"analysis\", \"anatomical\", \"ancestral\", \"animal\", \"animal\", \"animal\", \"animal\", \"annotation\", \"annual_acm\", \"appearance\", \"appearance\", \"appearance\", \"appearance\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approach\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximate\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"approximation\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"architecture\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"area\", \"arm\", \"arm\", \"arm\", \"arti\", \"articulator\", \"arxiv_preprint\", \"arxiv_preprint\", \"arxiv_preprint\", \"arxiv_preprint\", \"assignment\", \"assignment\", \"assignment\", \"assignment\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"assumption\", \"asynchronous\", \"asynchronous\", \"asynchronous\", \"atari_game\", \"attack\", \"attack\", \"attack\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attention\", \"attentional\", \"attentivechrome\", \"attraction\", \"attractor\", \"attractor\", \"attribute\", \"attribute\", \"attribute\", \"auction\", \"audio\", \"audio\", \"audio\", \"auditory\", \"auditory\", \"auto_encoder\", \"autoencoder\", \"automatic_differentiation\", \"automaton\", \"automaton\", \"axiom\", \"axon\", \"axon\", \"bach\", \"back_propagation\", \"backprop\", \"backpropagation\", \"bag\", \"bag\", \"bai\", \"balcan\", \"bandit\", \"barn_owl\", \"barycenter\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"based\", \"batch\", \"batch\", \"batch\", \"batch\", \"batch_normalization\", \"batching\", \"bayesian\", \"bayesian\", \"bayesian\", \"bayesian\", \"bee\", \"behavioral\", \"behavioral\", \"behavioral\", \"behavioral\", \"belief_propagation\", \"bellman\", \"bfgs\", \"bfgs\", \"bid\", \"bidder\", \"bij\", \"biological\", \"biological\", \"biological\", \"biological\", \"biological\", \"biological\", \"biological\", \"biophysical\", \"bipartite\", \"bipartite\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bleu_score\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"block\", \"blur\", \"bnn\", \"bound\", \"bound\", \"bound\", \"bounded\", \"bounded\", \"bounded\", \"bounded\", \"bounding_box\", \"bp\", \"bp\", \"bp\", \"brain\", \"brain\", \"brain\", \"bregman_divergence\", \"bt\", \"bt\", \"bt\", \"bt\", \"bt\", \"bucket\", \"budget\", \"bundle\", \"buyer\", \"cae\", \"calcium\", \"calcium_imaging\", \"calibration\", \"calibration\", \"camera\", \"candidate\", \"candidate\", \"candidate\", \"candidate\", \"candidate\", \"candidate\", \"candidate\", \"candidate\", \"capsule\", \"caption\", \"caption\", \"captioning\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"case\", \"catastrophic_interference\", \"categorization\", \"categorization\", \"category\", \"category\", \"category\", \"causal\", \"causal\", \"causal\", \"cca\", \"ccd\", \"celeba\", \"cell\", \"cell\", \"cell\", \"cell\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center\", \"center_surround\", \"centralized\", \"chair\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"change\", \"channel\", \"channel\", \"channel\", \"channel\", \"character\", \"character\", \"character\", \"charge\", \"charge\", \"chernoff\", \"child\", \"child\", \"chip\", \"chu\", \"circuit\", \"circuit\", \"clarans\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"class\", \"classification\", \"classification\", \"classification\", \"classification\", \"classifier\", \"classify\", \"classify\", \"classify\", \"classify\", \"classify\", \"clause\", \"cleanup\", \"click\", \"clinical\", \"clinical\", \"clinical\", \"clipping\", \"clique\", \"clump\", \"cluster\", \"clustering\", \"cmos\", \"cnn\", \"cnns\", \"cochlear\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"code\", \"coding\", \"coding\", \"coding\", \"coding\", \"coding\", \"coding\", \"coding\", \"cognitive\", \"cognitive\", \"cognitive\", \"cold_start\", \"collaborative_filtering\", \"color\", \"color\", \"color\", \"color\", \"color\", \"colt\", \"colt\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"column\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"communication\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"community\", \"comparator\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"comparison\", \"compartmental\", \"completion\", \"completion\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"complexity\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"component\", \"compressed_sensing\", \"compressive\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computation\", \"computer_vision\", \"computer_vision\", \"computer_vision\", \"computer_vision\", \"computer_vision\", \"computing_stoc\", \"concave\", \"concave\", \"concentration_inequality\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"condition\", \"conditional\", \"conditional\", \"conditional\", \"conditional\", \"conditional\", \"conductance\", \"conductance\", \"conic\", \"connected\", \"connected\", \"connected\", \"connected\", \"connected\", \"connected\", \"connection\", \"connection\", \"connection\", \"connection\", \"connection\", \"connection\", \"connection\", \"connection\", \"connectivity\", \"connectivity\", \"connectivity\", \"connectivity\", \"connectivity\", \"consciousness\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consider\", \"consolidation\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constant\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"constraint\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"context\", \"contextual_bandit\", \"continuous\", \"continuous\", \"continuous\", \"continuous\", \"continuous\", \"continuous\", \"continuous\", \"continuous\", \"continuous\", \"continuous\", \"continuous\", \"continuously_differentiable\", \"contraction\", \"contraction\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control\", \"control_variate\", \"controller\", \"controller\", \"conv\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convergence\", \"convex\", \"convex\", \"convex\", \"convnet\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolution\", \"convolutional\", \"coordinate_descent\", \"copula\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"core\", \"coreset\", \"corollary\", \"correctly_classified\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlation\", \"correlogram\", \"corruption\", \"corruption\", \"corruption\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"cost\", \"counterfactual\", \"covariance\", \"covariance\", \"covariance\", \"covariate\", \"covariates\", \"coverage\", \"coverage\", \"cr\", \"crf\", \"crfs\", \"critic\", \"critical\", \"critical\", \"critical\", \"critical\", \"critical\", \"critical\", \"critical\", \"critical\", \"critical\", \"critical\", \"critical\", \"crop\", \"csc\", \"ct\", \"ct\", \"ct\", \"ct\", \"ct\", \"ct\", \"ct\", \"ct\", \"ctm\", \"cue\", \"cue\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"current\", \"cursive_handwriting\", \"cursor\", \"cut\", \"cut\", \"cut\", \"cut\", \"cvpr\", \"cvpr\", \"cyclic\", \"cyclic\", \"da\", \"da\", \"da\", \"da\", \"dag\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"data\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"dataset\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"datasets\", \"day\", \"day\", \"day\", \"day\", \"day\", \"dc\", \"dc\", \"dc\", \"dc\", \"dc\", \"dc\", \"dcgan\", \"dcnn\", \"de_vries\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"decision\", \"decoder\", \"decoder\", \"decoder\", \"decomposition\", \"decomposition\", \"decomposition\", \"decomposition\", \"decomposition\", \"decomposition\", \"decomposition\", \"decomposition\", \"deconvolution\", \"deep\", \"deep\", \"definition\", \"definition\", \"definition\", \"definition\", \"definition\", \"definition\", \"definition\", \"definition\", \"deformation\", \"deformation\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"degree\", \"delay\", \"delay\", \"delay\", \"delay\", \"delay\", \"delay\", \"dendrite\", \"dendritic\", \"denoiser\", \"denoising\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"denotes\", \"density\", \"density\", \"density\", \"density\", \"descent\", \"descent\", \"descriptor\", \"descriptor\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"detection\", \"device\", \"device\", \"diabolo\", \"diagonal\", \"diagonal\", \"diagonal\", \"diagonal\", \"diagonal\", \"diagonal\", \"dialog\", \"dictionary\", \"dictionary\", \"dictionary\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"different\", \"differential_privacy\", \"differentially_private\", \"diffusion\", \"diffusion\", \"diffusion\", \"diffusion\", \"digital\", \"digital\", \"digital\", \"digital\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimension\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"dimensional\", \"directed\", \"directed\", \"directed\", \"directed\", \"directed\", \"directed_acyclic\", \"direction\", \"direction\", \"direction\", \"direction\", \"direction\", \"direction\", \"direction\", \"direction\", \"direction\", \"dirichlet\", \"discount_factor\", \"discounted\", \"discriminative\", \"discriminative\", \"discriminative\", \"discriminator\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distance\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distributed\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"distribution\", \"dmd\", \"dnn\", \"dnns\", \"document\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"domain\", \"downstream\", \"dpp\", \"dqn\", \"drain\", \"dropout\", \"dual\", \"dual\", \"dual\", \"duality\", \"dude\", \"dueling_bandit\", \"dx_dx\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"dynamic\", \"eccentricity\", \"eccv\", \"edge\", \"edge\", \"edge\", \"eeg\", \"efe\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"effect\", \"eigen\", \"eigenvalue\", \"eigenvalue\", \"eigenvalue\", \"eigenvectors\", \"eigenvectors\", \"elastic\", \"elastic\", \"elbo\", \"em\", \"em\", \"em\", \"em\", \"em\", \"embedding\", \"embedding\", \"embedding\", \"embedding\", \"embedding\", \"embedding\", \"embeddings\", \"embeddings\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"empirical\", \"encoder\", \"encoder\", \"encoder_decoder\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"energy\", \"english\", \"english\", \"english\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"ensemble\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"entry\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"environment\", \"eoo\", \"episode\", \"episode\", \"eq\", \"eq\", \"eq\", \"eq\", \"eq\", \"eq\", \"eq\", \"eq\", \"equation\", \"equation\", \"equation\", \"equation\", \"equation\", \"equation\", \"equation\", \"equation\", \"equation\", \"equation\", \"equation\", \"equation\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"equilibrium\", \"erm\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"error\", \"es\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimate\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimation\", \"estimator\", \"estimator\", \"estimator\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"et_al\", \"evaluation\", \"evaluation\", \"evaluation\", \"evaluation\", \"evaluation\", \"evaluation\", \"evaluation\", \"evaluation\", \"event\", \"event\", \"event\", \"event\", \"event\", \"evy\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"example\", \"excess_risk\", \"exchangeable\", \"excitatory\", \"excitatory\", \"excitatory_inhibitory\", \"exemplar\", \"exemplar\", \"exemplar\", \"exists\", \"exists\", \"exists\", \"exists\", \"exists\", \"exists\", \"exists\", \"exists\", \"exists\", \"expectation_maximization\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"experiment\", \"expert\", \"expert\", \"expert\", \"expert\", \"expert\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exploration\", \"exponential_family\", \"exponential_family\", \"exponential_family\", \"extrapolation\", \"eye\", \"eye\", \"eye_movement\", \"f\", \"f\", \"face\", \"face\", \"face\", \"facial\", \"facial_expression\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factor\", \"factorization\", \"factorization\", \"fair\", \"fair\", \"fair\", \"fair\", \"fair\", \"fairness\", \"fake\", \"fascicle\", \"fc\", \"fcn\", \"fdr\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"feature\", \"federated\", \"feed_forward\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedback\", \"feedforward\", \"feedforward\", \"felix\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"field\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"fig\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"figure\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filter\", \"filtering\", \"filtering\", \"filtering\", \"filtering\", \"filtering\", \"fine_tuning\", \"fine_tuning\", \"finger\", \"finger\", \"fire\", \"fire\", \"fire\", \"firing\", \"fixation\", \"flanker\", \"floating\", \"floating\", \"floating\", \"floating_gate\", \"fm\", \"fmri\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"following\", \"fom\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"force\", \"forecasting\", \"forecasting\", \"formula\", \"formula\", \"formula\", \"formula\", \"formula\", \"formula\", \"frame\", \"frame\", \"frame\", \"frame\", \"frank_wolfe\", \"free_energy\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency\", \"frequency_band\", \"fritzke\", \"frobenius_norm\", \"fsm\", \"fully_connected\", \"fully_connected\", \"fully_connected\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"function\", \"ga\", \"ga\", \"ga\", \"game\", \"game\", \"game\", \"gamma\", \"gamma\", \"gamma\", \"gan\", \"ganglion\", \"gans\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaussian\", \"gaze\", \"gaze\", \"gb\", \"gc\", \"gene\", \"gene\", \"generative\", \"generative\", \"generative\", \"generative\", \"generative_adversarial\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator\", \"generator_discriminator\", \"genome\", \"geodesic\", \"geoffrey_hinton\", \"geoffrey_hinton\", \"geoffrey_hinton\", \"gibbs_sampler\", \"gibbs_sampling\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"given\", \"glimpse\", \"glms\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"global\", \"glomerulus\", \"glove\", \"google\", \"google\", \"gp\", \"gps\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient\", \"gradient_descent\", \"gradient_descent\", \"gradient_descent\", \"graf\", \"grammar\", \"grammatical\", \"graph\", \"graphical\", \"graphical\", \"graphon\", \"ground_truth\", \"ground_truth\", \"ground_truth\", \"ground_truth\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"group\", \"gru\", \"gtf\", \"gu\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"guarantee\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"hand\", \"handwriting\", \"handwritten_character\", \"hard_thresholding\", \"hardness\", \"hardware\", \"hash\", \"hashing\", \"hasselmo\", \"hawkes_process\", \"head\", \"head\", \"head\", \"hebbian\", \"hebbian\", \"hedge\", \"hidden\", \"hidden\", \"hidden\", \"hierarchical\", \"hierarchical\", \"hierarchical\", \"hierarchical\", \"hierarchical\", \"hierarchical\", \"hilbert\", \"hindsight\", \"hinge_loss\", \"hippocampal\", \"hippocampus\", \"hippocampus\", \"hm\", \"hm\", \"hmc\", \"hme\", \"hmm\", \"hmm\", \"hmms\", \"hmms\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hold\", \"hop\", \"hop\", \"horizon\", \"horizon\", \"hp\", \"hpc\", \"hra\", \"ht\", \"ht\", \"ht\", \"ht\", \"human\", \"human\", \"human\", \"human\", \"human\", \"human\", \"hw\", \"hx\", \"hypergraph\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"hypothesis\", \"ian_goodfellow\", \"ica\", \"iccv\", \"iccv\", \"iclr\", \"iearning\", \"iht\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ii\", \"ij\", \"ij\", \"ij\", \"ij\", \"ij\", \"ij\", \"illumination\", \"ilya_sutskever\", \"image\", \"image\", \"image\", \"imagenet\", \"imitation\", \"imm\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"implementation\", \"impossibility\", \"inception\", \"inception_score\", \"incoherence\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"index\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"individual\", \"inducing\", \"inducing\", \"inducing\", \"inducing\", \"inducing\", \"inequality\", \"inequality\", \"inequality\", \"inf\", \"inf\", \"infant\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"inference\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence\", \"influence_maximization\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"information\", \"inhibitory\", \"inhibitory\", \"inpainting\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"input\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"instance\", \"intensity\", \"intensity\", \"intensity\", \"intensity\", \"intensity\", \"interconnect\", \"interneurons\", \"interventional\", \"iou\", \"ip\", \"ip\", \"ip\", \"ip\", \"irl\", \"ising\", \"isotonic_regression\", \"isotropic\", \"isotropic\", \"item\", \"item\", \"item\", \"iterates\", \"iterates\", \"iterates\", \"iterates\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"iteration\", \"kak\", \"kernel\", \"kernel\", \"kingma_ba\", \"kl_divergence\", \"kl_divergence\", \"knn\", \"kohonen\", \"krr\", \"kv\", \"kvk\", \"kwk\", \"kx\", \"kxi\", \"kxk\", \"kxk\", \"kz\", \"l\", \"l\", \"l\", \"l\", \"l\", \"label\", \"label\", \"label\", \"label\", \"labeled\", \"labeled\", \"labeled\", \"labeled\", \"labeled\", \"ladder\", \"lagrangian\", \"lanczos\", \"language\", \"language\", \"language\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"large\", \"lasso\", \"lasso\", \"latent\", \"latent\", \"latent\", \"latents\", \"lateral\", \"lattice\", \"lattice\", \"lattice\", \"layer\", \"layer\", \"layer\", \"layered\", \"layered\", \"lds\", \"le_cun\", \"leaf\", \"leaf\", \"leaf\", \"leaf\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learn\", \"learned\", \"learned\", \"learned\", \"learned\", \"learned\", \"learned\", \"learned\", \"learned\", \"learned\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"learning\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"least\", \"lemma\", \"lemma\", \"lenet\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"length\", \"lesion\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"let\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"level\", \"leveraging\", \"lg\", \"lgn\", \"lifted\", \"lifted\", \"lighting\", \"likelihood\", \"likelihood\", \"limit\", \"limit\", \"limit\", \"limit\", \"limit\", \"limit\", \"limit\", \"limit\", \"limit\", \"limit\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"linear\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"link\", \"list\", \"list\", \"list\", \"list\", \"lloyd\", \"ln\", \"ln\", \"ln\", \"ln\", \"ln\", \"ln_ln\", \"ln_ln\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"local\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"location\", \"log\", \"log\", \"log\", \"log\", \"log\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long\", \"long_beach\", \"long_beach\", \"loss\", \"loss\", \"loss\", \"loss\", \"loss\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"low\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lower\", \"lsh\", \"lstm\", \"lstm\", \"lstms\", \"lugosi\", \"lyapunov\", \"mab\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"machine\", \"mae\", \"maf\", \"manifold\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"map\", \"mapreduce\", \"marginal\", \"marginal\", \"marginal\", \"marginalization\", \"marginals\", \"market\", \"markov_chain\", \"markov_chain\", \"martinetz\", \"martingale\", \"mask\", \"mask\", \"mask\", \"matching_pursuit\", \"mathematical_programming\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matrix\", \"matroid\", \"max\", \"max\", \"max\", \"max\", \"max\", \"max\", \"max\", \"max\", \"max\", \"maximum_posteriori\", \"mc\", \"mc\", \"mc\", \"mcmc\", \"mcts\", \"mdp\", \"mdps\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"mean\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"measurement\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"mechanism\", \"meg\", \"membrane\", \"membrane_potential\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"memory\", \"message_passing\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"method\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"metric\", \"min\", \"min\", \"min\", \"min\", \"min\", \"min\", \"min\", \"min\", \"min\", \"min\", \"min\", \"ming\", \"mini_batch\", \"minibatch\", \"minimax\", \"minimization\", \"minimization\", \"minimization\", \"minimization\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"minimum\", \"mips\", \"mirror_descent\", \"mixture\", \"mixture\", \"mixture\", \"mixture\", \"mjk\", \"mk\", \"mk\", \"mk\", \"mk\", \"mle\", \"mle\", \"mle\", \"mmd_gan\", \"mnist\", \"mnist\", \"mnist_cifar\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"model\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"modeling\", \"module\", \"module\", \"module\", \"module\", \"molecule\", \"molecule\", \"momentum\", \"monotonic\", \"monotonic\", \"monotonic\", \"monotonic\", \"monotonic\", \"monotonic\", \"monte_carlo\", \"monte_carlo\", \"monte_carlo\", \"motif\", \"motion\", \"motion\", \"motion\", \"motor\", \"motor\", \"motor\", \"motor_command\", \"movement\", \"movement\", \"movement\", \"movie\", \"movie\", \"mpgm\", \"mse\", \"mse\", \"mst\", \"mtse_query\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi\", \"multi_armed\", \"multiclass\", \"multilayer\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multiple\", \"multivariate\", \"multivariate\", \"multivariate\", \"muscle\", \"music\", \"music\", \"musical\", \"nadel\", \"nash_equilibrium\", \"nats\", \"nd\", \"nd\", \"nd\", \"nd\", \"nd\", \"nd\", \"nd\", \"nd\", \"nd\", \"nd\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"neighbor\", \"nesterov\", \"net\", \"net\", \"net\", \"net\", \"net\", \"network\", \"network\", \"network\", \"network\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neural\", \"neuron\", \"neuron\", \"neuron\", \"neuronal\", \"neuronal\", \"nll\", \"nlp\", \"nmf\", \"nmse\", \"nnz\", \"node\", \"node\", \"node\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"noise\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"non\", \"nonconvex\", \"nonconvex\", \"nonlinear\", \"nonlinear\", \"nonlinear\", \"nonlinear\", \"nonlinear\", \"nonlinear\", \"nonlinear\", \"nonsmooth\", \"norm\", \"norm\", \"norm\", \"nuclear_norm\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"number\", \"nyi\", \"nystr\", \"nystr_om\", \"object\", \"object\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"objective\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observation\", \"observer\", \"observer\", \"occlusion\", \"oco\", \"ocular_dominance\", \"odor\", \"offline\", \"offline\", \"olfactory\", \"ols\", \"omniglot\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"one\", \"online\", \"online\", \"online\", \"online\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operation\", \"operator\", \"operator\", \"operator\", \"operator\", \"operator\", \"operator\", \"operator\", \"opponent\", \"opponent\", \"optical_flow\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimal\", \"optimistic\", \"optimistic\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"optimization\", \"option\", \"option\", \"option\", \"option\", \"option\", \"option\", \"oracle\", \"oracle\", \"orange\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"order\", \"orientation\", \"orientation\", \"orthogonal\", \"orthogonal\", \"orthogonal\", \"orthogonal\", \"orthogonal\", \"oscillation\", \"oscillation\", \"oscillation\", \"oscillation\", \"oscillator\", \"oscillatory\", \"oscillatory\", \"oscillatory\", \"outcome\", \"outcome\", \"outcome\", \"outcome\", \"outcome\", \"outcome\", \"outcome\", \"outlier\", \"outlier\", \"outlier\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"output\", \"owl\", \"oxide\", \"pac\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"page\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parallel\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parameter\", \"parent\", \"parent\", \"parietal_cortex\", \"parsing\", \"partially_observable\", \"participant\", \"particle\", \"partition\", \"partition\", \"partition\", \"partitioning\", \"partitioning\", \"party\", \"pascal_voc\", \"patch\", \"patch\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"path\", \"pathway\", \"patient\", \"patient\", \"patient\", \"patient\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"pattern\", \"payoff\", \"pc_bo\", \"pca\", \"pca\", \"pd\", \"pd\", \"pd\", \"pe\", \"pe\", \"peer\", \"people\", \"people\", \"people\", \"people\", \"people\", \"peptide\", \"perception\", \"perception\", \"perception\", \"perception\", \"perceptual\", \"perceptual\", \"perceptual\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"performance\", \"perturbation\", \"perturbation\", \"perturbation\", \"perturbation\", \"perturbation\", \"perturbed\", \"perturbed\", \"perturbed\", \"perturbed\", \"pew\", \"pg\", \"ph\", \"phone\", \"phoneme\", \"phonetic\", \"phrase\", \"physic_engine\", \"physical\", \"physical\", \"physical\", \"physical\", \"physical\", \"physical\", \"physical\", \"physical\", \"pinter\", \"pitch\", \"pixel\", \"pixelcnn\", \"planning\", \"planning\", \"plant\", \"plant\", \"player\", \"pmd\", \"poincar\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"point\", \"pointer\", \"pointnet\", \"policy\", \"polynomial\", \"polynomial\", \"polynomial\", \"polynomial\", \"polynomial\", \"polynomial\", \"polynomially\", \"polytope\", \"pomdp\", \"pooling\", \"pooling\", \"pooling\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"population\", \"pose\", \"pose\", \"pose\", \"pose\", \"pose\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"position\", \"posterior\", \"posterior\", \"postsynaptic\", \"preconditioning\", \"predicate\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"prediction\", \"preference\", \"preference\", \"preference\", \"presynaptic\", \"price\", \"price\", \"primal\", \"primal_dual\", \"principal_component\", \"principal_component\", \"principal_component\", \"principe\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"prior\", \"privacy\", \"private\", \"private\", \"probabilistic\", \"probabilistic\", \"probabilistic\", \"probabilistic\", \"probabilistic\", \"probabilistic\", \"probabilistic\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probability\", \"probing\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"problem\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"process\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processing\", \"processor\", \"prognostic\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"program\", \"projection\", \"projection\", \"projection\", \"projection\", \"projection\", \"projection\", \"proof\", \"proof\", \"proof\", \"proof_sketch\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"property\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"proposed\", \"protein\", \"protein\", \"provable\", \"prove\", \"prove\", \"prove\", \"prove\", \"prove\", \"prox\", \"proximal\", \"proximal\", \"proximal\", \"pruning\", \"pruning\", \"pruning\", \"pruning\", \"psd\", \"pseudocode\", \"psychophysical\", \"pt\", \"pt\", \"pt\", \"pt\", \"pt\", \"pu\", \"pv\", \"pvi\", \"px\", \"px\", \"pyramid\", \"pyramidal_cell\", \"quadrature\", \"quadrature\", \"quantization\", \"quantization\", \"quantization\", \"quantization\", \"quantized\", \"quantized\", \"quantum\", \"query\", \"querying\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question\", \"question_answering\", \"rademacher\", \"rademacher_complexity\", \"radon\", \"ramp\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"random\", \"rank\", \"rank\", \"ranked\", \"ranking\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rate\", \"rating\", \"rbm\", \"rcs\", \"readout\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"real\", \"receptive_field\", \"receptive_field\", \"receptor\", \"receptor\", \"recognition\", \"recognition\", \"recognition\", \"recognition\", \"recognizer\", \"recommendation\", \"recommendation\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"reconstruction\", \"recording\", \"recording\", \"recording\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recover\", \"recovery\", \"recovery\", \"recovery\", \"recovery\", \"recurrent\", \"recurrent\", \"recurrent\", \"reedy\", \"reg\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"region\", \"regression\", \"regression\", \"regression\", \"regressor\", \"regret\", \"regret\", \"regularization\", \"regularization\", \"regularization\", \"regularized\", \"regularized\", \"regularized\", \"regularizer\", \"regularizer\", \"regularizers\", \"reinforcement\", \"relu\", \"remark\", \"remark\", \"remark\", \"remark\", \"remark\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"representation\", \"reproducing_kernel\", \"resampling\", \"resnet\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"resolution\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"respectively\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"response\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"result\", \"retina\", \"retinal\", \"retrieval\", \"retrieval\", \"retrieval\", \"revenue\", \"reversible\", \"reward\", \"rgb\", \"ridge\", \"ridge_regression\", \"ridge_regression\", \"riemannian\", \"riemannian_manifold\", \"rip\", \"risk\", \"risk\", \"risk\", \"rkhs\", \"rkhs\", \"rl\", \"rl\", \"rl\", \"rl\", \"rl\", \"rladder\", \"rn\", \"rn\", \"rn\", \"rn\", \"rn\", \"rn\", \"rna\", \"rnn\", \"rnn\", \"rnns\", \"road\", \"road\", \"road\", \"road\", \"road\", \"road\", \"robot\", \"robot\", \"robot\", \"roi\", \"roi\", \"rollout\", \"rotation\", \"rotation\", \"rotation\", \"rotation\", \"round\", \"round\", \"round\", \"round\", \"routing\", \"routing\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"row\", \"rpfb\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rule\", \"rumelhart\", \"rumelhart\", \"runtime\", \"saccade\", \"saddle\", \"saga\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sample\", \"sampler\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sampling\", \"sardnet\", \"satisfies\", \"satisfies\", \"satisfies\", \"satisfies\", \"sbl\", \"sbm\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scale\", \"scene\", \"scene\", \"scene\", \"schatten_norm\", \"schema\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"scheme\", \"score\", \"score\", \"score\", \"score\", \"score\", \"score\", \"scoring\", \"scoring\", \"scoring\", \"scoring\", \"screening\", \"sdca\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"search\", \"sect\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"section\", \"security\", \"segmentation\", \"segmentation\", \"segmentation\", \"segmentation\", \"seller\", \"semantic\", \"semantic\", \"semantic\", \"semi_supervised\", \"semi_supervised\", \"seminal\", \"sensing\", \"sensing\", \"sensing\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensor\", \"sensory\", \"sensory\", \"sentence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"sequence\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"series\", \"server\", \"service\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"set\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"setting\", \"sg\", \"sgan\", \"sgd\", \"sgd\", \"shalev_shwartz\", \"shallow\", \"shap\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shape\", \"shapley\", \"shared\", \"shared\", \"shared\", \"shared\", \"shared\", \"shared\", \"shared\", \"shared\", \"shot\", \"shot\", \"shot\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"show\", \"shunting\", \"siam_review\", \"siamese\", \"sift\", \"sigmoid\", \"sigmoid\", \"sigmoid\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"signal\", \"silicon\", \"similarity\", \"similarity\", \"similarity\", \"similarity\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"simulation\", \"singular\", \"singular\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"size\", \"skill\", \"slate\", \"smd\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"smooth\", \"snn\", \"sobolev\", \"soda\", \"softmax\", \"softmax\", \"softmax\", \"softmax\", \"sollich\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"solution\", \"soma\", \"somatic\", \"sound\", \"sound\", \"sound\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"source\", \"sp\", \"sp\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"space\", \"spark\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparse\", \"sparsity\", \"sparsity\", \"spatial\", \"spatial\", \"spatial\", \"spatial\", \"speaker\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectral\", \"spectrogram\", \"spectrogram_inversion\", \"speech\", \"speech\", \"speech\", \"speedup\", \"speedup\", \"spherical\", \"spike\", \"spike_train\", \"spiking\", \"spin_glass\", \"spline\", \"squared\", \"squared\", \"squared\", \"squared\", \"squared\", \"squared\", \"sr\", \"sst\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"st\", \"stability\", \"stability\", \"stability\", \"stability\", \"stability\", \"stability\", \"stable\", \"stable\", \"stable\", \"stable\", \"stable\", \"stable\", \"stable\", \"stable\", \"stable\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"state\", \"statistic\", \"statistic\", \"statistic\", \"statistic\", \"statistic\", \"statistic\", \"statistic\", \"statistic\", \"statistic\", \"statistic\", \"statistical_mechanic\", \"statistical_mechanic\", \"steganographic\", \"stein\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"step\", \"stereo\", \"stimulus\", \"stimulus\", \"stoc\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"stochastic\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"storage\", \"stored\", \"stored\", \"stored\", \"stored\", \"stored\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"strategy\", \"streaming\", \"string\", \"string\", \"strongly_convex\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"structure\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"study\", \"subgaussian\", \"subgradient\", \"subgraph\", \"subject\", \"subject\", \"subject\", \"sublinear\", \"submodular\", \"submodular\", \"submodular_maximization\", \"subspace\", \"subspace\", \"suffix\", \"sup\", \"super_resolution\", \"supervised\", \"supervised\", \"supervised\", \"supervised\", \"supervised\", \"supervised\", \"supervised\", \"supervision\", \"supervision\", \"supp\", \"supplement\", \"supplement\", \"supplementary\", \"supplementary\", \"supremum\", \"survival\", \"survival\", \"sutton\", \"svd\", \"svm\", \"svm\", \"svrg\", \"syllable\", \"symbol\", \"symbol\", \"symbol\", \"symbol\", \"symbolic\", \"symbolic\", \"symmetric\", \"symmetric\", \"symmetric\", \"symmetric\", \"symmetric\", \"symmetric\", \"symmetric\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry\", \"symmetry\", \"synapsis\", \"synapsis\", \"synaptic\", \"synaptic_transmission\", \"synchrony\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"system\", \"t\", \"t\", \"t\", \"t\", \"t\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"table\", \"talker\", \"tang\", \"tangent\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"target\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"task\", \"tau\", \"tbe\", \"teacher\", \"teacher\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"temporal\", \"tensor\", \"tensorflow\", \"terrence_sejnowski\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"test\", \"testing\", \"testing\", \"testing\", \"testing\", \"testing\", \"testing\", \"testing\", \"testing\", \"testing\", \"text\", \"text\", \"text\", \"text\", \"text\", \"text\", \"texture\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"th\", \"theorem\", \"theorem\", \"theorem\", \"theorem\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"theory\", \"thermodynamic_limit\", \"thm\", \"thm\", \"thompson_sampling\", \"thread\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"threshold\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"time\", \"timit\", \"tk\", \"token\", \"token\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"top\", \"topic\", \"topic\", \"topology\", \"topology\", \"topology\", \"torque\", \"tp\", \"tp\", \"tp\", \"tract\", \"trader\", \"train\", \"train\", \"train\", \"train\", \"trained\", \"trained\", \"trained\", \"trained\", \"trained\", \"training\", \"training\", \"training\", \"training\", \"training\", \"training\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"trajectory\", \"transcription\", \"transducer\", \"transductive\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transfer\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"transformation\", \"transistor\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"transition\", \"translation\", \"translation\", \"translation\", \"translation\", \"translation\", \"translation_rotation\", \"transport\", \"tree\", \"tree\", \"treewidth\", \"trevor_darrell\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"trial\", \"triggering\", \"triple_gan\", \"triplet\", \"triplet\", \"triplet\", \"trpo\", \"tsp\", \"ttur\", \"tunneling\", \"turing\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"two\", \"ucb\", \"underdetermined\", \"unfairness\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unit\", \"unlabeled\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"update\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"upper\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"used\", \"user\", \"user\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"using\", \"ut\", \"ut\", \"ut\", \"ut\", \"ut\", \"utility\", \"utility\", \"utility\", \"utility\", \"utility\", \"utterance\", \"vae\", \"vaes\", \"validation\", \"validation\", \"validation\", \"validation\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"value\", \"vanilla\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variable\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"variance\", \"variational\", \"vb\", \"vc_dimension\", \"vec\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vector\", \"vertex\", \"vgg\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"vi\", \"video\", \"video\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"view\", \"vincent\", \"vision\", \"vision\", \"vision\", \"vision\", \"visual\", \"visual\", \"visual\", \"visuomotor\", \"vlsi\", \"voice\", \"voice\", \"voltage\", \"voltage\", \"vowel\", \"voxels\", \"vpn\", \"vqa\", \"vt\", \"vt\", \"vt\", \"vt\", \"vt\", \"wasserstein\", \"waveform\", \"waveform\", \"waveform\", \"web\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"weight\", \"welling\", \"wgan\", \"whitening\", \"wikipedia\", \"word\", \"word\", \"word\", \"word\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"work\", \"worker\", \"worker\", \"worker\", \"writer\", \"wta\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xi\", \"xiong\", \"xj\", \"xj\", \"xj\", \"xj\", \"xj\", \"xk\", \"xk\", \"xk\", \"xk\", \"xk\", \"xk\", \"xk\", \"xk_xk\", \"xk_xk\", \"xk_xk\", \"xk_xk\", \"xr\", \"xt\", \"xt\", \"xt\", \"xt\", \"xt\", \"xu\", \"xu\", \"xu\", \"xu\", \"xu\", \"yi\", \"yi\", \"yi\", \"yi\", \"yi\", \"yi\", \"ylx\", \"yoshua_bengio\", \"yoshua_bengio\", \"yt\", \"yt\", \"yt\", \"yt\", \"yt\", \"zt\", \"zt\", \"zt\", \"zt\", \"zt\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [9, 10, 19, 5, 6, 18, 7, 3, 15, 13, 17, 11, 4, 14, 12, 8, 20, 2, 1, 16]};\n",
       "\n",
       "function LDAvis_load_lib(url, callback){\n",
       "  var s = document.createElement('script');\n",
       "  s.src = url;\n",
       "  s.async = true;\n",
       "  s.onreadystatechange = s.onload = callback;\n",
       "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
       "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "}\n",
       "\n",
       "if(typeof(LDAvis) !== \"undefined\"){\n",
       "   // already loaded: just create the visualization\n",
       "   !function(LDAvis){\n",
       "       new LDAvis(\"#\" + \"ldavis_el1123221260817831524039933797\", ldavis_el1123221260817831524039933797_data);\n",
       "   }(LDAvis);\n",
       "}else if(typeof define === \"function\" && define.amd){\n",
       "   // require.js is available: use it to load d3/LDAvis\n",
       "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
       "   require([\"d3\"], function(d3){\n",
       "      window.d3 = d3;\n",
       "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "        new LDAvis(\"#\" + \"ldavis_el1123221260817831524039933797\", ldavis_el1123221260817831524039933797_data);\n",
       "      });\n",
       "    });\n",
       "}else{\n",
       "    // require.js not available: dynamically load d3 & LDAvis\n",
       "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
       "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
       "                 new LDAvis(\"#\" + \"ldavis_el1123221260817831524039933797\", ldavis_el1123221260817831524039933797_data);\n",
       "            })\n",
       "         });\n",
       "}\n",
       "</script>"
      ],
      "text/plain": [
       "PreparedData(topic_coordinates=              x         y  topics  cluster      Freq\n",
       "topic                                               \n",
       "8     -0.120662 -0.030539       1        1  9.901420\n",
       "9     -0.143073 -0.139894       2        1  9.693207\n",
       "18    -0.091293 -0.036891       3        1  9.282038\n",
       "4     -0.151050 -0.130116       4        1  7.850171\n",
       "5     -0.113537  0.010938       5        1  7.405191\n",
       "17    -0.032112  0.072763       6        1  5.800398\n",
       "6     -0.081619  0.058355       7        1  4.932710\n",
       "2     -0.029949 -0.130875       8        1  4.771500\n",
       "14    -0.064717  0.001131       9        1  4.701760\n",
       "12    -0.087943 -0.101212      10        1  4.528399\n",
       "16    -0.060511 -0.047960      11        1  4.353325\n",
       "10     0.079563  0.137192      12        1  4.249203\n",
       "3      0.018616  0.097128      13        1  3.928748\n",
       "13    -0.019873  0.109349      14        1  3.803671\n",
       "11     0.110054  0.111422      15        1  3.077863\n",
       "7      0.080305  0.112499      16        1  2.679866\n",
       "19     0.074397  0.033499      17        1  2.635397\n",
       "1      0.351457 -0.342394      18        1  2.319097\n",
       "0      0.164097  0.141810      19        1  2.284995\n",
       "15     0.117851  0.073794      20        1  1.801040, topic_info=            Term           Freq          Total Category  logprob  loglift\n",
       "451        model  155714.000000  155714.000000  Default  30.0000  30.0000\n",
       "470      network   78634.000000   78634.000000  Default  29.0000  29.0000\n",
       "346        image   45252.000000   45252.000000  Default  28.0000  28.0000\n",
       "1038      matrix   51044.000000   51044.000000  Default  27.0000  27.0000\n",
       "275      feature   40977.000000   40977.000000  Default  26.0000  26.0000\n",
       "...          ...            ...            ...      ...      ...      ...\n",
       "552   processing    1539.368845   22084.170362  Topic20  -5.2588   1.3533\n",
       "471       neural    1608.109940   51518.644100  Topic20  -5.2151   0.5499\n",
       "483       number    1400.532536   51301.545467  Topic20  -5.3533   0.4159\n",
       "1208       using    1231.964153   64673.971414  Topic20  -5.4816   0.0561\n",
       "2199      scheme    1158.506101    7628.929127  Topic20  -5.5430   2.1320\n",
       "\n",
       "[1478 rows x 6 columns], token_table=       Topic      Freq                  Term\n",
       "term                                        \n",
       "59239      3  0.998267       aaron_courville\n",
       "99599      7  0.998436  absolute_discounting\n",
       "5289       4  0.977905           accelerated\n",
       "5289       5  0.006955           accelerated\n",
       "5289      20  0.014606           accelerated\n",
       "...      ...       ...                   ...\n",
       "8857       3  0.247895                    zt\n",
       "8857       4  0.158054                    zt\n",
       "8857       9  0.025372                    zt\n",
       "8857      17  0.560676                    zt\n",
       "8857      18  0.007487                    zt\n",
       "\n",
       "[4758 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[9, 10, 19, 5, 6, 18, 7, 3, 15, 13, 17, 11, 4, 14, 12, 8, 20, 2, 1, 16])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.151159268746868\n",
      "\n",
      "Coherence Score:  0.4549351316322289\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity:  -8.15115919231209\n",
      "\n",
      "Coherence Score:  0.4549351316322289\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_words_bigrams, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.04503143),\n",
       " (4, 0.14354584),\n",
       " (5, 0.05435283),\n",
       " (6, 0.010055193),\n",
       " (7, 0.016024968),\n",
       " (8, 0.11549007),\n",
       " (9, 0.049557358),\n",
       " (14, 0.4621343),\n",
       " (17, 0.07067498)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model.get_document_topics(corpus[22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generalization in Reinforcement Learning: Safely Approximating the Value Function Justin A. Boyan and Andrew W. Moore Computer Science Department Carnegie Mellon University Pittsburgh, PA 15213 jab@cs.cmu.edu, awm@cs.cmu .edu Abstract A straightforward approach to the curse of dimensionality in reinforcement learning and dynamic programming is to replace the lookup table with a generalizing function approximator such as a neural net. Although this has been successful in the domain of backgammon, there is no guarantee of convergence. In this paper, we show that the combination of dynamic programming and function approximation is not robust, and in even very benign cases, may produce an entirely wrong policy. We then introduce Grow-Support, a new algorithm which is safe from divergence yet can still reap the benefits of successful generalization . 1 INTRODUCTION Reinforcement learning-the problem of getting an agent to learn to act from sparse, delayed rewards-has been advanced by techniques based on dynamic programming (DP). These algorithms compute a value function which gives, for each state, the minimum possible long-term cost commencing in that state. For the high-dimensional and continuous state spaces characteristic of real-world control tasks, a discrete representation of the value function is intractable; some form of generalization is required. A natural way to incorporate generalization into DP is to use a function approximator, rather than a lookup table, to represent the value function. This approach, which dates back to uses of Legendre polynomials in DP [Bellman et al., 19631, has recently worked well on several dynamic control problems [Mahadevan and Connell, 1990, Lin, 1993] and succeeded spectacularly on the game of backgammon [Tesauro, 1992, Boyan, 1992]. On the other hand, many sensible implementations have been less successful [Bradtke, 1993, Schraudolph et al., 1994]. Indeed, given the well-established success 370 Justin Boyan, Andrew W. Moore on backgammon, the absence of similarly impressive results appearing for other games is perhaps an indication that using function approximation in reinforcement learning does not always work well. In this paper, we demonstrate that the straightforward substitution of function approximators for lookup tables in DP is not robust and, even in very benign cases, may diverge, resulting in an entirely wrong control policy. We then present Grow-Support, a new algorithm designed to converge robustly. Grow-Support grows a collection of states over which function approximation is stable. One-step backups based on Bellman error are not used; instead, values are assigned by performing \"rollouts\" -explicit simulations with a greedy policy. We discuss potential computational advantages of this method and demonstrate its success on some example problems for which the conventional DP algorithm fails. 2 DISCRETE AND SMOOTH VALUE ITERATION Many popular reinforcement learning algorithms, including Q-Iearning and TD(O), are based on the dynamic programmin~ algorithm known as value iteration [Watkins, 1989, Sutton, 1988, Barto et al., 1989J, which for clarity we will call discrete value iteration. Discrete value iteration takes as input a complete model of the world as a Markov Decision Task, and computes the optimal value function J*: J* (x) = the minimum possible sum of future costs starting from x To assure that J* is well-defined, we assume here that costs are nonnegative and that some absorbing goal state-with all future costs O-is reachable from every state. For simplicity we also assume that state transitions are deterministic. Note that J* and the world model together specify a \"greedy\" policy which is optimal for the domain: optimal action from state x = argmin(CosT(x, a) + J*(NEXT-STATE(X, a))) aEA We now consider extending discrete value iteration to the continuous case: we replace the lookup table over all states with a function approximator trained over a sample of states. The smooth value iteration algorithm is given in the appendix. Convergence is no longer guaranteed; we instead recognize four possible classes of behavior: good convergence The function approximator accurately represents the intermediate value functions at each iteration (that is, after m iterations, the value function correctly represents the cost of the cheapest m-step path), and successfully converges to the optimal J* value function. lucky convergence The function approximator does not accurately represent the intermediate value functions at each iteration; nevertheless, the algorithm manages to converge to a value function whose greedy policy is optimal. bad convergence The algorithm converges, i.e. the target J-values for the N training points stop changing, but the resulting value function and policy are poor. divergence Worst of all: small fitter errors may become magnified from one iteration to the next, resulting in a value function which never stops changing. The hope is that the intermediate value functions will be smooth and we will achieve \"good convergence.\" Unfortunately, our experiments have generated all four of these behaviors-and the divergent behavior occurs frequently, even for quite simple problems. Generalization in Reinforcement Learning: Safely Approximating the Value Function 2.1 37 J DIVERGENCE IN SMOOTH VALUE ITERATION We have run simulations in a variety of domains-including a continuous gridworld, a car-on-the-hill problem with nonlinear dynamics, and tic-tac-toe versus a stochastic opponent-and using a variety of function approximators, including polynomial regression, backpropagation, and local weighted regression. In our experiments, none of these function approximators was immune from divergence. The first set ofresults is from the 2-D continuous gridworld, described in Figure 1. By quantizing the state space into a 100 x 100 grid, we can compute J* with discrete value iteration, as shown in Figure 2. The optimal value function is exactly linear: J*(x, y) = 20 - lOx - lOy. Since J* is linear, one would hope smooth value iteration could converge to it with a function approximator as simple as linear or quadratic regression. However, the intermediate value functions of Figure 2 are not smooth and cannot be fit accurately by a low-order polynomial. Using linear regression on a sample of 256 randomly-chosen states, smooth value iteration took over 500 iterations before \"luckily\" converging to optimal. Quadratic regression, though it always produces a smaller fit error than linear regression, did not converge (Figure 3). The quadratic function, in trying to both be flat in the middle of state space and bend down toward 0 at the goal corner, must compensate by underestimating the values at the corner opposite the goal. These underestimates then enlarge on each iteration, as the one-step DP lookaheads erroneously indicate that points can lower their expected cost-to-go by stepping farther away from the goal. The resulting policy is anti-optimal. fontinuous Gridworld J*(x,y) 0.8 0.6 >. 0.4 0.2 0L-0~.~2-0~.~4-0~.~6~0~.~8~1 x Figure 1: In the continuous gridworld domain, the state is a point (x, y) E [0,1]2. There are four actions corresponding to short steps (length 0.05, cost 0.5) in each compass direction, and the goal region is the upper right-hand corner. l*(x, y) is linear. Iteration 12 Iteration 25 .8 1 Figure 2: Computation of 1* by discrete value iteration Iteration 40 Justin Boyan, Andrew W. Moore 372 Iteration 17 Iteration 43 Iteration 127 1 .8 .8 .8 1 Figure 3: Divergence of smooth value iteration with quadratic regression (note z-axis). J*(x , y) Iteration 144 o. o. >. o. .8 o. 0.20 . 40.60 . 8 x 1 1 Figure 4: The 2-D continuous gridworld with puddles, its optimal value function, and a diverging approximation of the value function by Local Weighted Regression (note z-axis). car- o n-the-Hill J* (pa s, vel) 0.5 pas Figure 5: The car-on-the-hill domain. When the velocity is below a threshold, the car must reverse up the left hill to gain enough speed to reach the goal, so r is discontinuous. Iteration 11 Iterati on 101 Iteration 201 Figure 6: Divergerice oYsmooth value iteration wit~ for car-on-th~~hill~ The neural net, a 2-layer MLP with 80 hidden units, was trained for 2000 epochs per iteration. It may seem as though the divergence of smooth value iteration shown above can be attributed to the global nature of polynomial regression. In fact, when the domain is made slightly less trivial, the same types of instabilities appear with even a highly Generalization in Reinforcement Learning: Safely Approximating the Value Function 373 Table 1: Summary of convergence results: Smooth value iteration Domain 2-D grid world 2-D puddle world Car-on-the-hill Linear lucky Quadratic diverge - - - - LWR good diverge good Backprop lucky diverge diverge local memory-based function approximator such as local weighted regression (LWR) [Cleveland and Delvin, 1988]. Figure 4 shows the continuous gridworld augmented to include two oval \"puddles\" through which it is costly to step. Although LWR can fit the corresponding J* function nearly perfectly, smooth value iteration with LWR nonetheless reliably diverges. On another two-dimensional domain, the car-on-the-hill (Figure 5), smooth value iteration with LWR did converge, but a neural net trained by backpropagation did not (see Figure 6) . Table 1 summarizes our results . In light of such experiments, we conclude that the straightforward combination of DP and function approximation is not robust. A general-purpose learning method will require either using a function approximator constrained to be robust during DP [Yee, 1992], or an algorithm which explicitly prevents divergence even in the face of imperfect function approximation, such as the Grow-Support algorithm we present in Section 3. 2.2 RELATED WORK Theoretically, it is not surprising that inserting a smoothing process into a recursive DP procedure can lead to trouble. In [Thrun and Schwartz, 1993] one case is analyzed with the assumption that errors due to function approximation bias are independently distributed. Another area of theoretical analysis concerns inadequately approximated J* functions. In [Singh and Yee, 1994] and [Williams, 1993] bounds are derived for the maximum reduction in optimality that can be produced by a given error in function approximation. If a basis function approximator is used, then the reduction can be large [Sabes, 1993]. These results assume generalization from a dataset containing true optimal values; the true reinforcement learning scenario is even harder because each iteration of DP requires its own function approximation. 3 THE GROW-SUPPORT ALGORITHM The Grow-Support algorithm is designed to construct the optimal value function with a generalizing function approximator while being robust and stable. It recognizes that function approximators cannot always be relied upon to fit the intermediate value functions produced by DP. Instead, it assumes only that the function approximator can represent the final J* function accurately. The specific principles of Grow-Support are these: 1. We maintain a \"support\" set of states whose final J* values have been computed, starting with goal states, and growing this set out from the goal. The fitter is trained only on these values, which we assume it is capable of fitting. 2. Instead of propagating values by one-step DP backups, we use simulations with the current greedy policy, called \"rollouts\". They explicitly verify the achievability of a states cost-to-go estimate before adding that state to the 374 Justin Boyan, Andrew W. Moore support. In a rollout, the J values are derived from costs of actual paths to the goal, not from the values of the previous iterations function approximation. This prevents divergence . 3. We take maximum advantage of generalization. Each iteration, we add to the support set any sample state which can, by executing a single action, reach a state that passes the rollout test. In a discrete environment, this would cause the support set to expand in one-step concentric \"shells\" back from the goal. But in our continuous case, the function approximator may be able to extrapolate correctly well beyond the support region-and when this happens, we can add many points to the support set at once. This leads to the very desirable behavior that the support set grows in big jumps in regions where the value function is smooth. Iteration 1, I Support I =4 Iteration 2, 1Support 1=12 Iteration 3, ISupportl=256 Figure 7: Grow-Support with quadratic regression on the gridworld. (Compare Figure 3.) Iteration 1, I Support I =3 Iteration 2, ISupportl=213 Iteration 5, ISupportl=253 Figure 8: Grow-Support with LWR on the two-puddle gridworld. (Compare Figure 4.) Iteration 3, I Support I =79 Iteration 8, ISupportl=134 Iteration 14, ISupportl=206 3 O. 2 O. -2 o. Figure 9: Grow-Support with backprop on car-on-the-hill. (Compare Figure 6.) The algorithm, again restricted to the deterministic case for simplicity, is outlined in the appendix. In Figures 7-9, we illustrate its convergence on the same combinations of domain and function approximator which caused smooth value iteration to diverge. In Figure 8, all but three points are added to the support within only five iterations, Generalization in Reinforcement Learning: Safely Approximating the Value Function 375 and the resulting greedy policy is optimal. In Figure 9, after 14 iterations, the algorithm terminates. Although 50 states near the discontinuity were not added to the support set, the resulting policy is optimal within the support set. Grow-support converged to a near-optimal policy for all the problems and fitters in Table 1. The Grow-Support algorithm is more robust than value iteration. Empirically, it was also seen to be no more computationally expensive (and often much cheaper) despite the overhead of performing rollouts. Reasons for this are (1) the rollout test is not expensive; (2) once a state has been added to the support, its value is fixed and it needs no more computation; and most importantly, (3) the aggressive exploitation of generalization enables the algorithm to converge in very few iterations. However, with a nondeterministic problem, where multiple rollouts are required to assess the accuracy of a prediction, Grow-Support would become more expensive. It is easy to prove that Grow-Support will always terminate after a finite number of iterations. If the function approximator is inadequate for representing the J* function, Grow-Support may terminate before adding all sample states to the support set. When this happens, we then know exactly which of the sample states are having trouble and which have been learned. This suggests potential schemes for adaptively adding sample states to the support in problematic regions. Investigation of these ideas is in progress. In conclusion, we have demonstrated that dynamic programming methods may diverge when their tables are replaced by generalizing function approximators. Our Grow-Support algorithm uses rollouts, rather than one-step backups, to assign training values and to keep inaccurate states out of the training set. We believe these principles will contribute substantially to producing practical, robust, reinforcement learning. Acknowledgements We thank Scott Fahlman, Geoff Gordon, Mary Lee, Michael Littman and Marc Ringuette for their suggestions, and the NDSEG fellowship and NSF Grant IRI-9214873 for their support. APPENDIX: ALGORITHMS Smooth Value Iteration(X, G, A, NEXT-STATE, COST, FITJ): Given: _ a finite collection of states X = {Xl, X2, .. . XN} sampled from the continuous state space X C fR n , and goal region G C X _ a finite set of allowable actions A _ a deterministic transition function NEXT-STATE: X x A -+ X _ the I-step cost function COST: X x A -+ fR _ a smoothing function approximator FIT J iter := 0 ]<0) [i] := 0 Vi = 1 ... N {X I t-+ J?(iter) [1] } repeat !rain ~ITJ(iter) to approximate the training set: : Iter .:= Iter + 1; XN t-+ /iter)[N] for ~ := 1 ... N do .(iter) [.] ._ { 0 . J 1.minaEA (COST(Xi,a) + FITJ(lter-I)(NEXT-STATE(xi,a))) until j array stops changing if Xi E G otherwise 376 Justin Boyan, Andrew W. Moore subroutine RoIloutCost(x, J): Starting from state x , follow the greedy policy defined by value function J until either reaching the goal, or exceeding a total path cost of J(x) + ?. Then return: --t the actual total cost of the path, if goal is reached from x with cost ~ J(x) + e --t 00, if goal is not reached in cost J(x) + ?. Grow-Support(X,G,A, NEXT-STATE, COST, FITJ): Given: ? exactly the same inputs as Smooth Value Iteration. SUPPORT := {(Xi t-+ 0) I Xi E G} repeat Train FIT J to approximate the training set SUPPORT for each Xi ~ SUPPORT do c := minaEA [COsT(xi,a) + RolloutCost(NEXT-STATE(Xi, a), FITJ)] if c < 00 then add (Xi t-+ c) to the training set SUPPORT until SUPPORT stops growing or includes all sample points. References [Barto et al., 1989] A . Barto, R. Sutton , and C . Watkins . Learning and sequential decision making. Technical Report COINS 89- 95, Univ. of Massachusetts, 1989 . [Bellman et al., 1963] R . Bellman, R . Kalaba, and B . Kotkin. Polynomial approximation-a new computational technique in dynamic programming: Allocation processes . Mathematics of Computation, 17, 1963. [Boyan , 1992] J. A . Boyan. Modular neural networks for learning context-dependent game strategies . Masters thesis, Cambridge University, 1992. [Bradtke, 1993] S. J. Bradtke. Reinforcement learning applied to linear quadratic regulation. In S. J . Hanson, J . Cowan, and C . L . Giles, editors, NIPS-5. Morgan Kaufmann , 1993. [Cleveland and Delvin, 1988] W . S. Cleveland and S. J. Delvin. Locally weighted regression : An approach to regression analysis by local fitting. JASA , 83(403):596-610, September 1988. [Lin, 1993] L.-J . Lin . Reinforcement Learning for Robots Using Neural Networks. PhD thesis, Carnegie Mellon University, 1993. [Mahadevan and Connell , 1990] S. Mahadevan and J. Connell . Automatic programming of behavior-based robots using reinforcement learning. Technical report, IBM T. J . Watson Research Center, NY 10598, 1990 . [Sabes, 1993] P. Sabes . Approximating Q-values with basis function represent ations. In Proceedings of the Fourth C onnectionist Models Summer School, 1993. [Schraudolph et al., 1994] N . Schraudolph, P . Dayan, and T. Sejnowski . Using TD(>.) to learn an evaluation function for the game of Go . In J. D. Cowan, G . Tesauro , and J . Alspector, editors, NIPS-6. Morgan Kaufmann, 1994. [Singh and Yee, 1994] S. P. Singh and R. Yee. An upper bound on the loss from approximate optimal-value functions . Machine Learning, 1994. Technical Note (to appear) . [Sutton, 1988] R . Sutton . Learning to predict by the methods of temporal differences. Machine Learning, 3,1988. [Tesauro, 1992] G. Tesauro. Practical issues in temporal difference learning. Machine Learning, 8(3/4), May 1992. [Thrun and Schwartz, 1993] S. Thrun and A . Schwartz. Issues in using function approximation for reinforcement learning. In Proceedings of the Fourth Connectionist Models Summer School, 1993. [Watkins, 1989] C . Watkins. Learning from Delayed Rewards. PhD thesis, Cambridge University, 1989 . [Williams, 1993] R. Williams . Tight performance bounds on greedy policies based on imperfect value functions . Technical Report NU-CCS-93-13, Northeastern University, 1993. [Yee, 1992] R . Yee. sachusetts, 1992. Abstraction in control learning. Technical Report COINS 92-16 , Univ. of Mas- '"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.ldamodel.LdaModel(\n",
    "            corpus=corpus,\n",
    "            id2word=dictionary,\n",
    "            num_topics=num_topics, \n",
    "            random_state=100,\n",
    "            update_every=1,\n",
    "            chunksize=100,\n",
    "            passes=10,\n",
    "            alpha='auto',\n",
    "            per_word_topics=True)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2h 1min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=data_words_bigrams, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "if prepare:\n",
    "    lda_model_opt = gensim.models.ldamodel.LdaModel(\n",
    "        corpus=corpus,\n",
    "        id2word=id2word,\n",
    "        num_topics=8, \n",
    "        random_state=100,\n",
    "        update_every=1,\n",
    "        chunksize=100,\n",
    "        passes=10,\n",
    "        alpha='auto',\n",
    "        per_word_topics=True)\n",
    "    lda_model_opt.save('lda_opt.pkl')\n",
    "else:\n",
    "    lda_model_opt = gensim.models.ldamodel.LdaModel.load('lda_opt.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.013*\"model\" + 0.012*\"neuron\" + 0.009*\"time\" + 0.008*\"cell\" + '\n",
      "  '0.007*\"neural\" + 0.007*\"figure\" + 0.007*\"signal\" + 0.007*\"system\" + '\n",
      "  '0.007*\"response\" + 0.006*\"activity\"'),\n",
      " (1,\n",
      "  '0.014*\"algorithm\" + 0.013*\"graph\" + 0.012*\"node\" + 0.009*\"set\" + '\n",
      "  '0.008*\"time\" + 0.008*\"cluster\" + 0.007*\"clustering\" + 0.007*\"structure\" + '\n",
      "  '0.007*\"number\" + 0.006*\"tree\"'),\n",
      " (2,\n",
      "  '0.050*\"network\" + 0.022*\"neural\" + 0.017*\"input\" + 0.015*\"learning\" + '\n",
      "  '0.015*\"layer\" + 0.013*\"output\" + 0.012*\"weight\" + 0.012*\"training\" + '\n",
      "  '0.012*\"unit\" + 0.008*\"function\"'),\n",
      " (3,\n",
      "  '0.032*\"image\" + 0.012*\"object\" + 0.012*\"model\" + 0.011*\"feature\" + '\n",
      "  '0.007*\"using\" + 0.007*\"convolutional\" + 0.006*\"representation\" + '\n",
      "  '0.006*\"map\" + 0.006*\"method\" + 0.006*\"recognition\"'),\n",
      " (4,\n",
      "  '0.016*\"algorithm\" + 0.012*\"function\" + 0.010*\"problem\" + 0.008*\"bound\" + '\n",
      "  '0.008*\"matrix\" + 0.008*\"method\" + 0.007*\"theorem\" + 0.006*\"learning\" + '\n",
      "  '0.006*\"result\" + 0.006*\"log\"'),\n",
      " (5,\n",
      "  '0.031*\"model\" + 0.018*\"distribution\" + 0.013*\"data\" + 0.009*\"log\" + '\n",
      "  '0.009*\"parameter\" + 0.008*\"sample\" + 0.008*\"inference\" + 0.008*\"gaussian\" + '\n",
      "  '0.008*\"variable\" + 0.007*\"method\"'),\n",
      " (6,\n",
      "  '0.016*\"learning\" + 0.015*\"model\" + 0.013*\"data\" + 0.012*\"task\" + '\n",
      "  '0.012*\"feature\" + 0.012*\"training\" + 0.009*\"set\" + 0.008*\"classification\" + '\n",
      "  '0.008*\"label\" + 0.007*\"class\"'),\n",
      " (7,\n",
      "  '0.018*\"state\" + 0.015*\"learning\" + 0.014*\"policy\" + 0.012*\"action\" + '\n",
      "  '0.011*\"algorithm\" + 0.009*\"time\" + 0.009*\"reward\" + 0.008*\"regret\" + '\n",
      "  '0.008*\"value\" + 0.008*\"agent\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model_opt.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "doc_rl1 = '''Deep reinforcement learning on Atari games maps pixel directly to actions; internally,\n",
    "the deep neural network bears the responsibility of both extracting useful\n",
    "information and making decisions based on it. Aiming at devoting entire deep\n",
    "networks to decision making alone, we propose a new method for learning policies\n",
    "and compact state representations separately but simultaneously for policy\n",
    "approximation in reinforcement learning. State representations are generated by a\n",
    "novel algorithm based on Vector Quantization and Sparse Coding, trained online\n",
    "along with the network, and capable of growing its dictionary size over time. We\n",
    "also introduce new techniques allowing both the neural network and the evolution\n",
    "strategy to cope with varying dimensions. This enables networks of only 6 to 18\n",
    "neurons to learn to play a selection of Atari games with performance comparable—\n",
    "and occasionally superior—to state-of-the-art techniques using evolution strategies\n",
    "on deep networks two orders of magnitude larger.'''\n",
    "\n",
    "\n",
    "doc_rl2 = '''Deep reinforcement learning methods traditionally struggle with tasks where environment\n",
    "rewards are particularly sparse. One successful method of guiding\n",
    "exploration in these domains is to imitate trajectories provided by a human demonstrator.\n",
    "However, these demonstrations are typically collected under artificial\n",
    "conditions, i.e. with access to the agent’s exact environment setup and the demonstrator’s\n",
    "action and reward trajectories. Here we propose a two-stage method that\n",
    "overcomes these limitations by relying on noisy, unaligned footage without access\n",
    "to such data. First, we learn to map unaligned videos from multiple sources to a\n",
    "common representation using self-supervised objectives constructed over both time\n",
    "and modality (i.e. vision and sound). Second, we embed a single YouTube video\n",
    "in this representation to construct a reward function that encourages an agent to\n",
    "imitate human gameplay. This method of one-shot imitation allows our agent to\n",
    "convincingly exceed human-level performance on the infamously hard exploration\n",
    "games MONTEZUMA’S REVENGE, PITFALL! and PRIVATE EYE for the first time†\n",
    ",\n",
    "even if the agent is not presented with any environment rewards.\n",
    "'''\n",
    "\n",
    "doc_cv = '''Convolutional Neural Networks (CNNs) have become the method of choice \n",
    "for learning problems involving 2D planar images. However, a number of problems of recent \n",
    "interest have created a demand for models that can analyze spherical images. \n",
    "Examples include omnidirectional vision for drones, robots, and autonomous cars, \n",
    "molecular regression problems, and global weather and climate modelling. \n",
    "A naive application of convolutional networks to a planar projection of the spherical signal\n",
    "is destined to fail, because the space-varying distortions introduced by such a projection will\n",
    "make translational weight sharing ineffective.\n",
    "In this paper we introduce the building blocks for constructing spherical CNNs. \n",
    "We propose a definition for the spherical cross-correlation that is both expressive and rotation-equivariant.\n",
    "The spherical correlation satisfies a generalized Fourier theorem, which allows us to compute \n",
    "it efficiently using a generalized (non-commutative) Fast Fourier Transform (FFT) algorithm.\n",
    "We demonstrate the computational efficiency, numerical accuracy, and effectiveness of spherical \n",
    "CNNs applied to 3D model recognition and atomization energy regression.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def doc2bowl_bigram(doc):\n",
    "    doc = clean(doc)\n",
    "    words = doc_to_words(doc, stop_words, lemma)\n",
    "    bigrams = bigram_mod[words]\n",
    "    bow = id2word.doc2bow(bigrams)\n",
    "    return bow, bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_rl1, bigrams_rl1 = doc2bowl_bigram(doc_rl1)\n",
    "bow_rl2, bigrams_rl2 = doc2bowl_bigram(doc_rl2)\n",
    "bow_cv, bigrams_cv = doc2bowl_bigram(doc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deep',\n",
       " 'reinforcement',\n",
       " 'learning',\n",
       " 'atari_game',\n",
       " 'map',\n",
       " 'pixel',\n",
       " 'directly',\n",
       " 'action',\n",
       " 'internally',\n",
       " 'deep',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'bear',\n",
       " 'responsibility',\n",
       " 'extracting',\n",
       " 'useful',\n",
       " 'information',\n",
       " 'making',\n",
       " 'decision',\n",
       " 'based',\n",
       " 'aiming',\n",
       " 'devoting',\n",
       " 'entire',\n",
       " 'deep',\n",
       " 'network',\n",
       " 'decision',\n",
       " 'making',\n",
       " 'alone',\n",
       " 'propose',\n",
       " 'new',\n",
       " 'method',\n",
       " 'learning',\n",
       " 'policy',\n",
       " 'compact',\n",
       " 'state',\n",
       " 'representation',\n",
       " 'separately',\n",
       " 'simultaneously',\n",
       " 'policy',\n",
       " 'approximation',\n",
       " 'reinforcement',\n",
       " 'learning',\n",
       " 'state',\n",
       " 'representation',\n",
       " 'generated',\n",
       " 'novel',\n",
       " 'algorithm',\n",
       " 'based',\n",
       " 'vector',\n",
       " 'quantization',\n",
       " 'sparse',\n",
       " 'coding',\n",
       " 'trained',\n",
       " 'online',\n",
       " 'along',\n",
       " 'network',\n",
       " 'capable',\n",
       " 'growing',\n",
       " 'dictionary',\n",
       " 'size',\n",
       " 'time',\n",
       " 'also',\n",
       " 'introduce',\n",
       " 'new',\n",
       " 'technique',\n",
       " 'allowing',\n",
       " 'neural',\n",
       " 'network',\n",
       " 'evolution',\n",
       " 'strategy',\n",
       " 'cope',\n",
       " 'varying',\n",
       " 'dimension',\n",
       " 'enables',\n",
       " 'network',\n",
       " 'neuron',\n",
       " 'learn',\n",
       " 'play',\n",
       " 'selection',\n",
       " 'atari_game',\n",
       " 'performance',\n",
       " 'comparable',\n",
       " 'occasionally',\n",
       " 'superior',\n",
       " 'state',\n",
       " 'art',\n",
       " 'technique',\n",
       " 'using',\n",
       " 'evolution',\n",
       " 'strategy',\n",
       " 'deep',\n",
       " 'network',\n",
       " 'two',\n",
       " 'order',\n",
       " 'magnitude',\n",
       " 'larger']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bigrams_rl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2, 0.3263107),\n",
       " (3, 0.2581074),\n",
       " (4, 0.017848648),\n",
       " (6, 0.026870906),\n",
       " (7, 0.34916314)]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt.get_document_topics(bow_rl1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 0.29723138),\n",
       " (4, 0.015419452),\n",
       " (5, 0.03982899),\n",
       " (6, 0.11953734),\n",
       " (7, 0.50085264)]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt.get_document_topics(bow_rl2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0.029139243),\n",
       " (1, 0.11906097),\n",
       " (2, 0.077320196),\n",
       " (3, 0.44559783),\n",
       " (4, 0.16184708),\n",
       " (5, 0.11535659),\n",
       " (7, 0.043800566)]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt.get_document_topics(bow_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def bow2feat(bow):\n",
    "    return np.asarray([x for _, x in lda_model.get_document_topics(bow, minimum_probability=0)])\n",
    "\n",
    "\n",
    "def doc2feat(doc):\n",
    "    bow, _ = doc2bowl_bigram(doc)\n",
    "    return bow2feat(bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_rl1 = doc2feat(doc_rl1)\n",
    "feat_rl2 = doc2feat(doc_rl2)\n",
    "feat_cv = doc2feat(doc_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00347409, 0.00494003, 0.01583711, 0.04266278, 0.01496889,\n",
       "       0.01671956, 0.0161709 , 0.00446689, 0.03555086, 0.00768752,\n",
       "       0.00424144, 0.02585269, 0.02773212, 0.12899452, 0.28083357,\n",
       "       0.02106646, 0.00525921, 0.29093683, 0.02459397, 0.02801055],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(feat_rl1.shape)\n",
    "feat_rl1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "doc1: rl1, doc2: rl2, similarity 0.27\n",
      "doc1: rl1, doc2: cv, similarity 0.48\n",
      "doc1: rl2, doc2: cv, similarity 0.48\n"
     ]
    }
   ],
   "source": [
    "names = ['rl1', 'rl2', 'cv']\n",
    "feats = [feat_rl1, feat_rl2, feat_cv]\n",
    "names_feat = zip(names, feats)\n",
    "\n",
    "for (n1, f1), (n2, f2) in combinations(names_feat, 2):\n",
    "    print('doc1: {}, doc2: {}, similarity {:.2f}'.format(n1, n2, distance.euclidean(f1, f2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Russian example\n",
    "\n",
    "https://github.com/maxoodf/russian_news_corpus\n",
    "\n",
    "```bash\n",
    "git clone https://github.com/maxoodf/russian_news_corpus.git\n",
    "cd ./russian_news_corpus\n",
    "cat ./russian_news.txt.bz2_a* | bzip2 -d > ./russian_news.txt\n",
    "cat russian_news.txt | awk 'BEGIN {srand()} !/^$/ { if (rand() <= .005) print $0}' > russian_news_10k.txt\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ru = Path('/media/storage/data_nlp/russian_news_corpus/russian_news_10k.txt').read_text(encoding='utf-8').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_words_ru(doc, stop_words):\n",
    "    stop_words = set(stop_words)\n",
    "    # remove stop words and punctuation\n",
    "    words = [w for w in gensim.utils.simple_preprocess(str(doc), deacc=True, max_len=100) if w not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "prepare = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ru = [clean(t) for t in data_ru]\n",
    "data_words_ru = [doc_to_words_ru(t, stop_words) for t in data_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['сми',\n",
       " 'называть',\n",
       " 'украина',\n",
       " 'коррумпированныи',\n",
       " 'болото',\n",
       " 'мир',\n",
       " 'политика',\n",
       " 'аргумент',\n",
       " 'факт',\n",
       " 'москва']"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_ru[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram_ru = gensim.models.Phrases(data_words_ru, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "\n",
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod_ru = gensim.models.phrases.Phraser(bigram_ru)\n",
    "    \n",
    "data_words_bigrams_ru = [bigram_mod_ru[w] for w in data_words_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['цивилизованныи',\n",
       " 'подход',\n",
       " 'наркоз',\n",
       " 'город',\n",
       " 'новость',\n",
       " 'санкт_петербург',\n",
       " 'фонтанка_ру',\n",
       " 'приморскии',\n",
       " 'раион',\n",
       " 'петербург']"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_words_bigrams_ru[1][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word_ru = corpora.Dictionary(data_words_bigrams_ru)\n",
    "corpus_ru = [id2word_ru.doc2bow(text) for text in data_words_bigrams_ru]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_ru = gensim.models.ldamodel.LdaModel(\n",
    "    corpus=corpus_ru,\n",
    "    id2word=id2word_ru,\n",
    "    num_topics=20, \n",
    "    random_state=100,\n",
    "    update_every=1,\n",
    "    chunksize=100,\n",
    "    passes=10,\n",
    "    alpha='auto',\n",
    "    per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0,\n",
      "  '0.021*\"человек\" + 0.020*\"москва\" + 0.019*\"сообщать\" + 0.011*\"место\" + '\n",
      "  '0.011*\"происходить\" + 0.009*\"улица\" + 0.009*\"здание\" + 0.008*\"находиться\" + '\n",
      "  '0.008*\"мужчина\" + 0.008*\"погибать\"'),\n",
      " (1,\n",
      "  '0.027*\"сбербанк\" + 0.015*\"минфин\" + 0.015*\"снижаться\" + 0.011*\"магазин\" + '\n",
      "  '0.010*\"продукт\" + 0.010*\"ставка\" + 0.009*\"мост\" + 0.008*\"валюта\" + '\n",
      "  '0.008*\"реитинг\" + 0.008*\"выпуск\"'),\n",
      " (2,\n",
      "  '0.034*\"крым\" + 0.025*\"интернет\" + 0.023*\"депутат\" + 0.019*\"закон\" + '\n",
      "  '0.016*\"госдума\" + 0.012*\"законопроект\" + 0.008*\"депутат_госдума\" + '\n",
      "  '0.007*\"лнр\" + 0.007*\"нилов\" + 0.007*\"сеть\"'),\n",
      " (3,\n",
      "  '0.015*\"сирия\" + 0.014*\"военныи\" + 0.014*\"оон\" + 0.011*\"город\" + '\n",
      "  '0.010*\"посол\" + 0.010*\"сша\" + 0.009*\"сила\" + 0.009*\"нато\" + '\n",
      "  '0.008*\"россиискии\" + 0.008*\"россия\"'),\n",
      " (4,\n",
      "  '0.022*\"суд\" + 0.020*\"дело\" + 0.019*\"год\" + 0.009*\"сотрудник\" + '\n",
      "  '0.009*\"задерживать\" + 0.009*\"сообщать\" + 0.008*\"которыи\" + 0.008*\"бывшии\" + '\n",
      "  '0.006*\"убииство\" + 0.006*\"экс\"'),\n",
      " (5,\n",
      "  '0.008*\"роман\" + 0.008*\"иран\" + 0.006*\"израиль\" + 0.006*\"подарок\" + '\n",
      "  '0.006*\"штаб\" + 0.006*\"сохраняться\" + 0.006*\"южныи_осетия\" + 0.006*\"греция\" '\n",
      "  '+ 0.006*\"рокфеллер\" + 0.005*\"выставлять\"'),\n",
      " (6,\n",
      "  '0.011*\"система\" + 0.010*\"исследование\" + 0.009*\"ученыи\" + '\n",
      "  '0.008*\"специалист\" + 0.008*\"медведев\" + 0.007*\"программа\" + '\n",
      "  '0.006*\"развитие\" + 0.006*\"научныи\" + 0.006*\"врач\" + 0.005*\"работа\"'),\n",
      " (7,\n",
      "  '0.031*\"россия\" + 0.017*\"президент\" + 0.015*\"заявлять\" + 0.014*\"россиискии\" '\n",
      "  '+ 0.013*\"глава\" + 0.013*\"украина\" + 0.012*\"страна\" + 0.009*\"которыи\" + '\n",
      "  '0.008*\"сообщать\" + 0.008*\"год\"'),\n",
      " (8,\n",
      "  '0.037*\"это\" + 0.026*\"которыи\" + 0.017*\"весь\" + 0.015*\"свои\" + 0.015*\"мочь\" '\n",
      "  '+ 0.013*\"такои\" + 0.011*\"человек\" + 0.009*\"другои\" + 0.008*\"время\" + '\n",
      "  '0.008*\"говорить\"'),\n",
      " (9,\n",
      "  '0.019*\"ребенок\" + 0.018*\"город\" + 0.018*\"регион\" + 0.012*\"полицеискии\" + '\n",
      "  '0.011*\"тысяча\" + 0.010*\"житель\" + 0.008*\"человек\" + 0.008*\"область\" + '\n",
      "  '0.008*\"региональныи\" + 0.008*\"земля\"'),\n",
      " (10,\n",
      "  '0.075*\"сша\" + 0.050*\"трамп\" + 0.028*\"американскии\" + 0.018*\"дональд_трамп\" '\n",
      "  '+ 0.013*\"самолет\" + 0.009*\"вашингтон\" + 0.009*\"белыи_дом\" + 0.006*\"кадыров\" '\n",
      "  '+ 0.006*\"администрация\" + 0.005*\"штат\"'),\n",
      " (11,\n",
      "  '0.017*\"год\" + 0.008*\"ребенок\" + 0.008*\"женщина\" + 0.007*\"становиться\" + '\n",
      "  '0.007*\"день\" + 0.007*\"жизнь\" + 0.006*\"свои\" + 0.006*\"больница\" + '\n",
      "  '0.006*\"номер\" + 0.005*\"молодои\"'),\n",
      " (12,\n",
      "  '0.019*\"год\" + 0.010*\"фильм\" + 0.009*\"русскии\" + 0.008*\"музеи\" + '\n",
      "  '0.008*\"культура\" + 0.008*\"памятник\" + 0.007*\"театр\" + 0.007*\"советскии\" + '\n",
      "  '0.007*\"белоруссия\" + 0.006*\"история\"'),\n",
      " (13,\n",
      "  '0.023*\"год\" + 0.018*\"банк\" + 0.018*\"компания\" + 0.007*\"млн\" + '\n",
      "  '0.007*\"проект\" + 0.007*\"рубль\" + 0.006*\"которыи\" + 0.006*\"предприятие\" + '\n",
      "  '0.005*\"строительство\" + 0.005*\"получать\"'),\n",
      " (14,\n",
      "  '0.017*\"церковь\" + 0.016*\"турция\" + 0.012*\"турецкии\" + 0.011*\"храм\" + '\n",
      "  '0.009*\"грузия\" + 0.007*\"святои\" + 0.006*\"вчера\" + 0.006*\"собор\" + '\n",
      "  '0.006*\"акция_протест\" + 0.006*\"арена\"'),\n",
      " (15,\n",
      "  '0.020*\"новость\" + 0.016*\"газета_ru\" + 0.011*\"чемпионат\" + 0.009*\"также\" + '\n",
      "  '0.009*\"спортсмен\" + 0.008*\"соревнование\" + 0.007*\"испания\" + '\n",
      "  '0.007*\"праздник\" + 0.007*\"финал\" + 0.006*\"победитель\"'),\n",
      " (16,\n",
      "  '0.051*\"год\" + 0.011*\"составлять\" + 0.011*\"рост\" + 0.010*\"уровень\" + '\n",
      "  '0.010*\"рынок\" + 0.010*\"россия\" + 0.010*\"рубль\" + 0.010*\"экономика\" + '\n",
      "  '0.010*\"цена\" + 0.008*\"россиискии\"'),\n",
      " (17,\n",
      "  '0.024*\"донбасс\" + 0.021*\"военныи\" + 0.011*\"днр\" + 0.010*\"техника\" + '\n",
      "  '0.010*\"советник\" + 0.009*\"сторона\" + 0.009*\"армения\" + 0.008*\"боевои\" + '\n",
      "  '0.008*\"конфликт\" + 0.007*\"минобороны\"'),\n",
      " (18,\n",
      "  '0.027*\"великобритания\" + 0.027*\"лондон\" + 0.026*\"британскии\" + '\n",
      "  '0.020*\"газпром\" + 0.018*\"газ\" + 0.015*\"кндр\" + 0.013*\"восстанавливать\" + '\n",
      "  '0.011*\"спг\" + 0.010*\"отчет\" + 0.008*\"потребоваться\"'),\n",
      " (19,\n",
      "  '0.022*\"матч\" + 0.021*\"команда\" + 0.014*\"сборная\" + 0.013*\"клуб\" + '\n",
      "  '0.012*\"россия\" + 0.011*\"спорт\" + 0.010*\"игра\" + 0.010*\"первыи\" + '\n",
      "  '0.008*\"футболист\" + 0.008*\"второи\"')]\n"
     ]
    }
   ],
   "source": [
    "pprint(lda_model_ru.print_topics())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "with open('lda_ru', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        \"data_ru\": data_ru,\n",
    "        \"data_words_ru\": data_words_ru,\n",
    "        \"bigram_mod_ru\": bigram_mod_ru,\n",
    "        \"data_words_bigrams_ru\": data_words_bigrams_ru,\n",
    "        \"id2word_ru\": id2word_ru,\n",
    "        \"corpus_ru\": corpus_ru,\n",
    "        \"lda_model_ru\": lda_model_ru,\n",
    "    }, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "model_list_ru, coherence_values_ru = compute_coherence_values(\n",
    "    dictionary=id2word_ru, corpus=corpus_ru, texts=data_words_bigrams_ru, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "limit=40; start=2; step=6;\n",
    "x = range(start, limit, step)\n",
    "plt.plot(x, coherence_values_ru)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "lda_model_opt_ru = model_list_ru[2]\n",
    "lda_model_opt_ru.save('lda_model_opt_ru.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.023*\"человек\" + 0.015*\"москва\" + 0.013*\"сообщать\" + 0.010*\"место\" + 0.010*\"город\" + 0.010*\"происходить\" + 0.008*\"дом\" + 0.008*\"улица\" + 0.007*\"здание\" + 0.007*\"данные\"'),\n",
       " (1,\n",
       "  '0.039*\"год\" + 0.025*\"банк\" + 0.014*\"рубль\" + 0.012*\"составлять\" + 0.012*\"компания\" + 0.011*\"рынок\" + 0.009*\"рост\" + 0.009*\"млн\" + 0.009*\"цена\" + 0.008*\"млрд\"'),\n",
       " (2,\n",
       "  '0.015*\"крым\" + 0.009*\"новыи\" + 0.009*\"ребенок\" + 0.007*\"завод\" + 0.007*\"интернет\" + 0.007*\"работа\" + 0.007*\"специалист\" + 0.007*\"ученыи\" + 0.006*\"школа\" + 0.006*\"год\"'),\n",
       " (3,\n",
       "  '0.025*\"суд\" + 0.023*\"дело\" + 0.012*\"год\" + 0.012*\"задерживать\" + 0.009*\"сотрудник\" + 0.008*\"убииство\" + 0.008*\"которыи\" + 0.007*\"полиция\" + 0.007*\"бывшии\" + 0.006*\"мвд\"'),\n",
       " (4,\n",
       "  '0.022*\"год\" + 0.019*\"сообщать\" + 0.015*\"москва\" + 0.015*\"россия\" + 0.013*\"риа_новость\" + 0.012*\"россиискии\" + 0.011*\"март\" + 0.009*\"новость\" + 0.008*\"тасс\" + 0.006*\"проходить\"'),\n",
       " (5,\n",
       "  '0.012*\"аукцион\" + 0.012*\"грузия\" + 0.010*\"чечня\" + 0.009*\"дипломат\" + 0.007*\"месторождение\" + 0.006*\"дочка\" + 0.006*\"южныи_осетия\" + 0.005*\"заранее\" + 0.005*\"ирландскии\" + 0.005*\"повторять\"'),\n",
       " (6,\n",
       "  '0.017*\"это\" + 0.014*\"которыи\" + 0.014*\"россия\" + 0.013*\"год\" + 0.010*\"россиискии\" + 0.009*\"страна\" + 0.009*\"мочь\" + 0.008*\"наш\" + 0.008*\"новыи\" + 0.007*\"отмечать\"'),\n",
       " (7,\n",
       "  '0.023*\"россия\" + 0.021*\"президент\" + 0.019*\"сша\" + 0.018*\"заявлять\" + 0.016*\"украина\" + 0.012*\"страна\" + 0.011*\"глава\" + 0.011*\"трамп\" + 0.010*\"это\" + 0.010*\"россиискии\"'),\n",
       " (8,\n",
       "  '0.013*\"партия\" + 0.009*\"депутат\" + 0.008*\"выборы\" + 0.008*\"которыи\" + 0.007*\"свои\" + 0.007*\"проходить\" + 0.006*\"год\" + 0.005*\"митинг\" + 0.005*\"власть\" + 0.005*\"парламент\"'),\n",
       " (9,\n",
       "  '0.023*\"военныи\" + 0.013*\"полицеискии\" + 0.011*\"город\" + 0.010*\"территория\" + 0.009*\"раион\" + 0.008*\"сирия\" + 0.007*\"минобороны\" + 0.007*\"днр\" + 0.007*\"сила\" + 0.007*\"донбасс\"'),\n",
       " (10,\n",
       "  '0.017*\"год\" + 0.008*\"фильм\" + 0.008*\"становиться\" + 0.006*\"культура\" + 0.006*\"церковь\" + 0.006*\"русскии\" + 0.006*\"музеи\" + 0.005*\"театр\" + 0.005*\"которыи\" + 0.004*\"новыи\"'),\n",
       " (11,\n",
       "  '0.026*\"это\" + 0.015*\"которыи\" + 0.014*\"свои\" + 0.012*\"весь\" + 0.011*\"человек\" + 0.009*\"такои\" + 0.009*\"мочь\" + 0.007*\"самыи\" + 0.006*\"другои\" + 0.006*\"время\"'),\n",
       " (12,\n",
       "  '0.016*\"команда\" + 0.016*\"матч\" + 0.010*\"сборная\" + 0.010*\"россия\" + 0.009*\"клуб\" + 0.009*\"спорт\" + 0.008*\"первыи\" + 0.008*\"новость\" + 0.007*\"игра\" + 0.006*\"второи\"'),\n",
       " (13,\n",
       "  '0.016*\"год\" + 0.010*\"которыи\" + 0.010*\"компания\" + 0.008*\"решение\" + 0.008*\"закон\" + 0.006*\"это\" + 0.006*\"принимать\" + 0.006*\"мочь\" + 0.005*\"получать\" + 0.005*\"также\"')]"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda_model_opt_ru.print_topics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
