{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from stem import Signal\n",
    "from stem.control import Controller\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request(url):\n",
    "    renew_tor_ip()\n",
    "    \n",
    "    user_agent = UserAgent().chrome\n",
    "    headers = {'User-Agent': user_agent}\n",
    "    \n",
    "    \n",
    "    session = requests.session()\n",
    "\n",
    "    session.proxies = {}\n",
    "    session.proxies['http']='socks5h://localhost:9050'\n",
    "    session.proxies['https']='socks5h://localhost:9050'\n",
    "\n",
    "    try:\n",
    "        r = session.get(url, headers=headers)\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "    else:\n",
    "        return r   \n",
    "\n",
    "def get_current_ip():\n",
    "    session = requests.session()\n",
    "\n",
    "    # TO Request URL with SOCKS over TOR\n",
    "    session.proxies = {}\n",
    "    session.proxies['http']='socks5h://localhost:9050'\n",
    "    session.proxies['https']='socks5h://localhost:9050'\n",
    "\n",
    "    try:\n",
    "        r = session.get('http://httpbin.org/ip')\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "    else:\n",
    "        return r.text.split()[2].replace('\\\"', '')\n",
    "\n",
    "\n",
    "def renew_tor_ip():\n",
    "    with Controller.from_port(port = 9051) as controller:\n",
    "        controller.authenticate(password=\"tor_for_parsing\")\n",
    "        controller.signal(Signal.NEWNYM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_cars = 3350\n",
    "cars_per_page = 38\n",
    "pages_with_cars = math.ceil(total_cars/cars_per_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages_with_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_ru_url = 'https://auto.ru/cars/volkswagen/polo/used/?sort=price-asc&page={}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "20 % 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_auto_ru(number_of_pages, links):\n",
    "    range_list = list(range(1, number_of_pages + 1))\n",
    "    for page in tqdm(range_list):\n",
    "        \n",
    "        prev_links = set(links).copy()\n",
    "        \n",
    "        get_page(auto_ru_url, page, links)\n",
    "        \n",
    "        if prev_links == set(links):\n",
    "            i = 5\n",
    "            while prev_links == set(links) and i > 0:\n",
    "                get_page(auto_ru_url, page, links)\n",
    "                i -= 1\n",
    "        \n",
    "        print(f'page: {page}/{number_of_pages}, links collected: {len(links)}, unique_links: {len(set(links))}')\n",
    "        \n",
    "        if page & 10 == 0:\n",
    "            with open('volk_polo_pages.json', 'r+') as file:\n",
    "                file.seek(0)\n",
    "                file.truncate()\n",
    "                json.dump(links, file)\n",
    "\n",
    "def get_page(main_url, page_num, links):\n",
    "    try:\n",
    "        resp = get_request(main_url.format(page_num))\n",
    "    except Exception:\n",
    "        return None\n",
    "    else:\n",
    "        if resp:\n",
    "            if resp.status_code == 200:\n",
    "                get_cars_on_page(links, resp.text)\n",
    "\n",
    "def get_cars_on_page(links, content):\n",
    "    soup = BeautifulSoup(content, 'html.parser')\n",
    "    cars_on_page = soup.find_all('div', {'class': 'ListingItem-module__thumb'})\n",
    "\n",
    "    for i, car in enumerate(cars_on_page):\n",
    "        link_to_car = car.find('a', {'class': 'Link OfferThumb'})\n",
    "        if link_to_car:\n",
    "            link_to_car = link_to_car.get('href', None)\n",
    "            if link_to_car:\n",
    "                links.append(link_to_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_links=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a27a2cc31b2246f6854704e89b3fafa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=89.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page: 1/89, links collected: 37, unique_links: 37\n",
      "page: 2/89, links collected: 74, unique_links: 74\n",
      "page: 3/89, links collected: 111, unique_links: 111\n",
      "page: 4/89, links collected: 148, unique_links: 148\n",
      "page: 5/89, links collected: 185, unique_links: 185\n",
      "page: 6/89, links collected: 222, unique_links: 222\n",
      "page: 7/89, links collected: 259, unique_links: 259\n",
      "page: 8/89, links collected: 296, unique_links: 296\n",
      "page: 9/89, links collected: 333, unique_links: 333\n",
      "page: 10/89, links collected: 370, unique_links: 370\n",
      "page: 11/89, links collected: 407, unique_links: 407\n",
      "page: 12/89, links collected: 444, unique_links: 444\n",
      "page: 13/89, links collected: 481, unique_links: 481\n",
      "page: 14/89, links collected: 518, unique_links: 518\n",
      "page: 15/89, links collected: 555, unique_links: 555\n",
      "page: 16/89, links collected: 592, unique_links: 592\n",
      "page: 17/89, links collected: 629, unique_links: 629\n",
      "page: 18/89, links collected: 666, unique_links: 666\n",
      "page: 19/89, links collected: 703, unique_links: 703\n",
      "page: 20/89, links collected: 740, unique_links: 740\n",
      "page: 21/89, links collected: 777, unique_links: 777\n",
      "page: 22/89, links collected: 814, unique_links: 814\n",
      "page: 23/89, links collected: 851, unique_links: 851\n",
      "page: 24/89, links collected: 888, unique_links: 888\n",
      "page: 25/89, links collected: 925, unique_links: 925\n",
      "page: 26/89, links collected: 962, unique_links: 962\n",
      "page: 27/89, links collected: 999, unique_links: 999\n",
      "page: 28/89, links collected: 1036, unique_links: 1036\n",
      "page: 29/89, links collected: 1036, unique_links: 1036\n",
      "page: 30/89, links collected: 1036, unique_links: 1036\n",
      "page: 31/89, links collected: 1072, unique_links: 1072\n",
      "page: 32/89, links collected: 1108, unique_links: 1108\n",
      "page: 33/89, links collected: 1145, unique_links: 1145\n",
      "page: 34/89, links collected: 1182, unique_links: 1182\n",
      "page: 35/89, links collected: 1218, unique_links: 1218\n",
      "page: 36/89, links collected: 1255, unique_links: 1255\n",
      "page: 37/89, links collected: 1255, unique_links: 1255\n",
      "page: 38/89, links collected: 1255, unique_links: 1255\n",
      "page: 39/89, links collected: 1292, unique_links: 1292\n",
      "page: 40/89, links collected: 1329, unique_links: 1329\n",
      "page: 41/89, links collected: 1366, unique_links: 1366\n",
      "page: 42/89, links collected: 1403, unique_links: 1403\n",
      "page: 43/89, links collected: 1440, unique_links: 1440\n",
      "page: 44/89, links collected: 1477, unique_links: 1477\n",
      "page: 45/89, links collected: 1514, unique_links: 1514\n",
      "page: 46/89, links collected: 1514, unique_links: 1514\n",
      "SOCKSHTTPSConnectionPool(host='auto.ru', port=443): Max retries exceeded with url: /cars/volkswagen/polo/used/?sort=price-asc&page=47 (Caused by NewConnectionError('<urllib3.contrib.socks.SOCKSHTTPSConnection object at 0x7f3fa0410490>: Failed to establish a new connection: 0x01: General SOCKS server failure'))\n",
      "page: 47/89, links collected: 1551, unique_links: 1551\n",
      "page: 48/89, links collected: 1588, unique_links: 1588\n",
      "page: 49/89, links collected: 1624, unique_links: 1624\n",
      "page: 50/89, links collected: 1659, unique_links: 1659\n",
      "page: 51/89, links collected: 1696, unique_links: 1696\n",
      "page: 52/89, links collected: 1733, unique_links: 1733\n",
      "page: 53/89, links collected: 1769, unique_links: 1769\n",
      "page: 54/89, links collected: 1806, unique_links: 1806\n",
      "page: 55/89, links collected: 1843, unique_links: 1843\n",
      "page: 56/89, links collected: 1880, unique_links: 1880\n",
      "page: 57/89, links collected: 1917, unique_links: 1917\n",
      "page: 58/89, links collected: 1953, unique_links: 1953\n",
      "page: 59/89, links collected: 1990, unique_links: 1990\n",
      "page: 60/89, links collected: 2026, unique_links: 2026\n",
      "page: 61/89, links collected: 2063, unique_links: 2063\n",
      "page: 62/89, links collected: 2063, unique_links: 2063\n",
      "page: 63/89, links collected: 2100, unique_links: 2100\n",
      "page: 64/89, links collected: 2136, unique_links: 2135\n",
      "page: 65/89, links collected: 2172, unique_links: 2171\n",
      "page: 66/89, links collected: 2172, unique_links: 2171\n",
      "page: 67/89, links collected: 2208, unique_links: 2207\n",
      "page: 68/89, links collected: 2245, unique_links: 2244\n",
      "page: 69/89, links collected: 2282, unique_links: 2280\n",
      "page: 70/89, links collected: 2319, unique_links: 2317\n",
      "page: 71/89, links collected: 2356, unique_links: 2354\n",
      "page: 72/89, links collected: 2393, unique_links: 2390\n",
      "page: 73/89, links collected: 2430, unique_links: 2427\n",
      "page: 74/89, links collected: 2467, unique_links: 2464\n",
      "page: 75/89, links collected: 2504, unique_links: 2501\n",
      "page: 76/89, links collected: 2541, unique_links: 2538\n",
      "page: 77/89, links collected: 2578, unique_links: 2574\n",
      "page: 78/89, links collected: 2615, unique_links: 2611\n",
      "page: 79/89, links collected: 2652, unique_links: 2648\n",
      "page: 80/89, links collected: 2689, unique_links: 2685\n",
      "page: 81/89, links collected: 2726, unique_links: 2721\n",
      "page: 82/89, links collected: 2763, unique_links: 2758\n",
      "page: 83/89, links collected: 2763, unique_links: 2758\n",
      "page: 84/89, links collected: 2799, unique_links: 2794\n",
      "page: 85/89, links collected: 2836, unique_links: 2831\n",
      "page: 86/89, links collected: 2873, unique_links: 2868\n",
      "page: 87/89, links collected: 2909, unique_links: 2904\n",
      "page: 88/89, links collected: 2946, unique_links: 2940\n",
      "page: 89/89, links collected: 2982, unique_links: 2976\n",
      "\n"
     ]
    }
   ],
   "source": [
    "parse_auto_ru(pages_with_cars, cars_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2976"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(set(cars_links)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_1800_pages = cars_links.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('volk_polo_used_pages.json', 'w') as file:\n",
    "    file.seek(0)\n",
    "    file.truncate()\n",
    "    json.dump(list(set(cars_links)), file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_science",
   "language": "python",
   "name": "data_science"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
